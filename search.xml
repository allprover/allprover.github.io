<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>UCINET社交网络分析</title>
    <url>/2024/03/23/UCINET%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="1-共现矩阵"><a href="#1-共现矩阵" class="headerlink" title="1.共现矩阵"></a>1.共现矩阵</h1><h2 id="灰度共生矩阵"><a href="#灰度共生矩阵" class="headerlink" title="灰度共生矩阵"></a>灰度共生矩阵</h2><ul>
<li>先将图像转换成灰度图片</li>
<li>然后再用<code>graycomatirx</code>函数进行共生矩阵计算</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.set_printoptions(suppress=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">glcm</span>(<span class="params">arr, d_x, d_y, gray_level=<span class="number">16</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;计算并返回归一化后的灰度共生矩阵&#x27;&#x27;&#x27;</span></span><br><span class="line">    max_gray = arr.<span class="built_in">max</span>()</span><br><span class="line">    height, width = arr.shape</span><br><span class="line">    arr = arr.astype(np.float64)  <span class="comment"># 将uint8类型转换为float64，以免数据失真</span></span><br><span class="line">    arr = arr * (gray_level - <span class="number">1</span>) // max_gray  <span class="comment"># 若灰度级数大于gray_level，则将图像的灰度级缩小至gray_level，减小灰度共生矩阵的大小。量化后灰度值范围：0 ~ gray_level - 1</span></span><br><span class="line">    ret = np.zeros([gray_level, gray_level])</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(height -  <span class="built_in">abs</span>(d_y)):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(width - <span class="built_in">abs</span>(d_x)):  <span class="comment"># range(width - d_x)  #注释为源代码，经评论指出错误后修改</span></span><br><span class="line">            rows = arr[j][i].astype(<span class="built_in">int</span>)</span><br><span class="line">            cols = arr[j + d_y][i + d_x].astype(<span class="built_in">int</span>)</span><br><span class="line">            ret[rows][cols] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> d_x &gt;= d_y:</span><br><span class="line">        ret = ret / <span class="built_in">float</span>(height * (width - <span class="number">1</span>))  <span class="comment"># 归一化, 水平方向或垂直方向</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ret = ret / <span class="built_in">float</span>((height - <span class="number">1</span>) * (width - <span class="number">1</span>))  <span class="comment"># 归一化, 45度或135度方向</span></span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;归一化时分母值根据角度theta变化，0度或90度时为height * (width - 1), 45度或135度时为(height - 1) * (width - 1)&#x27;&#x27;&#x27;</span></span><br><span class="line">    fp = <span class="string">r&#x27;/home/jovyan/work/000.png&#x27;</span></span><br><span class="line">    img = cv2.imread(fp)</span><br><span class="line">    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 转换为灰度图像，uint8</span></span><br><span class="line">    <span class="comment">#glcm_0 = glcm(img_gray, 1, 0)  # 水平方向</span></span><br><span class="line">    glcm_1 = glcm(img_gray, <span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># 垂直方向</span></span><br><span class="line">    <span class="comment"># glcm_2 = glcm(img_gray, 1, 1)  # 45度方向</span></span><br><span class="line">    <span class="comment"># glcm_3 = glcm(img_gray, -1, 1)  # 135度方向</span></span><br><span class="line">    <span class="built_in">print</span>(glcm_1)</span><br><span class="line"></span><br><span class="line">    np.save(<span class="string">&#x27;/home/jovyan/work/glcm_1.npy&#x27;</span>, glcm_1)</span><br></pre></td></tr></table></figure>
<p>我们将npy.文件格式转换为csv，再转化为Excel文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loaded_data = np.load(<span class="string">&#x27;/home/jovyan/work/glcm_1.npy&#x27;</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line">  </span><br><span class="line">df = pd.DataFrame(loaded_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存为CSV文件  </span></span><br><span class="line">df.to_csv(<span class="string">&#x27;/home/jovyan/work/output.csv&#x27;</span>, index=<span class="literal">False</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 保存为Excel文件（需要安装openpyxl或xlsxwriter库）  </span></span><br><span class="line">df.to_excel(<span class="string">&#x27;output.xlsx&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>输出的表格如下图：</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240323185009666.png" alt="image-20240323185009666"></p>
<h1 id="2-Ucinet分析"><a href="#2-Ucinet分析" class="headerlink" title="2 Ucinet分析"></a>2 Ucinet分析</h1><h2 id="2-1-输入矩阵中"><a href="#2-1-输入矩阵中" class="headerlink" title="2.1 输入矩阵中"></a>2.1 输入矩阵中</h2><p>菜单栏第三行第二个</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240323185402089.png" alt="image-20240323185402089"></p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240323185201093.png" alt="image-20240323185201093"></p>
<p>随后保存</p>
<p><img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240323185323487.png" alt="image-20240323185323487"></p>
<h2 id="2-2-二值化"><a href="#2-2-二值化" class="headerlink" title="2.2 二值化"></a>2.2 二值化</h2><p>transform-&gt;dichotomize</p>
<pre><code>    0 1 2 3 4 5 6 7 8 9 1 1 1 1 1 1
    - - - - - - - - - - - - - - - -
 0  1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0
 1  1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0
 2  1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
 3  1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0
 4  1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0
 5  0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
 6  0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
 7  0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
 8  0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0
 9  0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0
10  0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
11  0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
12  0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
13  0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1
14  0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1
15  0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1
</code></pre><h2 id="2-3-生成网络"><a href="#2-3-生成网络" class="headerlink" title="2.3 生成网络"></a>2.3 生成网络</h2><p><img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240323185515725.png" alt="image-20240323185515725"></p>
<p>将刚才保存的共现矩阵导入</p>
<p><img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240323185610750.png" alt="image-20240323185610750"></p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240323185751157.png" alt="image-20240323185751157"></p>
<h2 id="2-4-中心性分析"><a href="#2-4-中心性分析" class="headerlink" title="2.4 中心性分析"></a>2.4 中心性分析</h2><p>Analysis-&gt;centralitymeasures</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/20180415162735355" alt="img"></p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240323193324338.png" alt="image-20240323193324338"></p>
<h2 id="2-5-节点中心度"><a href="#2-5-节点中心度" class="headerlink" title="2.5 节点中心度"></a>2.5 节点中心度</h2><p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240323185849724.png" alt="image-20240323185849724"></p>
<p>FREEMAN’S DEGREE CENTRALITY MEASURES:</p>
<p>Diagonal valid?               NO<br>Model:                        SYMMETRIC<br>Input dataset:                cocomarix (C:\Users\lenovo\Desktop\论文\UCINET\cocomarix)</p>
<p>​               1            2            3<br>​          Degree    NrmDegree        Share</p>
<hr>
<p>  8  7         0.017       13.909        0.130<br>  7  6         0.017       13.291        0.124<br>  9  8         0.014       10.977        0.103<br> 15 14         0.011        8.892        0.083<br> 10  9         0.010        8.241        0.077<br> 14 13         0.010        8.011        0.075<br>  6  5         0.009        7.025        0.066<br> 11 10         0.007        5.887        0.055<br> 13 12         0.007        5.866        0.055<br>  4  3         0.007        5.270        0.049<br> 12 11         0.006        4.755        0.045<br> 16 15         0.005        3.821        0.036<br>  3  2         0.005        3.633        0.034<br>  5  4         0.004        3.246        0.030<br>  2  1         0.003        2.043        0.019<br>  1  0         0.002        1.904        0.018</p>
<p>DESCRIPTIVE STATISTICS</p>
<p>​                     1            2            3<br>​                Degree    NrmDegree        Share</p>
<hr>
<p>  1     Mean         0.008        6.673        0.063<br>  2  Std Dev         0.004        3.572        0.033<br>  3      Sum         0.133      106.771        1.000<br>  4 Variance         0.000       12.763        0.001<br>  5      SSQ         0.001      916.710        0.080<br>  6    MCSSQ         0.000      204.204        0.018<br>  7 Euc Norm         0.038       30.277        0.284<br>  8  Minimum         0.002        1.904        0.018<br>  9  Maximum         0.017       13.909        0.130</p>
<p>Network Centralization = 8.27%<br>Heterogeneity = 8.04%.  Normalized = 1.91%</p>
<p>Actor-by-centrality matrix saved as dataset FreemanDegree</p>
<hr>
<p>Running time:  00:00:01<br>Output generated:  23 3月 24 18:59:01<br>Copyright (c) 2002-8 Analytic Technologies</p>
<blockquote>
<p>NrmDegree 标准中心度</p>
<p>Mean 均值</p>
<p>Std Dev 标准差</p>
<p>Variance 方差</p>
<p>SSQ   平方差和</p>
<p>MCSSQ 平均值平方差和</p>
<p>Euc Norm 欧几里得范数</p>
</blockquote>
<h2 id="2-6-接近中心度"><a href="#2-6-接近中心度" class="headerlink" title="2.6 接近中心度"></a>2.6 接近中心度</h2><p>network-&gt;centrality-&gt;closeness</p>
<p>CLOSENESS CENTRALITY</p>
<p>Input dataset:                cocomarix (C:\Users\lenovo\Desktop\论文\UCINET\cocomarix)<br>Method:                       Geodesic paths only (Freeman Closeness)<br>Output dataset:               Closeness (C:\Users\lenovo\Desktop\论文\UCINET\Closeness)</p>
<p>Note: Data not symmetric, therefore separate in-closeness &amp; out-closeness computed.</p>
<p>Closeness Centrality Measures</p>
<pre><code>               1            2            3            4
       inFarness   outFarness  inCloseness outCloseness
    ------------ ------------ ------------ ------------
</code></pre><p> 11 10        16.000       16.000       93.750       93.750<br> 10  9        16.000       18.000       93.750       83.333<br>  7  6        16.000       17.000       93.750       88.235<br> 12 11        17.000       18.000       88.235       83.333<br>  6  5        17.000       19.000       88.235       78.947<br>  8  7        17.000       17.000       88.235       88.235<br>  9  8        18.000       18.000       83.333       83.333<br>  5  4        18.000       18.000       83.333       83.333<br>  4  3        18.000       20.000       83.333       75.000<br> 13 12        19.000       18.000       78.947       83.333<br>  3  2        20.000       18.000       75.000       83.333<br> 14 13        20.000       21.000       75.000       71.429<br> 15 14        21.000       22.000       71.429       68.182<br>  2  1        22.000       20.000       68.182       75.000<br> 16 15        26.000       25.000       57.692       60.000<br>  1  0        29.000       25.000       51.724       60.000</p>
<p>Statistics</p>
<pre><code>                     1            2            3            4
             inFarness   outFarness  inCloseness outCloseness
          ------------ ------------ ------------ ------------
</code></pre><p>  1     Mean        19.375       19.375       79.621       78.674<br>  2  Std Dev         3.569        2.595       12.153        9.445<br>  3      Sum       310.000      310.000     1273.930     1258.778<br>  4 Variance        12.734        6.734      147.693       89.217<br>  5      SSQ      6210.000     6114.000   103794.195   100460.148<br>  6    MCSSQ       203.750      107.750     2363.083     1427.469<br>  7 Euc Norm        78.804       78.192      322.171      316.954<br>  8  Minimum        16.000       16.000       51.724       60.000<br>  9  Maximum        29.000       25.000       93.750       93.750</p>
<p>Network in-Centralization = 31.22%<br>Network out-Centralization = 33.31%</p>
<p>Output actor-by-centrality measure matrix saved as dataset Closeness (C:\Users\lenovo\Desktop\论文\UCINET\Closeness)</p>
<hr>
<p>Running time:  00:00:01<br>Output generated:  23 3月 24 19:37:04<br>Copyright (c) 1999-2008 Analytic Technologies</p>
<h2 id="2-7-中间中心度"><a href="#2-7-中间中心度" class="headerlink" title="2.7 中间中心度"></a>2.7 中间中心度</h2><p>network-&gt;centrality-&gt;freeman betweenness-&gt;node betweenness</p>
<p>FREEMAN BETWEENNESS CENTRALITY</p>
<p>Input dataset:                cocomarix (C:\Users\lenovo\Desktop\论文\UCINET\cocomarix)</p>
<p>Important note: this routine binarizes but does NOT symmetrize.</p>
<p>Un-normalized centralization: 115.007</p>
<pre><code>               1            2
     Betweenness nBetweenness
    ------------ ------------
</code></pre><p> 11 10        11.563        5.506<br>  7  6         7.874        3.749<br>  5  4         6.907        3.289<br> 12 11         6.215        2.959<br> 10  9         5.533        2.635<br>  4  3         5.395        2.569<br>  8  7         4.846        2.308<br>  3  2         4.621        2.201<br> 13 12         4.389        2.090<br>  6  5         3.718        1.771<br>  9  8         2.939        1.400<br> 14 13         2.330        1.109<br>  2  1         2.310        1.100<br> 15 14         1.359        0.647<br>  1  0         0.000        0.000<br> 16 15         0.000        0.000</p>
<p>DESCRIPTIVE STATISTICS FOR EACH MEASURE</p>
<pre><code>                     1            2
           Betweenness nBetweenness
          ------------ ------------
</code></pre><p>  1     Mean         4.375        2.083<br>  2  Std Dev         2.901        1.382<br>  3      Sum        70.000       33.333<br>  4 Variance         8.418        1.909<br>  5      SSQ       440.937       99.986<br>  6    MCSSQ       134.687       30.541<br>  7 Euc Norm        20.999        9.999<br>  8  Minimum         0.000        0.000<br>  9  Maximum        11.563        5.506</p>
<p>Network Centralization Index = 3.65%</p>
<p>Output actor-by-centrality measure matrix saved as dataset FreemanBetweenness</p>
<hr>
<p>Running time:  00:00:01<br>Output generated:  23 3月 24 19:38:10<br>Copyright (c) 1999-2008 Analytic Technologies</p>
<h2 id="2-8-凝聚子群分析"><a href="#2-8-凝聚子群分析" class="headerlink" title="2.8 凝聚子群分析"></a>2.8 凝聚子群分析</h2><p>network-&gt;roles&amp; positions -&gt;structural -&gt;concor</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240323193930316.png" alt="image-20240323193930316"></p>
<h1 id="3-结论"><a href="#3-结论" class="headerlink" title="3 结论"></a>3 结论</h1><p>社交网络分析在灰度共生矩阵上的应用，反应了像素点之间的关联。从而可以得出图片中的痕迹是否明显。</p>
<h1 id="4-与自己方向相结合"><a href="#4-与自己方向相结合" class="headerlink" title="4 与自己方向相结合"></a>4 与自己方向相结合</h1><p>我的研究方向是视频深度伪造检测</p>
<p>本次提供的灰度共生数据，来源于以下图片</p>
<p><img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240325082027764.png" alt="image-20240325082027764"></p>
<p>倘若，再加以处理，例如：将真的图片中的人脸提取出来，再进行灰度共生矩阵处理，对其进行中心性分析等一系列社交网络分析。然后将所得的分析数据输入神经网络模型中，并重复输入不同的人脸图像，让模型进行学习。再将假图片的分析数据给训练后的模型进行评估。</p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>Hexo安装和配置next主题</title>
    <url>/2024/03/22/%E5%AE%89%E8%A3%85Hexo%E5%92%8C%E9%85%8D%E7%BD%AEnext/</url>
    <content><![CDATA[<h1 id="1-安装Hexo"><a href="#1-安装Hexo" class="headerlink" title="1.安装Hexo"></a>1.安装Hexo</h1><p>Hexo 依赖了 Node.js 和 Git，所以在安装 Hexo 之前必须确保安装了这两个工具.</p>
<h2 id="1-2-安装Node-js"><a href="#1-2-安装Node-js" class="headerlink" title="1.2 安装Node.js"></a>1.2 安装Node.js</h2><p>下载：<a href="https://link.zhihu.com/?target=https%3A//nodejs.org/en/download/">https://nodejs.org/en/download/</a></p>
<p>安装完</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node --version</span><br></pre></td></tr></table></figure>
<h2 id="1-3-安装git"><a href="#1-3-安装git" class="headerlink" title="1.3 安装git"></a>1.3 安装git</h2><p>下载：<a href="https://link.zhihu.com/?target=https%3A//git-scm.com/downloads">https://git-scm.com/downloads</a></p>
<p>安装完</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">git <span class="comment">--version</span></span><br></pre></td></tr></table></figure>
<h2 id="1-4-安装Hexo"><a href="#1-4-安装Hexo" class="headerlink" title="1.4 安装Hexo"></a>1.4 安装Hexo</h2><p>选择6.3.0版本<a href="https://www.npmjs.com/package/hexo/v/6.3.0">hexo - npm (npmjs.com)</a></p>
<p>install hexo</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">npm</span> i hexo@<span class="number">6</span>.<span class="number">3</span>.<span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>install 脚手架</p>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line">npm install hexo-<span class="keyword">cli</span> -g</span><br></pre></td></tr></table></figure>
<p>在F盘根目录打开bash</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">hexo <span class="keyword">init</span> blog</span><br></pre></td></tr></table></figure>
<p>开启服务</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line">hexo c <span class="variable">&amp;&amp;</span> hexo g <span class="variable">&amp;&amp;</span> hexo s</span><br></pre></td></tr></table></figure>
<h2 id="1-5-配置next主题"><a href="#1-5-配置next主题" class="headerlink" title="1.5 配置next主题"></a>1.5 配置next主题</h2><h3 id="1-主题-Gemini"><a href="#1-主题-Gemini" class="headerlink" title="1. 主题(Gemini)"></a>1. 主题(Gemini)</h3><p><strong>主题配置文件</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"># Schemes</span><br><span class="line"># scheme: Muse</span><br><span class="line"># scheme: Mist</span><br><span class="line"># scheme: Pisces</span><br><span class="line">scheme: Gemini</span><br></pre></td></tr></table></figure>
<h3 id="2-配置menu"><a href="#2-配置menu" class="headerlink" title="2. 配置menu"></a>2. 配置menu</h3><p><strong>站点配置文件</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"># Site</span><br><span class="line">title: 秦越人的博客</span><br><span class="line">subtitle: <span class="string">&#x27;Practice Tests Truth&#x27;</span></span><br><span class="line">description: <span class="string">&#x27;Welcome to my world&#x27;</span></span><br><span class="line">keywords:</span><br><span class="line">author: Qinyueren</span><br><span class="line">language: zh-CN</span><br><span class="line">timezone: <span class="string">&#x27;Asia&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>主题配置文件</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">menu</span>:</span><br><span class="line">  home: / || fa fa-home</span><br><span class="line">  about: /about/ || fa fa-user</span><br><span class="line">  tags: /tags/ || fa fa-tags</span><br><span class="line">  categories: /categories/ || fa fa-th</span><br><span class="line">  archives: /archives/ || fa fa-archive</span><br><span class="line">  #schedule: /schedule/ || fa fa-calendar</span><br><span class="line">  #sitemap: /sitemap.xml || fa fa-sitemap</span><br><span class="line">  #commonweal: /<span class="number">404</span>/ || fa fa-heartbeat</span><br><span class="line"></span><br><span class="line"># Enable / Disable menu icons / item badges.</span><br><span class="line">menu_settings:</span><br><span class="line">  icons: true</span><br><span class="line">  badges: false</span><br></pre></td></tr></table></figure>
<p><strong>样例</strong></p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240321175529789.png" alt="image-20240321175529789"></p>
<h3 id="3-配置看板娘"><a href="#3-配置看板娘" class="headerlink" title="3. 配置看板娘"></a>3. 配置看板娘</h3><p>安装插件</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">npm <span class="keyword">install</span> -save hexo-helper-live2d</span><br></pre></td></tr></table></figure>
<p><strong>站点配置文件</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">live2d:</span><br><span class="line">  enable: true</span><br><span class="line">  scriptFrom: local</span><br><span class="line">  pluginRootPath: live2dw/</span><br><span class="line">  pluginJsPath: lib/</span><br><span class="line">  pluginModelPath: assets/</span><br><span class="line">  tagMode: false</span><br><span class="line">  log: false</span><br><span class="line">  model:</span><br><span class="line">    use: live2d-widget-model-shizuku</span><br><span class="line">  display:</span><br><span class="line">    position: right</span><br><span class="line">    # width: <span class="number">150</span> # 大小根据模型结构自己调整合适的</span><br><span class="line">    # height: <span class="number">300</span></span><br><span class="line">  mobile:</span><br><span class="line">    show: true # 是否在手机端显示</span><br></pre></td></tr></table></figure>
<p>安装shizuku模型</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">npm <span class="keyword">install </span>live2d-widget-model-<span class="keyword">shizuku </span>--save</span><br></pre></td></tr></table></figure>
<p><strong>样例</strong></p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240321180000858.png" alt="image-20240321180000858"></p>
<h3 id="4-更换博客背景"><a href="#4-更换博客背景" class="headerlink" title="4. 更换博客背景"></a>4. 更换博客背景</h3><p>把准备好的背景图放入 <code>themes\hexo-theme-next\source\images</code> 中</p>
<p>新建 <code>hexo/source/_data/styles.styl</code></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">//背景图片设置</span><br><span class="line">body &#123;</span><br><span class="line">    background-image: url(/images/background.jpg);</span><br><span class="line">    background-repeat: no-repeat;</span><br><span class="line">    background-attachment: fixed;</span><br><span class="line">    background-size: 100% 100%;</span><br><span class="line">    //调整透明度</span><br><span class="line">    opacity: 0.85;</span><br><span class="line">    //可选</span><br><span class="line">    +mobile()&#123;</span><br><span class="line">      background-image: url(https://ziyuan.lruihao.cn/images/bg_cell.png);</span><br><span class="line">      background-size: cover;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="5-边框圆角"><a href="#5-边框圆角" class="headerlink" title="5. 边框圆角"></a>5. 边框圆角</h3><p>在之前新建的 <code>_data</code> 目录下新建 <code>variables.styl</code>，类似新建 <code>styles.styl</code>。打开 <code>variables.styl</code>，添加如下：</p>
<figure class="highlight gams"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 圆角设置</span></span><br><span class="line"><span class="meta"><span class="keyword">$border</span>-radius-inner     = 20px 20px 20px 20px;</span></span><br><span class="line"><span class="meta"><span class="keyword">$border</span>-radius           = 20px;</span></span><br></pre></td></tr></table></figure>
<p>打开 custom_file_path 中 variable 的注释</p>
<figure class="highlight gams"><table><tr><td class="code"><pre><span class="line">custom_file_path:</span><br><span class="line"></span><br><span class="line"><span class="keyword">variable</span>: source/_data/<span class="keyword">variables</span>.styl</span><br></pre></td></tr></table></figure>
<h3 id="6-美化归档栏和分类栏"><a href="#6-美化归档栏和分类栏" class="headerlink" title="6. 美化归档栏和分类栏"></a>6. 美化归档栏和分类栏</h3><p>在<code>blog/themes/next/layout/_macro/</code>下新建文件<code>post-collapse.swig</code>并复制一下内容</p>
<figure class="highlight django"><table><tr><td class="code"><pre><span class="line"><span class="template-tag">&#123;% <span class="name">macro</span> render(posts) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;%- <span class="name">set</span> current_year = &#x27;1970&#x27; %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="name">for</span></span> post <span class="keyword">in</span> posts.toArray() %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name">set</span> year = date(post.date, &#x27;YYYY&#x27;) %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> year !== current_year %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-tag">&#123;%- <span class="name">set</span> current_year = year %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;collection-year&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      &lt;</span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> theme.seo %&#125;</span><span class="language-xml">h2</span><span class="template-tag">&#123;% <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml">h1</span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"> class=&quot;collection-header&quot;&gt;</span><span class="template-variable">&#123;&#123; current_year &#125;&#125;</span><span class="language-xml">&lt;/</span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> theme.seo %&#125;</span><span class="language-xml">h2</span><span class="template-tag">&#123;% <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml">h1</span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml">&gt;</span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">article</span> <span class="attr">class</span>=<span class="string">&quot;my-post post-type-</span></span></span><span class="template-variable">&#123;&#123; post.type | default(&#x27;normal&#x27;) &#125;&#125;</span><span class="language-xml"><span class="tag"><span class="string">&quot;</span> <span class="attr">itemscope</span> <span class="attr">itemtype</span>=<span class="string">&quot;http://schema.org/Article&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">header</span> <span class="attr">class</span>=<span class="string">&quot;my-post-header&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;my-post-meta&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">time</span> <span class="attr">class</span>=<span class="string">&quot;my-post-time&quot;</span> <span class="attr">itemprop</span>=<span class="string">&quot;dateCreated&quot;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">              <span class="attr">datetime</span>=<span class="string">&quot;</span></span></span><span class="template-variable">&#123;&#123; moment(post.date).format() &#125;&#125;</span><span class="language-xml"><span class="tag"><span class="string">&quot;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">              <span class="attr">content</span>=<span class="string">&quot;</span></span></span><span class="template-variable">&#123;&#123; date(post.date, config.date_format) &#125;&#125;</span><span class="language-xml"><span class="tag"><span class="string">&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          </span><span class="template-variable">&#123;&#123; date(post.date, &#x27;MM-DD&#x27;) &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">time</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      &lt;</span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> theme.seo %&#125;</span><span class="language-xml">h3</span><span class="template-tag">&#123;% <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml">h2</span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"> class=&quot;my-post-title&quot;&gt;</span></span><br><span class="line"><span class="language-xml">        </span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> post.link %&#125;</span><span class="comment">&#123;# Link posts #&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;my-post-title-link post-title-link-external&quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span> <span class="attr">href</span>=<span class="string">&quot;</span></span></span><span class="template-variable">&#123;&#123; url_for(post.link) &#125;&#125;</span><span class="language-xml"><span class="tag"><span class="string">&quot;</span> <span class="attr">itemprop</span>=<span class="string">&quot;url&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            </span><span class="template-variable">&#123;&#123; post.title or post.link &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fa fa-external-link&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        </span><span class="template-tag">&#123;% <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;my-post-title-link&quot;</span> <span class="attr">href</span>=<span class="string">&quot;</span></span></span><span class="template-variable">&#123;&#123; url_for(post.path) &#125;&#125;</span><span class="language-xml"><span class="tag"><span class="string">&quot;</span> <span class="attr">itemprop</span>=<span class="string">&quot;url&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            </span><span class="template-tag">&#123;% <span class="name"><span class="name">if</span></span> post.type === &#x27;picture&#x27; %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              </span><span class="template-variable">&#123;&#123; post.content &#125;&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">            </span><span class="template-tag">&#123;% <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">              <span class="tag">&lt;<span class="name">span</span> <span class="attr">itemprop</span>=<span class="string">&quot;name&quot;</span>&gt;</span></span><span class="template-variable">&#123;&#123; post.title or __(&#x27;post.untitled&#x27;) &#125;&#125;</span><span class="language-xml"><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            </span><span class="template-tag">&#123;% <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">          <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        </span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">      &lt;/</span><span class="template-tag">&#123;%- <span class="name"><span class="name">if</span></span> theme.seo %&#125;</span><span class="language-xml">h3</span><span class="template-tag">&#123;% <span class="name"><span class="name">else</span></span> %&#125;</span><span class="language-xml">h2</span><span class="template-tag">&#123;%- <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml">&gt;</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">header</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">article</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="name">endfor</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="template-tag">&#123;% <span class="name">endmacro</span> %&#125;</span></span><br></pre></td></tr></table></figure>
<p>复制下面内容，粘贴到你所用主题的<code>index.styl</code>后面</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* 归档页样式 began */</span></span><br><span class="line"><span class="selector-class">.page-archive</span> <span class="selector-class">.archive-page-counter</span> &#123;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">18px</span>;</span><br><span class="line">  <span class="attribute">background-color</span>: <span class="number">#49b1f5</span>;</span><br><span class="line">  <span class="attribute">padding-left</span>: <span class="number">10px</span>;</span><br><span class="line">  <span class="attribute">padding-right</span>: <span class="number">10px</span>;</span><br><span class="line">  <span class="attribute">border-radius</span>: <span class="number">8px</span>;</span><br><span class="line">  <span class="attribute">color</span>: <span class="number">#fff</span>;</span><br><span class="line">  +mobile() &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">16px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.my-post-time</span>&#123;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">11px</span>;</span><br><span class="line">  <span class="attribute">position</span>: absolute;</span><br><span class="line">  <span class="attribute">color</span>: <span class="number">#fff</span>;</span><br><span class="line">  <span class="attribute">background-color</span>: <span class="number">#49b1f5</span>;</span><br><span class="line">  <span class="attribute">border-radius</span>: <span class="number">5px</span>;</span><br><span class="line">  <span class="attribute">padding-left</span>: <span class="number">5px</span>;</span><br><span class="line">  <span class="attribute">padding-right</span>: <span class="number">5px</span>;</span><br><span class="line">  <span class="attribute">margin-left</span>: <span class="number">15px</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.mypost</span>&#123;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">margin-bottom</span>: <span class="number">1rem</span>;</span><br><span class="line">  -webkit-<span class="attribute">transition</span>: all .<span class="number">2s</span> ease-in-out;</span><br><span class="line">  -moz-<span class="attribute">transition</span>: all .<span class="number">2s</span> ease-in-out;</span><br><span class="line">  -o-<span class="attribute">transition</span>: all .<span class="number">2s</span> ease-in-out;</span><br><span class="line">  -ms-<span class="attribute">transition</span>: all .<span class="number">2s</span> ease-in-out;</span><br><span class="line">  <span class="attribute">transition</span>: all .<span class="number">2s</span> ease-in-out;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">a</span><span class="selector-class">.my-post-title-link</span><span class="selector-pseudo">:before</span>&#123;</span><br><span class="line">  <span class="attribute">top</span>: <span class="number">10px</span>;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">18px</span>;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">18px</span>;</span><br><span class="line">  <span class="attribute">content</span>: <span class="string">&quot;📚&quot;</span>;</span><br><span class="line">  <span class="attribute">margin-right</span>: <span class="number">5px</span>;</span><br><span class="line">  <span class="attribute">font</span>: normal normal normal <span class="number">14px</span>/<span class="number">1</span> FontAwesome;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">15px</span>;</span><br><span class="line">  <span class="attribute">line-height</span>: <span class="number">18px</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.my-post</span><span class="selector-pseudo">:hover</span>&#123;</span><br><span class="line">  <span class="attribute">transform</span>: <span class="built_in">scale</span>(<span class="number">1.1</span>);</span><br><span class="line">  <span class="attribute">box-shadow</span>: <span class="number">10px</span> <span class="number">10px</span> <span class="number">15px</span> <span class="number">2px</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,.<span class="number">12</span>), <span class="number">0</span> <span class="number">0</span> <span class="number">6px</span> <span class="number">0</span> <span class="built_in">rgba</span>(<span class="number">104</span>, <span class="number">104</span>, <span class="number">105</span>, <span class="number">0.1</span>);</span><br><span class="line">  <span class="attribute">border-radius</span>: <span class="number">30px</span>;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">400px</span>;</span><br><span class="line">  <span class="attribute">padding</span>: <span class="number">1px</span> <span class="number">10px</span>;</span><br><span class="line">  <span class="attribute">margin-left</span>: <span class="number">25px</span>;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">16px</span>;</span><br><span class="line">  <span class="attribute">transition-duration</span>: <span class="number">0.15s</span>;</span><br><span class="line">  +mobile()&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">260px</span>;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">18px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  //<span class="attribute">display</span>:flex;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">a</span><span class="selector-class">.my-post-title-link</span>&#123;</span><br><span class="line">  <span class="attribute">text-decoration</span>: none;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">15px</span>;</span><br><span class="line">  <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">  +mobile() &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">14px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.my-post-title</span>&#123;</span><br><span class="line">  <span class="attribute">display</span>: block;</span><br><span class="line">  <span class="attribute">margin-left</span>: <span class="number">4.5rem</span>;</span><br><span class="line">  <span class="attribute">color</span>: <span class="number">#4c4948</span>;</span><br><span class="line">  <span class="attribute">text-decoration</span>: none;</span><br><span class="line">  <span class="attribute">font-size</span>: .<span class="number">8rem</span>;</span><br><span class="line">  <span class="attribute">cursor</span>: pointer;</span><br><span class="line">  +mobile() &#123;</span><br><span class="line">    //<span class="attribute">margin-left</span>: <span class="number">4rem</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.my-post-header</span>&#123;</span><br><span class="line">  <span class="attribute">position</span>: top;</span><br><span class="line">  <span class="attribute">margin-bottom</span>: <span class="number">1rem</span>;</span><br><span class="line">  -webkit-<span class="attribute">transition</span>: all .<span class="number">2s</span> ease-in-out;</span><br><span class="line">  -moz-<span class="attribute">transition</span>: all .<span class="number">2s</span> ease-in-out;</span><br><span class="line">  -o-<span class="attribute">transition</span>: all .<span class="number">2s</span> ease-in-out;</span><br><span class="line">  -ms-<span class="attribute">transition</span>: all .<span class="number">2s</span> ease-in-out;</span><br><span class="line">  <span class="attribute">transition</span>: all .<span class="number">2s</span> ease-in-out;</span><br><span class="line">&#125;</span><br><span class="line">//<span class="selector-class">.my-post-title-link</span>&#123;</span><br><span class="line">//  <span class="attribute">font-size</span>: <span class="number">16px</span>;</span><br><span class="line">//  <span class="attribute">font-weight</span>: <span class="number">500</span>;</span><br><span class="line">//&#125;</span><br><span class="line"><span class="selector-class">.my-post-meta</span>&#123;</span><br><span class="line">  <span class="attribute">position</span>: absolute;</span><br><span class="line">  <span class="attribute">color</span>: <span class="number">#99a9bf</span>;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">80px</span>;</span><br><span class="line">  <span class="attribute">color</span>: <span class="number">#114142</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">div</span><span class="selector-class">.post-block</span><span class="selector-class">.tag</span> <span class="selector-class">.collection-title</span> <span class="selector-tag">h2</span> &#123;</span><br><span class="line">  <span class="attribute">border-width</span>: <span class="number">1px</span>;</span><br><span class="line">  <span class="attribute">border-style</span>: solid;</span><br><span class="line">  <span class="attribute">border-color</span>: <span class="number">#3f3f3f</span>;</span><br><span class="line">  <span class="attribute">border-radius</span>: <span class="number">20px</span>;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">22px</span>;</span><br><span class="line">  <span class="attribute">background-color</span>: <span class="number">#b4e8fa</span>;</span><br><span class="line">  <span class="attribute">padding</span>: <span class="number">2px</span> <span class="number">15px</span>;</span><br><span class="line">  <span class="attribute">letter-spacing</span>: <span class="number">1.5px</span>;</span><br><span class="line">  <span class="attribute">box-sizing</span>: border-box;</span><br><span class="line">  <span class="attribute">color</span>: <span class="number">#3f3f3f</span>;</span><br><span class="line">  <span class="attribute">display</span>: inline-block;</span><br><span class="line">  <span class="attribute">margin</span>: <span class="number">10px</span> <span class="number">0</span> <span class="number">10px</span>;</span><br><span class="line">  <span class="attribute">text-align</span>: center;</span><br><span class="line">  +mobile()&#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">18px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* 归档页样式 end */</span></span><br></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* 分类页样式 began */</span></span><br><span class="line"><span class="selector-class">.category-list-link</span><span class="selector-pseudo">:hover</span>&#123;</span><br><span class="line">  <span class="attribute">transform</span>: <span class="built_in">scale</span>(<span class="number">1.1</span>);</span><br><span class="line">  <span class="attribute">box-shadow</span>: <span class="number">10px</span> <span class="number">10px</span> <span class="number">15px</span> <span class="number">2px</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,.<span class="number">12</span>), <span class="number">0</span> <span class="number">0</span> <span class="number">6px</span> <span class="number">0</span> <span class="built_in">rgba</span>(<span class="number">104</span>, <span class="number">104</span>, <span class="number">105</span>, <span class="number">0.1</span>);</span><br><span class="line">  <span class="attribute">border-radius</span>: <span class="number">15px</span>;</span><br><span class="line">  <span class="attribute">padding</span>: <span class="number">6px</span> <span class="number">16px</span>;</span><br><span class="line">  <span class="attribute">margin-left</span>: <span class="number">0px</span>;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">16px</span>;</span><br><span class="line">  <span class="attribute">transition-duration</span>: <span class="number">0.15s</span>;</span><br><span class="line">  //<span class="attribute">display</span>:flex;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">a</span><span class="selector-class">.category-list-link</span><span class="selector-pseudo">:before</span>&#123;</span><br><span class="line">  <span class="attribute">top</span>: <span class="number">10px</span>;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">18px</span>;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">18px</span>;</span><br><span class="line">  <span class="attribute">content</span>: <span class="string">&quot;📚&quot;</span>;</span><br><span class="line">  <span class="attribute">margin-right</span>: <span class="number">5px</span>;</span><br><span class="line">  <span class="attribute">font</span>: normal normal normal <span class="number">14px</span>/<span class="number">1</span> FontAwesome;</span><br><span class="line">  <span class="attribute">font-size</span>: <span class="number">15px</span>;</span><br><span class="line">  <span class="attribute">line-height</span>: <span class="number">18px</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* 分类页样式 end */</span></span><br></pre></td></tr></table></figure>
<h3 id="7-代码块Mac风"><a href="#7-代码块Mac风" class="headerlink" title="7. 代码块Mac风"></a>7. 代码块Mac风</h3><p><strong>站点配置</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">highlight:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment">#是否开启代码高亮</span></span><br><span class="line">  <span class="attr">line_number:</span> <span class="literal">true</span> <span class="comment">#是否增加代码行号</span></span><br><span class="line">  <span class="attr">auto_detect:</span> <span class="literal">true</span> <span class="comment">#自动判断代码语言</span></span><br><span class="line">  <span class="attr">tab_replace:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">wrap:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hljs:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">prismjs:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">preprocess:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">line_number:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">tab_replace:</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>主题配置</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">codeblock:</span></span><br><span class="line">  <span class="comment"># Code Highlight theme</span></span><br><span class="line">  <span class="comment"># All available themes: https://theme-next.js.org/highlight/</span></span><br><span class="line">  <span class="attr">theme:</span></span><br><span class="line">    <span class="comment"># light: github-dark</span></span><br><span class="line">    <span class="attr">light:</span> <span class="string">github-dark</span></span><br><span class="line">    <span class="attr">dark:</span> <span class="string">github-dark</span></span><br><span class="line">  <span class="attr">prism:</span></span><br><span class="line">    <span class="attr">light:</span> <span class="string">prism</span></span><br><span class="line">    <span class="attr">dark:</span> <span class="string">prism-dark</span></span><br><span class="line">  <span class="comment"># Add copy button on codeblock</span></span><br><span class="line">  <span class="attr">copy_button:</span> <span class="comment"># 一键复制</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># Available values: default | flat | mac</span></span><br><span class="line">    <span class="attr">style:</span> <span class="string">mac</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="8-设置阅读全文"><a href="#8-设置阅读全文" class="headerlink" title="8. 设置阅读全文"></a>8. 设置阅读全文</h3><p>执行</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">npm install hexo-excerpt <span class="comment">--save</span></span><br></pre></td></tr></table></figure>
<p><strong>站点</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">excerpt:</span>			<span class="comment"># 一定要顶格写，注意格式</span></span><br><span class="line">  <span class="attr">depth:</span> <span class="number">5</span>			<span class="comment"># 他的大小就是全文阅读预览长度设置</span></span><br><span class="line">  <span class="attr">excerpt_excludes:</span> []</span><br><span class="line">  <span class="attr">more_excludes:</span> []</span><br><span class="line">  <span class="attr">hideWholePostExcerpts:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p><strong>主题</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Automatically excerpt description in homepage as preamble text.</span></span><br><span class="line"><span class="attr">excerpt_description:</span> <span class="literal">true</span>		<span class="comment"># 一般默认为true</span></span><br></pre></td></tr></table></figure>
<h3 id="9-增加文章字数统计和阅读时长"><a href="#9-增加文章字数统计和阅读时长" class="headerlink" title="9. 增加文章字数统计和阅读时长"></a>9. 增加文章字数统计和阅读时长</h3><p>执行</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">npm install hexo-<span class="built_in">word</span>-counter</span><br></pre></td></tr></table></figure>
<p><strong>站点</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 增加文章字数统计及阅读时长功能</span></span><br><span class="line"><span class="attr">symbols_count_time:</span></span><br><span class="line">  <span class="attr">symbols:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">time:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">total_symbols:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">total_time:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">exclude_codeblock:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">wpm:</span> <span class="number">275</span></span><br><span class="line">  <span class="attr">suffix:</span> <span class="string">&quot;mins.&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="10-文章结束标志"><a href="#10-文章结束标志" class="headerlink" title="10. 文章结束标志"></a>10. 文章结束标志</h3><p>在路径 <code>\themes\next\layout\_macro</code> 中新建 <code>passage-end-tag.swig</code> 文件,并添加以下内容</p>
<figure class="highlight django"><table><tr><td class="code"><pre><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-tag">&#123;% <span class="name"><span class="name">if</span></span> not is_index %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">&quot;text-align:center;color: #ccc;font-size:14px;&quot;</span>&gt;</span>-------------已经到底啦！<span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fa fa-paw&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span>-------------<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-tag">&#123;% <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br></pre></td></tr></table></figure>
<p>打开 <code>\themes\next\layout\_macro\post.njk</code> 文件，在post-body 之后(END POST BODY)，post-footer 之前添加以下代码：</p>
<figure class="highlight django"><table><tr><td class="code"><pre><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;% <span class="name"><span class="name">if</span></span> not is_index %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    </span><span class="template-tag">&#123;% <span class="name"><span class="name">include</span></span> &#x27;passage-end-tag.swig&#x27; %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  </span><span class="template-tag">&#123;% <span class="name"><span class="name">endif</span></span> %&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br></pre></td></tr></table></figure>
<h3 id="11-分类设置"><a href="#11-分类设置" class="headerlink" title="11. 分类设置"></a>11. 分类设置</h3><p>在文章上头</p>
<p><strong>单层</strong></p>
<figure class="highlight ldif"><table><tr><td class="code"><pre><span class="line"><span class="attribute">categories</span>:</span><br><span class="line"><span class="literal">-</span> Hexo 博客</span><br></pre></td></tr></table></figure>
<p><strong>父子</strong></p>
<figure class="highlight ldif"><table><tr><td class="code"><pre><span class="line"><span class="attribute">categories</span>:</span><br><span class="line"><span class="literal">-</span> 前端</span><br><span class="line"><span class="literal">-</span> 笔记</span><br></pre></td></tr></table></figure>
<p><strong>并列</strong></p>
<figure class="highlight ldif"><table><tr><td class="code"><pre><span class="line"><span class="attribute">categories</span>:</span><br><span class="line"><span class="literal">-</span> [后端]</span><br><span class="line"><span class="literal">-</span> [笔记]</span><br></pre></td></tr></table></figure>
<p><strong>同一父类不同子类</strong></p>
<figure class="highlight ldif"><table><tr><td class="code"><pre><span class="line"><span class="attribute">categories</span>:</span><br><span class="line"><span class="literal">-</span> [学习,html]</span><br><span class="line"><span class="literal">-</span> [学习,http]</span><br></pre></td></tr></table></figure>
<h3 id="12-分类问题"><a href="#12-分类问题" class="headerlink" title="12. 分类问题"></a>12. 分类问题</h3><p>原因：</p>
<p>原因是因为我把_config.yml中的时区timezone改成了2020-5-1（笑死）</p>
<p>解决办法：</p>
<p>把timezone改成 Asia/Shanghai 就好了。</p>
<h3 id="13-删除分类"><a href="#13-删除分类" class="headerlink" title="13. 删除分类"></a>13. 删除分类</h3><figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">rm</span> -rf <span class="keyword">db</span>.json</span><br><span class="line"></span><br><span class="line">hexo clean</span><br><span class="line"></span><br><span class="line">hexo <span class="keyword">g</span></span><br><span class="line"></span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>
<h3 id="14-侧边栏滚动条"><a href="#14-侧边栏滚动条" class="headerlink" title="14. 侧边栏滚动条"></a>14. 侧边栏滚动条</h3><figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">/<span class="strong">*更好的侧边滚动条*</span>/</span><br><span class="line">::-webkit-scrollbar &#123;</span><br><span class="line"><span class="code">  width: 10px;</span></span><br><span class="line"><span class="code">  height: 10px;</span></span><br><span class="line">&#125;</span><br><span class="line">::-webkit-scrollbar-button &#123;</span><br><span class="line"><span class="code">  width: 0;</span></span><br><span class="line"><span class="code">  height: 0;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">::-webkit-scrollbar-button:start:increment,::-webkit-scrollbar-button:end:decrement</span> &#123;</span><br><span class="line"><span class="code">  display: none;</span></span><br><span class="line">&#125;</span><br><span class="line">::-webkit-scrollbar-corner &#123;</span><br><span class="line"><span class="code">  display: block;</span></span><br><span class="line">&#125;</span><br><span class="line">::-webkit-scrollbar-thumb &#123;</span><br><span class="line"><span class="code">  border-radius: 8px;</span></span><br><span class="line"><span class="code">  background-color: rgba(0,0,0,.2);</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">::-webkit-scrollbar-thumb:hover</span> &#123;</span><br><span class="line"><span class="code">  border-radius: 8px;</span></span><br><span class="line"><span class="code">  background-color: rgba(0,0,0,.5);</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">::-webkit-scrollbar-track,::-webkit-scrollbar-thumb</span> &#123;</span><br><span class="line"><span class="code">  border-right: 1px solid transparent;</span></span><br><span class="line"><span class="code">  border-left: 1px solid transparent;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">::-webkit-scrollbar-track:hover</span> &#123;</span><br><span class="line"><span class="code">  background-color: rgba(0,0,0,.15);</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">::-webkit-scrollbar-button:start</span> &#123;</span><br><span class="line"><span class="code">  width: 10px;</span></span><br><span class="line"><span class="code">  height: 10px;</span></span><br><span class="line"><span class="code">  /*background: url(../images/scrollbar_arrow.png) no-repeat 0 0;*/  /*可以添加滚动条样式*/</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="15-回到顶部按钮"><a href="#15-回到顶部按钮" class="headerlink" title="15. 回到顶部按钮"></a>15. 回到顶部按钮</h3><ul>
<li>在themes/*/_config.yml中搜索back2top，将enable属性的false改为true即可：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">back2top:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Back to top in sidebar.</span></span><br><span class="line">  <span class="attr">sidebar:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Scroll percent label in b2t button.</span></span><br><span class="line">  <span class="attr">scrollpercent:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h3 id="16-阅读进度条"><a href="#16-阅读进度条" class="headerlink" title="16. 阅读进度条"></a>16. 阅读进度条</h3><ul>
<li>在themes/*/_config.yml中搜索reading_progress，修改相关信息：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Reading progress bar</span></span><br><span class="line"><span class="attr">reading_progress:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Available values: top | bottom</span></span><br><span class="line">  <span class="attr">position:</span> <span class="string">top</span>        <span class="comment"># 进度条在页面中显示的位置：顶部/底部</span></span><br><span class="line">  <span class="attr">color:</span> <span class="string">&quot;#37c6c0&quot;</span>     <span class="comment"># 进度条颜色</span></span><br><span class="line">  <span class="attr">height:</span> <span class="string">3px</span>          <span class="comment"># 进度条宽度</span></span><br></pre></td></tr></table></figure>
<h1 id="2-git-配置"><a href="#2-git-配置" class="headerlink" title="2. git 配置"></a>2. git 配置</h1><p><strong>站点文件</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Site</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">秦越人的博客</span></span><br><span class="line"><span class="attr">subtitle:</span> <span class="string">&#x27;Practice Tests Truth&#x27;</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">&#x27;Welcome to my world&#x27;</span></span><br><span class="line"><span class="attr">keywords:</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">Qinyueren</span></span><br><span class="line"><span class="attr">language:</span> <span class="string">zh-CN</span></span><br><span class="line"><span class="attr">timezone:</span> <span class="string">&#x27;Asia/Shanghai&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># URL</span></span><br><span class="line"><span class="comment">## Set your site url here. For example, if you use GitHub Page, set url as &#x27;https://username.github.io/project&#x27;</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">http://qinyueren.gitee.io</span></span><br><span class="line"><span class="attr">root:</span> <span class="string">/learn_blog/</span></span><br><span class="line"><span class="attr">permalink:</span> <span class="string">:year/:month/:day/:title/</span></span><br><span class="line"><span class="attr">permalink_defaults:</span></span><br><span class="line"><span class="attr">pretty_urls:</span></span><br><span class="line">  <span class="attr">trailing_index:</span> <span class="literal">true</span> <span class="comment"># Set to false to remove trailing &#x27;index.html&#x27; from permalinks</span></span><br><span class="line">  <span class="attr">trailing_html:</span> <span class="literal">true</span> <span class="comment"># Set to false to remove trailing &#x27;.html&#x27; from permalinks</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">&#x27;git&#x27;</span></span><br><span class="line">  <span class="attr">repo:</span>  <span class="string">https://gitee.com/qinyueren/learn_blog.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># Extensions</span></span><br><span class="line"><span class="comment">## Plugins: https://hexo.io/plugins/</span></span><br><span class="line"><span class="comment">## Themes: https://hexo.io/themes/</span></span><br><span class="line"><span class="attr">theme:</span> <span class="string">hexo-theme-next</span></span><br></pre></td></tr></table></figure>
<h1 id="3-设置图床"><a href="#3-设置图床" class="headerlink" title="3. 设置图床"></a>3. 设置图床</h1><h2 id="3-1-安装Picgo"><a href="#3-1-安装Picgo" class="headerlink" title="3.1 安装Picgo"></a>3.1 安装Picgo</h2><p>下载picgo安装包</p>
<p><a href="https://[github](https://so.csdn.net/so/search?q=github&amp;spm=1001.2101.3001.7020).com/Molunerfinn/PicGo/releases">https://[github](https://so.csdn.net/so/search?q=github&amp;spm=1001.2101.3001.7020).com/Molunerfinn/PicGo/releases</a></p>
<p>在picgo界面</p>
<p>安装gitee-uploader插件</p>
<h2 id="3-2-新建图床库"><a href="#3-2-新建图床库" class="headerlink" title="3.2 新建图床库"></a>3.2 新建图床库</h2><p>gitee新建仓库</p>
<ul>
<li>输入仓库名称</li>
<li>仓库设置公开</li>
<li>勾选使用Readme文件初始化仓库（会自动插件master分支</li>
</ul>
<h2 id="3-3-配置picgo"><a href="#3-3-配置picgo" class="headerlink" title="3.3 配置picgo"></a>3.3 配置picgo</h2><ul>
<li>repo: 用户名/仓库名</li>
<li>branch: master</li>
<li>token: 私人令牌</li>
</ul>
<h2 id="3-4-typroa配置Picgo"><a href="#3-4-typroa配置Picgo" class="headerlink" title="3.4 typroa配置Picgo"></a>3.4 typroa配置Picgo</h2><p>文件–&gt;偏好设置–&gt;图像-》上传图片，对网络位置应用上述规则</p>
<p>设置picgo路径，并验证</p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>网站搭建</category>
      </categories>
  </entry>
  <entry>
    <title>法系机制</title>
    <url>/2024/03/22/%E6%B3%95%E7%B3%BB%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h1 id="1-门派的分灵机制"><a href="#1-门派的分灵机制" class="headerlink" title="1. 门派的分灵机制"></a>1. 门派的分灵机制</h1><h2 id="1-1-作用目标影响分灵系数"><a href="#1-1-作用目标影响分灵系数" class="headerlink" title="1.1 作用目标影响分灵系数"></a>1.1 作用目标影响分灵系数</h2><ol>
<li>当作用目标≤3时，分灵系数为$1-N\times0.1$，其中N为目标人数</li>
<li>当作用目标=4时，初始目标(3个)分灵系数为70%，额外目标分灵系数为60%</li>
<li>当作用目标≥5时，初始目标(3个)分灵系数为70%，额外目标分灵系数为$0.7-N\times0.05$</li>
<li>分灵系数最低为0.5，最高为1</li>
</ol>
<h2 id="1-2-魔王神木分灵系数"><a href="#1-2-魔王神木分灵系数" class="headerlink" title="1.2 魔王神木分灵系数"></a>1.2 魔王神木分灵系数</h2><p>根据实际输出的数据来看，秒5分灵系数从1~5分别是</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.9</td>
<td>0.8</td>
<td>0.7</td>
<td>0.6</td>
<td>0.6</td>
</tr>
</tbody>
</table>
</div>
<h2 id="1-3-龙宫化生寺分灵系数"><a href="#1-3-龙宫化生寺分灵系数" class="headerlink" title="1.3 龙宫化生寺分灵系数"></a>1.3 龙宫化生寺分灵系数</h2><p>根据实际输出的数据来看，秒7分灵系数从1~7分别是</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.9</td>
<td>0.8</td>
<td>0.7</td>
<td>0.6</td>
<td>0.5</td>
<td>0.5</td>
<td>0.5</td>
</tr>
</tbody>
</table>
</div>
<h2 id="1-4-天雷灌注天宫"><a href="#1-4-天雷灌注天宫" class="headerlink" title="1.4 天雷灌注天宫"></a>1.4 天雷灌注天宫</h2><p>待整理</p>
<h2 id="1-5-五雷咒方寸"><a href="#1-5-五雷咒方寸" class="headerlink" title="1.5 五雷咒方寸"></a>1.5 五雷咒方寸</h2><p>待整理</p>
<h2 id="1-6-女魃墓"><a href="#1-6-女魃墓" class="headerlink" title="1.6 女魃墓"></a>1.6 女魃墓</h2><p>待整理</p>
<h1 id="2-灵饰法伤与法结对比"><a href="#2-灵饰法伤与法结对比" class="headerlink" title="2. 灵饰法伤与法结对比"></a>2. 灵饰法伤与法结对比</h1><p>法术计算公式：</p>
<script type="math/tex; mode=display">
法术伤害=1\times分灵系数\times(1+魔心卡+修炼加成+天阵加成)</script><h2 id="2-1-无暴击下"><a href="#2-1-无暴击下" class="headerlink" title="2.1 无暴击下"></a>2.1 无暴击下</h2><div class="table-container">
<table>
<thead>
<tr>
<th>1法伤</th>
<th>分灵</th>
<th>修炼</th>
<th>天阵</th>
<th>低魔心</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>0.9</td>
<td>20%</td>
<td>25%</td>
<td>10%</td>
<td>1.395</td>
</tr>
<tr>
<td></td>
<td>0.8</td>
<td>20%</td>
<td>25%</td>
<td>10%</td>
<td>1.24</td>
</tr>
<tr>
<td></td>
<td>0.7</td>
<td>20%</td>
<td>25%</td>
<td>10%</td>
<td>1.085</td>
</tr>
<tr>
<td></td>
<td>0.6</td>
<td>20%</td>
<td>25%</td>
<td>10%</td>
<td>0.93</td>
</tr>
<tr>
<td></td>
<td>0.5</td>
<td>20%</td>
<td>25%</td>
<td>10%</td>
<td>0.775</td>
</tr>
<tr>
<td><strong>1法结</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>1.0</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>灵饰4段下，初始值为10<ul>
<li>法伤10+4*4=26</li>
<li>法结10+3*4=22</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>法伤26</th>
<th>分灵</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>0.9</td>
<td>36.27</td>
</tr>
<tr>
<td></td>
<td>0.8</td>
<td>32.24</td>
</tr>
<tr>
<td></td>
<td>0.7</td>
<td>28.21</td>
</tr>
<tr>
<td></td>
<td>0.6</td>
<td>24.18</td>
</tr>
<tr>
<td></td>
<td>0.5</td>
<td>20.15</td>
</tr>
<tr>
<td><strong>法结22</strong></td>
<td></td>
<td>22</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-2-暴击下"><a href="#2-2-暴击下" class="headerlink" title="2.2 暴击下"></a>2.2 暴击下</h2><div class="table-container">
<table>
<thead>
<tr>
<th>1法伤</th>
<th>分灵</th>
<th>修炼</th>
<th>天阵</th>
<th>低魔心</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>0.9</td>
<td>20%</td>
<td>25%</td>
<td>10%</td>
<td>2.79</td>
</tr>
<tr>
<td></td>
<td>0.8</td>
<td>20%</td>
<td>25%</td>
<td>10%</td>
<td>2.48</td>
</tr>
<tr>
<td></td>
<td>0.7</td>
<td>20%</td>
<td>25%</td>
<td>10%</td>
<td>2.17</td>
</tr>
<tr>
<td></td>
<td>0.6</td>
<td>20%</td>
<td>25%</td>
<td>10%</td>
<td>1.86</td>
</tr>
<tr>
<td></td>
<td>0.5</td>
<td>20%</td>
<td>25%</td>
<td>10%</td>
<td>1.5</td>
</tr>
<tr>
<td><strong>1法结</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>2.0</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>灵饰4段下，初始值为10<ul>
<li>法伤10+4*4=26</li>
<li>法结10+3*4=22</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>法伤26</th>
<th>分灵</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>0.9</td>
<td>72.54</td>
</tr>
<tr>
<td></td>
<td>0.8</td>
<td>64.48</td>
</tr>
<tr>
<td></td>
<td>0.7</td>
<td>56.42</td>
</tr>
<tr>
<td></td>
<td>0.6</td>
<td>48.36</td>
</tr>
<tr>
<td></td>
<td>0.5</td>
<td>39</td>
</tr>
<tr>
<td><strong>法结22</strong></td>
<td></td>
<td>44</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>游戏</category>
        <category>梦幻西游</category>
      </categories>
  </entry>
  <entry>
    <title>Deepfake Detection All model 一览</title>
    <url>/2024/03/22/%E6%89%80%E6%9C%89%E6%A8%A1%E5%9E%8B%E4%B8%80%E8%A7%88/</url>
    <content><![CDATA[<h1 id="Deep-Learing-深度学习"><a href="#Deep-Learing-深度学习" class="headerlink" title="Deep Learing(深度学习)"></a>Deep Learing(深度学习)</h1><h2 id="CNN-卷积神经网络"><a href="#CNN-卷积神经网络" class="headerlink" title="CNN(卷积神经网络)"></a>CNN(卷积神经网络)</h2><ul>
<li>XceptionNet</li>
<li>VGG</li>
<li>ResNet</li>
<li>GoogleNet</li>
<li>InceptionV3</li>
<li>MoblieNet</li>
<li>IncepResNet</li>
<li>EfficientNet</li>
<li>DenseNet</li>
<li>HRNet</li>
<li>SuppressNet</li>
<li>StatsNet</li>
<li>DEL</li>
</ul>
<h2 id="RNN-循环神经网络"><a href="#RNN-循环神经网络" class="headerlink" title="RNN(循环神经网络)"></a>RNN(循环神经网络)</h2><ul>
<li>LSTM</li>
<li>FaceNet</li>
<li>Bio Directional RNN</li>
<li>RCNN(区域卷积神经网络)</li>
<li>Faster RCNN</li>
<li>Long-term RCNN</li>
<li>HMN</li>
<li>MTCNN(多任务级联CNN)</li>
<li>MSCNN(多尺度时间CNN)</li>
</ul>
<h1 id="Machine-Learning-机器学习"><a href="#Machine-Learning-机器学习" class="headerlink" title="Machine Learning(机器学习)"></a>Machine Learning(机器学习)</h1><ul>
<li>SVM(支持向量机)</li>
<li>LR(逻辑回归)</li>
<li>MLP(多层感知器神经网络)</li>
<li>k-MN(k表示聚类)</li>
<li>KNN(k-最近邻居)</li>
<li>MIL</li>
<li>DA(判别分析)</li>
<li>NB(朴素贝叶斯)</li>
<li>RF</li>
<li>DT(决策树)</li>
<li>BOOST<ul>
<li>XGB</li>
<li>AdaBoost</li>
</ul>
</li>
</ul>
<h1 id="Statistical"><a href="#Statistical" class="headerlink" title="Statistical"></a>Statistical</h1><ul>
<li>EM(期望最大化)</li>
<li>CRA(协同关系分析)</li>
<li>EA</li>
<li>PI</li>
<li>WM</li>
<li>KLD</li>
<li>TVD</li>
<li>JSD</li>
</ul>
<h1 id="BC区块链"><a href="#BC区块链" class="headerlink" title="BC区块链"></a>BC区块链</h1><p>ETH(以太坊区块链)</p>
<h1 id="Feature"><a href="#Feature" class="headerlink" title="Feature"></a>Feature</h1><ul>
<li>SA：特殊伪像，</li>
<li>VA：视觉伪像，</li>
<li>BA：生物伪影，</li>
<li>FL：人脸标志，</li>
<li>STC：时空一致性，</li>
<li>TEX：纹理，</li>
<li>FDA：频域分析，</li>
<li>LS：潜在特征，</li>
<li>GAN：基于生成对抗性网络的特征，</li>
<li>MES：介观特征，</li>
<li>IFC：帧内不一致，</li>
<li>CPRNU：Constrastive and photo-responsed PRNU pattern，</li>
<li>IMG：图像元数据，增强和隐写分析，其他：不在通用列表中的不同特征</li>
</ul>
<h1 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h1><ul>
<li>FF:FaceForensics，</li>
<li>DFD:Deepfake Detection，</li>
<li>CELEB-A：Deepfake Forensics V1，</li>
<li>CELEB-DF:DDeepFake-Forensics V2，</li>
<li>DFDC:Depfake Detection Chalange，</li>
<li>DF-TIMIT:Depfake-TIMIT，</li>
<li>DF-1.0:DeperForensics-1.0，</li>
<li>WDF:Wild Deepfake，</li>
<li>SMFW:SwapMe和FaceSwap，</li>
<li>DFS:Deep Fakes，</li>
<li>FFD:野生中的假脸，</li>
<li>FE:FakeET，</li>
<li>FS:换脸器，</li>
<li>DF:DepFake，</li>
<li>SFD:换脸检测，</li>
<li>UADFV:不一致的头部姿势，</li>
<li>MANFA：篡改的脸，</li>
<li>其他：作者的自定义数据集</li>
</ul>
<h1 id="Focus"><a href="#Focus" class="headerlink" title="Focus"></a>Focus</h1><p>DMF：数字媒体取证，FM：面部操纵</p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>清点资源</title>
    <url>/2024/03/22/%E6%B8%85%E7%82%B9%E8%B5%84%E6%BA%90/</url>
    <content><![CDATA[<h1 id="清点资源"><a href="#清点资源" class="headerlink" title="清点资源"></a>清点资源</h1><h2 id="人物情况"><a href="#人物情况" class="headerlink" title="人物情况"></a>人物情况</h2><h3 id="等级与经验"><a href="#等级与经验" class="headerlink" title="等级与经验"></a>等级与经验</h3><p>总经验25 E</p>
<p>等级：144</p>
<p>目前经验4000万</p>
<h3 id="师门技能"><a href="#师门技能" class="headerlink" title="师门技能"></a>师门技能</h3><p>4个130级，3个99级</p>
<h3 id="人物修炼"><a href="#人物修炼" class="headerlink" title="人物修炼"></a>人物修炼</h3><p>3修12</p>
<h3 id="潜能果"><a href="#潜能果" class="headerlink" title="潜能果"></a>潜能果</h3><p>29个</p>
<h2 id="宝宝情况"><a href="#宝宝情况" class="headerlink" title="宝宝情况"></a>宝宝情况</h2><h3 id="宠修"><a href="#宠修" class="headerlink" title="宠修"></a>宠修</h3><p>三修4</p>
<h2 id="每月产出储备金"><a href="#每月产出储备金" class="headerlink" title="每月产出储备金"></a>每月产出储备金</h2><p>庭院500</p>
<p>牧场500</p>
<p>押镖420</p>
<p>师徒300</p>
<p>口袋1200</p>
<p>总计 500+500+420+300+1200=2920 万</p>
<h2 id="每周产出经验"><a href="#每周产出经验" class="headerlink" title="每周产出经验"></a>每周产出经验</h2><p>1-5星期：1000*5=5000万</p>
<p>6-7星期：2000+1000=3000万</p>
<p>共 8000万</p>
<h1 id="145未飞升"><a href="#145未飞升" class="headerlink" title="145未飞升"></a>145未飞升</h1><h2 id="师门技能-1"><a href="#师门技能-1" class="headerlink" title="师门技能"></a>师门技能</h2><p>2个99级升至130：1414*2=2828万</p>
<p>2个130级升至140：826*2=1632万（可以飞升后处理）</p>
<p>共 2828+1632=4460万</p>
<h2 id="人物修炼-1"><a href="#人物修炼-1" class="headerlink" title="人物修炼"></a>人物修炼</h2><p>3修12至3修13</p>
<p>438*2=876万</p>
<p>657万(师徒抵消一半)328</p>
<p>共876+328=1204万</p>
<p>帮贡达到1950</p>
<h2 id="辅助技能"><a href="#辅助技能" class="headerlink" title="辅助技能"></a>辅助技能</h2><p>家具75升至100：2700-2200</p>
<h2 id="潜能果-1"><a href="#潜能果-1" class="headerlink" title="潜能果"></a>潜能果</h2><p>转门派扣除：26个</p>
<h2 id="计算时间"><a href="#计算时间" class="headerlink" title="计算时间"></a>计算时间</h2><p>最低储备金：2828+1204=2952万（一个月时间）</p>
<p>一个月获得经验4*8000=3.5 E，则潜能果29个吃到50个</p>
<p>潜能果还剩下24个</p>
<h1 id="飞升130-140疲软期"><a href="#飞升130-140疲软期" class="headerlink" title="飞升130-140疲软期"></a>飞升130-140疲软期</h1><h2 id="人物经验"><a href="#人物经验" class="headerlink" title="人物经验"></a>人物经验</h2><p>1.6E 2周时间</p>
<h1 id="飞升140-145"><a href="#飞升140-145" class="headerlink" title="飞升140-145"></a>飞升140-145</h1><h2 id="140升145"><a href="#140升145" class="headerlink" title="140升145"></a>140升145</h2><p>共1E经验</p>
<h2 id="145级囤经验"><a href="#145级囤经验" class="headerlink" title="145级囤经验"></a>145级囤经验</h2><p>145升146需要4363万</p>
<p>师门上限为4.3E经验</p>
<h2 id="所需时间"><a href="#所需时间" class="headerlink" title="所需时间"></a>所需时间</h2><p>1+4.3=5.3E经验，需要2个月时间</p>
<h2 id="人物修炼-2"><a href="#人物修炼-2" class="headerlink" title="人物修炼"></a>人物修炼</h2><p>2个月，储备金为2902*2=5804万</p>
<p>双防12-15需1498*2=2996万</p>
<p>法修13-16需要2535万</p>
<h1 id="冲击155级"><a href="#冲击155级" class="headerlink" title="冲击155级"></a>冲击155级</h1><h2 id="145-152级"><a href="#145-152级" class="headerlink" title="145-152级"></a>145-152级</h2><p>消耗经验3.8E，还剩下4.3-3.8=0.5E</p>
<h2 id="152-155级"><a href="#152-155级" class="headerlink" title="152-155级"></a>152-155级</h2><p>消耗经验2.4E，一个月时间</p>
<h2 id="人修"><a href="#人修" class="headerlink" title="人修"></a>人修</h2><p>双抗15-17 需要 1332*2=2664万</p>
<p>法修16-17 需要 1053/2=527万</p>
<p>三修17 51修，已经达到渡劫人修要求</p>
<h1 id="冲击渡劫"><a href="#冲击渡劫" class="headerlink" title="冲击渡劫"></a>冲击渡劫</h1><h2 id="宠修-1"><a href="#宠修-1" class="headerlink" title="宠修"></a>宠修</h2><h3 id="不跑宠环和吃果子"><a href="#不跑宠环和吃果子" class="headerlink" title="不跑宠环和吃果子"></a>不跑宠环和吃果子</h3><p>每个月6000经验，需要4个月，达到4修10</p>
<h2 id="4个月储备金"><a href="#4个月储备金" class="headerlink" title="4个月储备金"></a>4个月储备金</h2><p>4*3000=1.2E</p>
<h2 id="师门技能-2"><a href="#师门技能-2" class="headerlink" title="师门技能"></a>师门技能</h2><p>3个130升至150，2个140升至150</p>
<p>1910*3+2168=7898万，还剩下4100万</p>
<h1 id="渡劫159收尾"><a href="#渡劫159收尾" class="headerlink" title="渡劫159收尾"></a>渡劫159收尾</h1><h2 id="155-159"><a href="#155-159" class="headerlink" title="155-159"></a>155-159</h2><p>3.5E，共一个月</p>
<h2 id="人修-1"><a href="#人修-1" class="headerlink" title="人修"></a>人修</h2><p>三修18需要 778*2+1167/2=2140万</p>
<h1 id="总计时间"><a href="#总计时间" class="headerlink" title="总计时间"></a>总计时间</h1><p>三个月到达155，四个月渡劫，收尾一个月</p>
<p>共8个月</p>
<p>暑期前155级，过年前渡劫成功</p>
]]></content>
      <categories>
        <category>游戏</category>
        <category>梦幻西游</category>
      </categories>
  </entry>
  <entry>
    <title>SelfBlendedImages论文精读</title>
    <url>/2024/03/24/SelfBlendedImages%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/</url>
    <content><![CDATA[<h1 id="1-论文解读"><a href="#1-论文解读" class="headerlink" title="1. 论文解读"></a>1. 论文解读</h1><h1 id="2-代码运行"><a href="#2-代码运行" class="headerlink" title="2. 代码运行"></a>2. 代码运行</h1><h2 id="2-1-环境"><a href="#2-1-环境" class="headerlink" title="2.1 环境"></a>2.1 环境</h2><p>下载 <code>requirements.txt</code></p>
<p>并运行</p>
<p><code>!pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p><code>!pip install efficientnet-pytorch==0.7.1 -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p><code>!pip install retinaface-pytorch==0.0.7 -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p><code>!pip install dlib -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p><code>!pip install imutils -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p><code>!pip install  numpy==1.21.4 -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<h2 id="2-2-数据集"><a href="#2-2-数据集" class="headerlink" title="2.2 数据集"></a>2.2 数据集</h2><p><strong>Celeb-DF-v2</strong>数据集</p>
<p>将其存放在<code>./data/</code>文件夹中</p>
<p>并且数据的文件树为以下结构</p>
<figure class="highlight smali"><table><tr><td class="code"><pre><span class="line"><span class="keyword">.</span></span><br><span class="line">└── data</span><br><span class="line">    └── Celeb-DF-v2</span><br><span class="line">        ├── Celeb-real</span><br><span class="line">        │   └── videos</span><br><span class="line">        │       └── *.mp4</span><br><span class="line">        ├── Celeb-synthesis</span><br><span class="line">        │   └── videos</span><br><span class="line">        │       └── *.mp4</span><br><span class="line">        ├── Youtube-real</span><br><span class="line">        │   └── videos</span><br><span class="line">        │       └── *.mp4</span><br><span class="line">        └── List_of_testing_videos.txt</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里有个坑，下载过的celeb数据集，路径是没有videos的，你要自己创建。反正要严格按照上面的路径来</p>
</blockquote>
<p><strong>FaceForensics++</strong>数据集</p>
<p>将其存放在<code>./data/</code>文件夹中</p>
<p>并且数据的文件树为以下结构</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">└── data</span><br><span class="line">    └── FaceForensics++</span><br><span class="line">        ├── <span class="keyword">original_sequences</span></span><br><span class="line"><span class="keyword"></span>        │   └── youtube</span><br><span class="line">        │       └── raw</span><br><span class="line">        │           └── videos</span><br><span class="line">        │               └── *.mp4</span><br><span class="line">        ├── train.<span class="keyword">json</span></span><br><span class="line"><span class="keyword"></span>        ├── val.<span class="keyword">json</span></span><br><span class="line"><span class="keyword"></span>        └── test.<span class="keyword">json</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>这个数据集一个original都要100G这么大，每个月的VPN流量伤不起啊</p>
</blockquote>
<h2 id="2-3-预训练模型"><a href="#2-3-预训练模型" class="headerlink" title="2.3 预训练模型"></a>2.3 预训练模型</h2><p>在作者的谷歌云盘中下载2个预训练模型：FF-raw and FF-c23.</p>
<p>并将其存放在 <code>./weights/</code> 文件中</p>
<h2 id="2-4-测试"><a href="#2-4-测试" class="headerlink" title="2.4 测试"></a>2.4 测试</h2><p><strong>测试Celeb-DF-v2数据集</strong></p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=* python3 src/inference/inference_dataset.py \</span><br><span class="line"><span class="deletion">-w weights/FFraw.tar \</span></span><br><span class="line"><span class="deletion">-d CDF</span></span><br></pre></td></tr></table></figure>
<p><strong>测试视频</strong></p>
<figure class="highlight livescript"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=* python3 src/inference/inference_video.py <span class="string">\</span></span><br><span class="line">-w weights/FFraw.tar <span class="string">\</span></span><br><span class="line">-i /path/<span class="keyword">to</span>/video.mp4</span><br></pre></td></tr></table></figure>
<p><strong>测试图片</strong></p>
<figure class="highlight livescript"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=* python3 src/inference/inference_image.py <span class="string">\</span></span><br><span class="line">-w weights/FFraw.tar <span class="string">\</span></span><br><span class="line">-i /path/<span class="keyword">to</span>/image.png</span><br></pre></td></tr></table></figure>
<h2 id="2-5-训练模型"><a href="#2-5-训练模型" class="headerlink" title="2.5 训练模型"></a>2.5 训练模型</h2><ol>
<li><p>下载<code>landmarks.dat</code></p>
<p><a href="https://github.com/codeniko/shape_predictor_81_face_landmarks">here</a> 将文件存放在 <code>./src/preprocess/</code> 文件中</p>
</li>
<li><p>运行两个人脸提取的代码，两个都要运行,不然训练不了，<code>crop_dlib_ff.py</code>和<code>crop_retina_ff.py</code></p>
</li>
</ol>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"><span class="keyword">python3</span> src/preprocess/crop_dlib_ff.<span class="keyword">py</span> -d Original</span><br><span class="line">CUDA_VISIBLE_DEVICES=* <span class="keyword">python3</span> src/preprocess/crop_retina_ff.<span class="keyword">py</span> -d Original</span><br></pre></td></tr></table></figure>
<ol>
<li>特征点参数代码可以下载也可以不下载</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> src/utils/library</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/AlgoHunt/Face-Xray.git src/utils/library</span><br></pre></td></tr></table></figure>
<ol>
<li>运行训练代码</li>
</ol>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=* python3 src/train_sbi.py \</span><br><span class="line">src/configs/<span class="keyword">sbi</span>/base.json \</span><br><span class="line">-n <span class="keyword">sbi</span></span><br></pre></td></tr></table></figure>
<p>运行完 5 个权重文件将会保存在 <code>./output/</code> 文件中</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240324184108970.png" alt="image-20240324184108970"></p>
<h1 id="3-代码解读"><a href="#3-代码解读" class="headerlink" title="3. 代码解读"></a>3. 代码解读</h1><h2 id="dilb人脸检测"><a href="#dilb人脸检测" class="headerlink" title="dilb人脸检测"></a>dilb人脸检测</h2><p><strong>可以当做模版使用</strong></p>
<p>这里只分析参数即可，具体代码直接套用，不需要深度理解</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser=argparse.ArgumentParser()</span><br><span class="line">    <span class="comment">#数据集</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-d&#x27;</span>,dest=<span class="string">&#x27;dataset&#x27;</span>,choices=[<span class="string">&#x27;DeepFakeDetection_original&#x27;</span>,<span class="string">&#x27;DeepFakeDetection&#x27;</span>,<span class="string">&#x27;FaceShifter&#x27;</span>,<span class="string">&#x27;Face2Face&#x27;</span>,<span class="string">&#x27;Deepfakes&#x27;</span>,<span class="string">&#x27;FaceSwap&#x27;</span>,<span class="string">&#x27;NeuralTextures&#x27;</span>,<span class="string">&#x27;Original&#x27;</span>,<span class="string">&#x27;Celeb-real&#x27;</span>,<span class="string">&#x27;Celeb-synthesis&#x27;</span>,<span class="string">&#x27;YouTube-real&#x27;</span>,<span class="string">&#x27;DFDC&#x27;</span>,<span class="string">&#x27;DFDCP&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#三种压缩系数</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-c&#x27;</span>,dest=<span class="string">&#x27;comp&#x27;</span>,choices=[<span class="string">&#x27;raw&#x27;</span>,<span class="string">&#x27;c23&#x27;</span>,<span class="string">&#x27;c40&#x27;</span>],default=<span class="string">&#x27;raw&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#抽帧数</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-n&#x27;</span>,dest=<span class="string">&#x27;num_frames&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,default=<span class="number">32</span>)</span><br><span class="line">    args=parser.parse_args()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 数据路径，这里的&#123;&#125;加入的是压缩系数</span></span><br><span class="line">    <span class="keyword">if</span> args.dataset==<span class="string">&#x27;Original&#x27;</span>:    dataset_path=<span class="string">&#x27;/home/jovyan/work/SelfBlendedImages/data/FaceForensics++/original_sequences/youtube/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(args.comp)</span><br><span class="line">    <span class="keyword">elif</span> args.dataset==<span class="string">&#x27;DeepFakeDetection_original&#x27;</span>:</span><br><span class="line">        dataset_path=<span class="string">&#x27;data/FaceForensics++/original_sequences/actors/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(args.comp)</span><br><span class="line">    <span class="keyword">elif</span> args.dataset <span class="keyword">in</span> [<span class="string">&#x27;DeepFakeDetection&#x27;</span>,<span class="string">&#x27;FaceShifter&#x27;</span>,<span class="string">&#x27;Face2Face&#x27;</span>,<span class="string">&#x27;Deepfakes&#x27;</span>,<span class="string">&#x27;FaceSwap&#x27;</span>,<span class="string">&#x27;NeuralTextures&#x27;</span>]:</span><br><span class="line">        dataset_path=<span class="string">&#x27;data/FaceForensics++/manipulated_sequences/&#123;&#125;/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(args.dataset,args.comp)</span><br><span class="line">    <span class="keyword">elif</span> args.dataset <span class="keyword">in</span> [<span class="string">&#x27;Celeb-real&#x27;</span>,<span class="string">&#x27;Celeb-synthesis&#x27;</span>,<span class="string">&#x27;YouTube-real&#x27;</span>]:</span><br><span class="line">        dataset_path=<span class="string">&#x27;data/Celeb-DF-v2/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(args.dataset)</span><br><span class="line">    <span class="keyword">elif</span> args.dataset <span class="keyword">in</span> [<span class="string">&#x27;DFDC&#x27;</span>]:</span><br><span class="line">        dataset_path=<span class="string">&#x27;data/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(args.dataset)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    face_detector = dlib.get_frontal_face_detector()</span><br><span class="line">    <span class="comment">#预测器的路径，需要下载</span></span><br><span class="line">    predictor_path = <span class="string">&#x27;/home/jovyan/work/SelfBlendedImages/src/preprocess/shape_predictor_81_face_landmarks.dat&#x27;</span></span><br><span class="line">    face_predictor = dlib.shape_predictor(predictor_path)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#视频路径</span></span><br><span class="line">    movies_path=dataset_path+<span class="string">&#x27;videos/&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#寻找以mp4后缀的文件名，并对齐排序</span></span><br><span class="line">    movies_path_list=<span class="built_in">sorted</span>(glob(movies_path+<span class="string">&#x27;*.mp4&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; : videos are exist in &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(movies_path_list),args.dataset))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#用来记录进度条</span></span><br><span class="line">    n_sample=<span class="built_in">len</span>(movies_path_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(n_sample)):</span><br><span class="line">        <span class="comment">#文件路径改成 frames 下</span></span><br><span class="line">        folder_path=movies_path_list[i].replace(<span class="string">&#x27;videos/&#x27;</span>,<span class="string">&#x27;frames/&#x27;</span>).replace(<span class="string">&#x27;.mp4&#x27;</span>,<span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">       <span class="comment">#并将参数输入 facecrop 函数</span></span><br><span class="line">        facecrop(movies_path_list[i],save_path=dataset_path,num_frames=args.num_frames,face_predictor=face_predictor,face_detector=face_detector)</span><br></pre></td></tr></table></figure>
<h2 id="retina人脸检测"><a href="#retina人脸检测" class="headerlink" title="retina人脸检测"></a>retina人脸检测</h2><p><strong>可以当做模版使用</strong></p>
<p>这里只分析参数即可，具体代码直接套用，不需要深度理解</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">	parser=argparse.ArgumentParser()</span><br><span class="line">	</span><br><span class="line">	parser.add_argument(<span class="string">&#x27;-d&#x27;</span>,dest=<span class="string">&#x27;dataset&#x27;</span>,choices=[<span class="string">&#x27;DeepFakeDetection_original&#x27;</span>,<span class="string">&#x27;DeepFakeDetection&#x27;</span>,<span class="string">&#x27;FaceShifter&#x27;</span>,<span class="string">&#x27;Face2Face&#x27;</span>,<span class="string">&#x27;Deepfakes&#x27;</span>,<span class="string">&#x27;FaceSwap&#x27;</span>,<span class="string">&#x27;NeuralTextures&#x27;</span>,<span class="string">&#x27;Original&#x27;</span>,<span class="string">&#x27;Celeb-real&#x27;</span>,<span class="string">&#x27;Celeb-synthesis&#x27;</span>,<span class="string">&#x27;YouTube-real&#x27;</span>,<span class="string">&#x27;DFDC&#x27;</span>,<span class="string">&#x27;DFDCP&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">	parser.add_argument(<span class="string">&#x27;-c&#x27;</span>,dest=<span class="string">&#x27;comp&#x27;</span>,choices=[<span class="string">&#x27;raw&#x27;</span>,<span class="string">&#x27;c23&#x27;</span>,<span class="string">&#x27;c40&#x27;</span>],default=<span class="string">&#x27;raw&#x27;</span>)</span><br><span class="line">	parser.add_argument(<span class="string">&#x27;-n&#x27;</span>,dest=<span class="string">&#x27;num_frames&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,default=<span class="number">32</span>)</span><br><span class="line">	args=parser.parse_args()</span><br><span class="line">	<span class="keyword">if</span> args.dataset==<span class="string">&#x27;Original&#x27;</span>:</span><br><span class="line">		dataset_path=<span class="string">&#x27;/home/jovyan/work/SelfBlendedImages/data/FaceForensics++/original_sequences/youtube/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(args.comp)</span><br><span class="line">	<span class="keyword">elif</span> args.dataset==<span class="string">&#x27;DeepFakeDetection_original&#x27;</span>:</span><br><span class="line">		dataset_path=<span class="string">&#x27;/home/jovyan/work/SelfBlendedImages/data/FaceForensics++/original_sequences/actors/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(args.comp)</span><br><span class="line">	<span class="keyword">elif</span> args.dataset <span class="keyword">in</span> [<span class="string">&#x27;DeepFakeDetection&#x27;</span>,<span class="string">&#x27;FaceShifter&#x27;</span>,<span class="string">&#x27;Face2Face&#x27;</span>,<span class="string">&#x27;Deepfakes&#x27;</span>,<span class="string">&#x27;FaceSwap&#x27;</span>,<span class="string">&#x27;NeuralTextures&#x27;</span>]:</span><br><span class="line">		dataset_path=<span class="string">&#x27;data/FaceForensics++/manipulated_sequences/&#123;&#125;/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(args.dataset,args.comp)</span><br><span class="line">	<span class="keyword">elif</span> args.dataset <span class="keyword">in</span> [<span class="string">&#x27;Celeb-real&#x27;</span>,<span class="string">&#x27;Celeb-synthesis&#x27;</span>,<span class="string">&#x27;YouTube-real&#x27;</span>]:</span><br><span class="line">		dataset_path=<span class="string">&#x27;data/Celeb-DF-v2/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(args.dataset)</span><br><span class="line">	<span class="keyword">elif</span> args.dataset <span class="keyword">in</span> [<span class="string">&#x27;DFDC&#x27;</span>,<span class="string">&#x27;DFDCVal&#x27;</span>]:</span><br><span class="line">		dataset_path=<span class="string">&#x27;data/&#123;&#125;/&#x27;</span>.<span class="built_in">format</span>(args.dataset)</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">raise</span> NotImplementedError</span><br><span class="line">	</span><br><span class="line">         <span class="comment">#设备是cuda</span></span><br><span class="line">	device=torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">         <span class="comment">#获取模型 resnet () 可以试试更换其他模型</span></span><br><span class="line">	model = get_model(<span class="string">&quot;resnet50_2020-07-20&quot;</span>, max_size=<span class="number">2048</span>,device=device)</span><br><span class="line">	model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	movies_path=dataset_path+<span class="string">&#x27;videos/&#x27;</span></span><br><span class="line"></span><br><span class="line">	movies_path_list=<span class="built_in">sorted</span>(glob(movies_path+<span class="string">&#x27;*.mp4&#x27;</span>))</span><br><span class="line">    </span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; : videos are exist in &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(movies_path_list),args.dataset))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	n_sample=<span class="built_in">len</span>(movies_path_list)</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(n_sample)):</span><br><span class="line">		folder_path=movies_path_list[i].replace(<span class="string">&#x27;videos/&#x27;</span>,<span class="string">&#x27;frames/&#x27;</span>).replace(<span class="string">&#x27;.mp4&#x27;</span>,<span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">len</span>(glob(folder_path.replace(<span class="string">&#x27;/frames/&#x27;</span>,<span class="string">&#x27;/retina/&#x27;</span>)+<span class="string">&#x27;*.npy&#x27;</span>))&lt;args.num_frames:</span><br><span class="line">			facecrop(model,movies_path_list[i],save_path=dataset_path,num_frames=args.num_frames)</span><br></pre></td></tr></table></figure>
<h2 id="sbi-自混合图像"><a href="#sbi-自混合图像" class="headerlink" title="sbi 自混合图像"></a>sbi 自混合图像</h2><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 随机种子模版</span></span><br><span class="line">seed=<span class="number">10</span>  </span><br><span class="line">random.seed(seed)  </span><br><span class="line">torch.manual_seed(seed)  </span><br><span class="line">np.random.seed(seed)  </span><br><span class="line">torch.cuda.manual_seed(seed)</span><br><span class="line"></span><br><span class="line"><span class="comment"># cuda后端设置 模版</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span>  </span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#图像大小调整为256x256。</span></span><br><span class="line">image_dataset=SBI_Dataset(phase=<span class="string">&#x27;test&#x27;</span>,image_size=<span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据加载模版</span></span><br><span class="line">batch_size=<span class="number">64</span>  </span><br><span class="line">dataloader = torch.utils.data.DataLoader(image_dataset,  </span><br><span class="line">                    batch_size=batch_size,  </span><br><span class="line">                    <span class="comment">#启用数据打乱</span></span><br><span class="line">                    shuffle=<span class="literal">True</span>,  </span><br><span class="line">                    collate_fn=image_dataset.collate_fn,  </span><br><span class="line">                    <span class="comment">#数据加载将在主进程中同步执行，不使用额外的进程。</span></span><br><span class="line">                    num_workers=<span class="number">0</span>,  </span><br><span class="line">                    worker_init_fn=image_dataset.worker_init_fn  </span><br><span class="line">                    )</span><br><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line">data_iter=<span class="built_in">iter</span>(dataloader)  </span><br><span class="line">data=<span class="built_in">next</span>(data_iter)</span><br><span class="line"></span><br><span class="line"><span class="comment">#处理图像数据</span></span><br><span class="line">img=data[<span class="string">&#x27;img&#x27;</span>]  </span><br><span class="line"><span class="comment">#view函数用于重新调整张量的形状。这里，我们将图像数据重新调整为(-1, 3, 256, 256)的形状，其中-1表示自动计算该维度的大小，3表示图像有3个通道（RGB），256x256是图像的尺寸。</span></span><br><span class="line">img=img.view((-<span class="number">1</span>,<span class="number">3</span>,<span class="number">256</span>,<span class="number">256</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#图像像素值应在0到1之间，并且不进行归一化。</span></span><br><span class="line">utils.save_image(img, <span class="string">&#x27;loader.png&#x27;</span>, nrow=batch_size, normalize=<span class="literal">False</span>, <span class="built_in">range</span>=(<span class="number">0</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h2 id="train-入口"><a href="#train-入口" class="headerlink" title="train 入口"></a>train 入口</h2><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    cfg=load_json(args.config)</span><br><span class="line"></span><br><span class="line">    seed=<span class="number">5</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    image_size=cfg[<span class="string">&#x27;image_size&#x27;</span>]</span><br><span class="line">    batch_size=cfg[<span class="string">&#x27;batch_size&#x27;</span>]</span><br><span class="line">    train_dataset=SBI_Dataset(phase=<span class="string">&#x27;train&#x27;</span>,image_size=image_size)</span><br><span class="line">    val_dataset=SBI_Dataset(phase=<span class="string">&#x27;val&#x27;</span>,image_size=image_size)</span><br><span class="line">   </span><br><span class="line">    train_loader=torch.utils.data.DataLoader(train_dataset,</span><br><span class="line">                        batch_size=batch_size//<span class="number">2</span>,</span><br><span class="line">                        shuffle=<span class="literal">True</span>,</span><br><span class="line">                        collate_fn=train_dataset.collate_fn,</span><br><span class="line">                        num_workers=<span class="number">4</span>,</span><br><span class="line">                        pin_memory=<span class="literal">True</span>,</span><br><span class="line">                        drop_last=<span class="literal">True</span>,</span><br><span class="line">                        worker_init_fn=train_dataset.worker_init_fn</span><br><span class="line">                        )</span><br><span class="line">    val_loader=torch.utils.data.DataLoader(val_dataset,</span><br><span class="line">                        batch_size=batch_size,</span><br><span class="line">                        shuffle=<span class="literal">False</span>,</span><br><span class="line">                        collate_fn=val_dataset.collate_fn,</span><br><span class="line">                        num_workers=<span class="number">4</span>,</span><br><span class="line">                        pin_memory=<span class="literal">True</span>,</span><br><span class="line">                        worker_init_fn=val_dataset.worker_init_fn</span><br><span class="line">                        )</span><br><span class="line">    </span><br><span class="line">    model=Detector()</span><br><span class="line">    </span><br><span class="line">    model=model.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 用来记录</span></span><br><span class="line">    iter_loss=[]</span><br><span class="line">    train_losses=[]</span><br><span class="line">    test_losses=[]</span><br><span class="line">    train_accs=[]</span><br><span class="line">    test_accs=[]</span><br><span class="line">    val_accs=[]</span><br><span class="line">    val_losses=[]</span><br><span class="line">    n_epoch=cfg[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line">    lr_scheduler=LinearDecayLR(model.optimizer, n_epoch, <span class="built_in">int</span>(n_epoch/<span class="number">4</span>*<span class="number">3</span>))</span><br><span class="line">    last_loss=<span class="number">99999</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    now=datetime.now()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 输出路径，其中还包含添加的参数名，以及日期</span></span><br><span class="line">    save_path=<span class="string">&#x27;output/&#123;&#125;_&#x27;</span>.<span class="built_in">format</span>(args.session_name)+now.strftime(os.path.splitext(os.path.basename(args.config))[<span class="number">0</span>])+<span class="string">&#x27;_&#x27;</span>+now.strftime(<span class="string">&quot;%m_%d_%H_%M_%S&quot;</span>)+<span class="string">&#x27;/&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#创建输出权重文件</span></span><br><span class="line">    os.mkdir(save_path)</span><br><span class="line">    os.mkdir(save_path+<span class="string">&#x27;weights/&#x27;</span>)</span><br><span class="line">    os.mkdir(save_path+<span class="string">&#x27;logs/&#x27;</span>)</span><br><span class="line">    logger = log(path=save_path+<span class="string">&quot;logs/&quot;</span>, file=<span class="string">&quot;losses.logs&quot;</span>)</span><br><span class="line"></span><br><span class="line">    criterion=nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每轮都要初始化，很好的模版</span></span><br><span class="line">    last_auc=<span class="number">0</span></span><br><span class="line">    last_val_auc=<span class="number">0</span></span><br><span class="line">    weight_dict=&#123;&#125;</span><br><span class="line">    n_weight=<span class="number">5</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epoch):</span><br><span class="line">        np.random.seed(seed + epoch)</span><br><span class="line">        train_loss=<span class="number">0.</span></span><br><span class="line">        train_acc=<span class="number">0.</span></span><br><span class="line">        model.train(mode=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">for</span> step,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(train_loader)):</span><br><span class="line">            img=data[<span class="string">&#x27;img&#x27;</span>].to(device, non_blocking=<span class="literal">True</span>).<span class="built_in">float</span>()</span><br><span class="line">            target=data[<span class="string">&#x27;label&#x27;</span>].to(device, non_blocking=<span class="literal">True</span>).long()</span><br><span class="line">            output=model.training_step(img, target)</span><br><span class="line">            loss=criterion(output,target)</span><br><span class="line">            loss_value=loss.item()</span><br><span class="line">            iter_loss.append(loss_value)</span><br><span class="line">            train_loss+=loss_value</span><br><span class="line">            acc=compute_accuray(F.log_softmax(output,dim=<span class="number">1</span>),target)</span><br><span class="line">            train_acc+=acc</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        train_losses.append(train_loss/<span class="built_in">len</span>(train_loader))</span><br><span class="line">        train_accs.append(train_acc/<span class="built_in">len</span>(train_loader))</span><br><span class="line"></span><br><span class="line">        log_text=<span class="string">&quot;Epoch &#123;&#125;/&#123;&#125; | train loss: &#123;:.4f&#125;, train acc: &#123;:.4f&#125;, &quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                        epoch+<span class="number">1</span>,</span><br><span class="line">                        n_epoch,</span><br><span class="line">                        train_loss/<span class="built_in">len</span>(train_loader),</span><br><span class="line">                        train_acc/<span class="built_in">len</span>(train_loader),</span><br><span class="line">                        )</span><br><span class="line"></span><br><span class="line">        model.train(mode=<span class="literal">False</span>)</span><br><span class="line">        val_loss=<span class="number">0.</span></span><br><span class="line">        val_acc=<span class="number">0.</span></span><br><span class="line">        output_dict=[]</span><br><span class="line">        target_dict=[]</span><br><span class="line">        np.random.seed(seed)</span><br><span class="line">        <span class="keyword">for</span> step,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(val_loader)):</span><br><span class="line">            img=data[<span class="string">&#x27;img&#x27;</span>].to(device, non_blocking=<span class="literal">True</span>).<span class="built_in">float</span>()</span><br><span class="line">            target=data[<span class="string">&#x27;label&#x27;</span>].to(device, non_blocking=<span class="literal">True</span>).long()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                output=model(img)</span><br><span class="line">                loss=criterion(output,target)</span><br><span class="line">            </span><br><span class="line">            loss_value=loss.item()</span><br><span class="line">            iter_loss.append(loss_value)</span><br><span class="line">            val_loss+=loss_value</span><br><span class="line">            acc=compute_accuray(F.log_softmax(output,dim=<span class="number">1</span>),target)</span><br><span class="line">            val_acc+=acc</span><br><span class="line">            output_dict+=output.softmax(<span class="number">1</span>)[:,<span class="number">1</span>].cpu().data.numpy().tolist()</span><br><span class="line">            target_dict+=target.cpu().data.numpy().tolist()</span><br><span class="line">        val_losses.append(val_loss/<span class="built_in">len</span>(val_loader))</span><br><span class="line">        val_accs.append(val_acc/<span class="built_in">len</span>(val_loader))</span><br><span class="line">        val_auc=roc_auc_score(target_dict,output_dict)</span><br><span class="line">        log_text+=<span class="string">&quot;val loss: &#123;:.4f&#125;, val acc: &#123;:.4f&#125;, val auc: &#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                        val_loss/<span class="built_in">len</span>(val_loader),</span><br><span class="line">                        val_acc/<span class="built_in">len</span>(val_loader),</span><br><span class="line">                        val_auc</span><br><span class="line">                        )</span><br><span class="line">     </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(weight_dict)&lt;n_weight:</span><br><span class="line">            save_model_path=os.path.join(save_path+<span class="string">&#x27;weights/&#x27;</span>,<span class="string">&quot;&#123;&#125;_&#123;:.4f&#125;_val.tar&quot;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>,val_auc))</span><br><span class="line">            weight_dict[save_model_path]=val_auc</span><br><span class="line">            torch.save(&#123;</span><br><span class="line">                    <span class="string">&quot;model&quot;</span>:model.state_dict(),</span><br><span class="line">                    <span class="string">&quot;optimizer&quot;</span>:model.optimizer.state_dict(),</span><br><span class="line">                    <span class="string">&quot;epoch&quot;</span>:epoch</span><br><span class="line">                &#125;,save_model_path)</span><br><span class="line">            last_val_auc=<span class="built_in">min</span>([weight_dict[k] <span class="keyword">for</span> k <span class="keyword">in</span> weight_dict])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> val_auc&gt;=last_val_auc:</span><br><span class="line">            save_model_path=os.path.join(save_path+<span class="string">&#x27;weights/&#x27;</span>,<span class="string">&quot;&#123;&#125;_&#123;:.4f&#125;_val.tar&quot;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>,val_auc))</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> weight_dict:</span><br><span class="line">                <span class="keyword">if</span> weight_dict[k]==last_val_auc:</span><br><span class="line">                    <span class="keyword">del</span> weight_dict[k]</span><br><span class="line">                    os.remove(k)</span><br><span class="line">                    weight_dict[save_model_path]=val_auc</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            torch.save(&#123;</span><br><span class="line">                    <span class="string">&quot;model&quot;</span>:model.state_dict(),</span><br><span class="line">                    <span class="string">&quot;optimizer&quot;</span>:model.optimizer.state_dict(),</span><br><span class="line">                    <span class="string">&quot;epoch&quot;</span>:epoch</span><br><span class="line">                &#125;,save_model_path)</span><br><span class="line">            last_val_auc=<span class="built_in">min</span>([weight_dict[k] <span class="keyword">for</span> k <span class="keyword">in</span> weight_dict])</span><br><span class="line">        </span><br><span class="line">        logger.info(log_text)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    parser=argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(dest=<span class="string">&#x27;config&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-n&#x27;</span>,dest=<span class="string">&#x27;session_name&#x27;</span>)</span><br><span class="line">    args=parser.parse_args()</span><br><span class="line">    main(args)</span><br><span class="line">        </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>LSTM长短期记忆</title>
    <url>/2024/03/25/LSTM%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86/</url>
    <content><![CDATA[<h1 id="LSTM的概念与RNN的区别"><a href="#LSTM的概念与RNN的区别" class="headerlink" title="LSTM的概念与RNN的区别"></a>LSTM的概念与RNN的区别</h1><p>LSTM（Long Short-Term Memory）是一种长短期记忆网络，是一种特殊的RNN（循环神经网络）。与传统的RNN相比，LSTM更加适用于处理和预测时间序列中间隔较长的重要事件。</p>
<p>传统的RNN结构可以看做是多个重复的神经元构成的“回路”，每个神经元都接受输入信息并产生输出，然后将输出再次作为下一个神经元的输入，依次传递下去。这种结构能够在序列数据上学习短时依赖关系，但是由于梯度消失和梯度爆炸问题，RNN在处理长序列时难以达到很好的性能。</p>
<p>而LSTM通过引入记忆细胞、输入门、输出门和遗忘门的概念，能够有效地解决长序列问题。</p>
<p>记忆细胞负责保存重要信息，输入门决定要不要将当前输入信息写入记忆细胞，遗忘门决定要不要遗忘记忆细胞中的信息，输出门决定要不要将记忆细胞的信息作为当前的输出。</p>
<p>这些门的控制能够有效地捕捉序列中重要的长时间依赖性，并且能够解决梯度问题。</p>
<h1 id="LSTM结构和原理"><a href="#LSTM结构和原理" class="headerlink" title="LSTM结构和原理"></a>LSTM结构和原理</h1><p>LSTM结构包括了记忆细胞、输入门、输出门和遗忘门这四个部分。</p>
<ul>
<li>记忆细胞（memory cell）: 它是 LSTM 的核心，负责保存重要的信息，并将这些信息传递给后面的网络层。</li>
<li>输入门（input gate）: 决定了当前输入信息是否写入记忆细胞，也就是说，能够控制输入信息对记忆细胞的影响。</li>
<li>遗忘门（forget gate）: 决定了记忆细胞中的信息是否被遗忘，也就是说，能够控制记忆细胞中保存的信息会不会消失。</li>
<li>输出门（output gate）: 决定了记忆细胞中的信息是否输出，也就是说，能够控制记忆细胞中保存的信息会不会对后面的网络层造成影响。</li>
</ul>
<p>这四个部分通过计算权重矩阵和输入信号的点积，并通过激活函数（通常是sigmoid函数）计算出每个门的输出值，再乘上记忆细胞的值来进行最终计算。</p>
<p><strong>结构</strong></p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/20200330163256331.png" alt="在这里插入图片描述"></p>
<p>LSTM模型是由 t 时刻的输入$X_t$，细胞状态$C_t$，临时细胞状态$\tilde{c}_t$，隐藏层状态$h_t$，遗忘门$f_t$，记忆门$i_t$，输出门$o_t$组成。</p>
<p>LSTM的计算过程可以概括为，通过对细胞状态中信息遗忘和记忆新的信息使得对后续时刻计算有用的信息得以传递，而无用的信息被丢弃，并在每个时间步都会输出隐层状态$h_t$。</p>
<p><strong>cell状态</strong></p>
<p>cell状态有点像传送带，它只用一些次要的线性交互就能贯穿整个链式结构，这其实也就是信息记忆的地方，因此信息能很容易地以不变的形式从中流过。</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/pIYBAFrr1fCAPfVOAABtsGAJp_U372.png" alt="img"></p>
<p>为了增加/删除cell中的信息，LSTM中有一些控制门（gate）。它们决定了信息通过的方式，包含一个sigmoid神经网络层和一个pointwise点乘操作。</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/pIYBAFrr1fGAe5PzAAAIs7gzYW4757.jpg" alt="img"></p>
<p>sigmoid层输出0到1之间的数字，点乘操作决定多少信息可以传送过去，当为0时，不传送；当为1时，全部传送。</p>
<p>像这样的控制门，LSTM共有3个，以此保护和控制cell状态。</p>
<p><strong>遗忘门</strong></p>
<p>对于输入$x<em>t$和$h</em>{t-1}$，遗忘门会输出一个值域为[0, 1]的数字，放进细胞状态$C_{t−1}$中。当为0时，全部删除；当为1时，全部保留。</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/pIYBAFrr1fGATapCAACa8w-t1tA951.png" alt="img"></p>
<p><strong>输入门</strong></p>
<p>分为两步，首先，LSTM会用一个包含sigmoid层的输入门决定哪些信息该保留，其次，它会用一个$tanh$层为这些信息生成一个向量$\tilde{c}_t$，用来更新细胞状态。</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/pIYBAFrr1fGAJko6AAC8z6KeefY047.png" alt="img"></p>
<p><strong>输出门</strong></p>
<p>有了遗忘门和输入门，现在我们就能把细胞状态$C<em>{t−1}$更新为$C</em>{t}$了。如下图所示，其中$f<em>t×C</em>{t−1}$表示希望删除的信息，$i_t×C_t$表示新增的信息。</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/pIYBAFrr1fGAQ_DiAACnSY72yLs112.png" alt="img"></p>
<h1 id="Bi-LSTM"><a href="#Bi-LSTM" class="headerlink" title="Bi-LSTM"></a>Bi-LSTM</h1><p>前向的LSTM与后向的LSTM结合成BiLSTM,将前向和后向的隐向量进行拼接.</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/20200330164206271.png" alt="在这里插入图片描述"></p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/20200330164838930.png" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>OpenGL学习</title>
    <url>/2024/03/26/OpenGL%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>计算机</category>
        <category>图形学</category>
      </categories>
  </entry>
  <entry>
    <title>图形学学习知识一览</title>
    <url>/2024/03/26/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E4%B8%80%E8%A7%88/</url>
    <content><![CDATA[<h1 id="OpenGL"><a href="#OpenGL" class="headerlink" title="OpenGL"></a>OpenGL</h1><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><p><a href="https://learnopengl-cn.github.io/">主页 - LearnOpenGL CN (learnopengl-cn.github.io)</a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>OpenGL</strong>（英语：Open Graphics Library，译名：开放图形库或者“开放式图形库”）是用于渲染2D、3D矢量图形的跨语言、跨平台的应用程序编程接口（API）。这个接口由近350个不同的函数调用组成，用来绘制从简单的图形到比较复杂的三维景象。而另一种程序接口系统是仅用于Microsoft Windows上的Direct3D。OpenGL常用于CAD、虚拟现实、科学可视化程序和电子游戏开发。</p>
<h2 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h2><ul>
<li><strong>建立3D模型：</strong>OpenGL除了能够处理一般的2D图形，即点、线、面的绘制外，主要任务是集合了3D立体的物体绘制函数。</li>
<li><strong>图形变换：</strong>OpenGL利用基本变换以及投影变换处理图形。所谓的基本变换就是在处理2D平面图形时的平移、旋转、变比、镜像变换。投影变换就是在处理3D立体图形时的平行投影以及透视投影。通过变换方式，可以将2D的平面图形清晰明了的变换成3D的立体图形，从而在减少计算的时间的同时就能够提高了图形显示的速度。</li>
<li><strong>颜色模式：</strong>OpenGL库中的颜色模型：使用较为广泛的RGBA模式以及颜色索引模式（color index）。</li>
<li><strong>光照、材质的设置：</strong>OpenGL库中包含了多种光照的类型。材质是用光反射率来表示的。其原理是基于人眼的原理，场景中的物体是由光的红绿蓝的分量以及材质的红绿蓝的反射率的乘积后所形成的颜色值。</li>
<li><strong>纹理映射：</strong>纹理指的是物体表面的花纹。OpenGL库中集合了对于物体纹理的映射处理方式，能够十分完整的复现物体表面的真实纹理。</li>
<li><strong>图像增强功能和位图显示的扩展功能：</strong>OpenGL的功能包括像素的读写、复制外，以及一些特殊的图像处理功能：比如，融合、反走样、雾的等等特殊的处理方式。对于图像的重现和处理，可以使得效果更有真实感，逼真。</li>
<li><strong>双缓存功能：</strong>OpenGL创新性的运用了双缓存形式。计算场景、生成画面图像、显示画面图像分别将其由前台缓存和后台缓存分开处理，大大提高了计算机的运算能力以及画面的显示速度。 [2]</li>
</ul>
<h1 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h1><p>OpenCV是一个基于Apache2.0许可（开源）发行的跨平台计算机视觉和机器学习软件库，可以运行在Linux、Windows、Android和Mac OS操作系统上。 [1]它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。<br>OpenCV用C++语言编写，它具有C ++，Python，Java和MATLAB接口，并支持Windows，Linux，Android和Mac OS，OpenCV主要倾向于实时视觉应用，并在可用时利用MMX和SSE指令， 如今也提供对于C#、Ch、Ruby，GO的支持。</p>
<h1 id="Vulkan"><a href="#Vulkan" class="headerlink" title="Vulkan"></a>Vulkan</h1><p>ulkan是一个跨平台的2D和3D绘图应用程序接口（API），最早由科纳斯组织（Khronos Group） [1]在2015年游戏开发者大会（GDC）上发表。<br>科纳斯最先把VulkanAPI称为“下一代OpenGL行动”（next generation OpenGL initiative）或“glNext”， [2]但在正式宣布Vulkan之后这些名字就没有再使用了。就像OpenGL，Vulkan针对实时3D程序（如电子游戏）设计，Vulkan并计划提供高性能和低CPU管理负担（overhead），这也是Direct3D12和AMD的Mantle的目标。Vulkan兼容Mantle的一个分支，并使用了Mantle的一些组件。<br>Vulkan旨在提供更低的CPU开销与更直接的GPU控制，其理念大致与Direct3D 12和Mantle类似。</p>
<h1 id="Game101"><a href="#Game101" class="headerlink" title="Game101"></a>Game101</h1><h2 id="视频"><a href="#视频" class="headerlink" title="视频"></a>视频</h2><p><a href="https://www.bilibili.com/video/BV1X7411F744/?t=1749&amp;vd_source=04946b2b94db8891e29af8d8d8614fc2">GAMES101-现代计算机图形学入门-闫令琪_哔哩哔哩_bilibili</a></p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h3 id="1-全局关照技术"><a href="#1-全局关照技术" class="headerlink" title="1. 全局关照技术"></a>1. 全局关照技术</h3><p>全局光照（Global Illumination,简称 GI）， 作为图形学中比较酷的概念之一，是指既考虑场景中来自光源的直接光照，又考虑经过场景中其他物体反射后的间接光照的一种渲染技术。</p>
<p>即可以理解为：全局光照 = 直接光照(Direct Light) + 间接光照(Indirect Light) </p>
<h3 id="2-卡通渲染"><a href="#2-卡通渲染" class="headerlink" title="2. 卡通渲染"></a>2. 卡通渲染</h3><p>美式卡通风格在色彩上比较连续，有渐变色，着色风格很大程度上依赖于艺术家定义的色调（tone），而在阴影和高光方面常常采取夸张和变形的做法 。</p>
<p>日式卡通风格往往角色造型更写实，但在着色方面，则趋向于大片大片纯色色块，并有的明暗交界 </p>
<h3 id="3-特效"><a href="#3-特效" class="headerlink" title="3. 特效"></a>3. 特效</h3><p>最简单的图形学应用——平常不常见的画面，穿帮被发现概率小 </p>
<h3 id="4-面部动作捕捉"><a href="#4-面部动作捕捉" class="headerlink" title="4. 面部动作捕捉"></a>4. 面部动作捕捉</h3><p>它是动作捕捉（Motion Capture）技术的一部分，指使用机械装置、相机等设备记录人类面部表情和动作，将之转换为一系列参数数据的过程。</p>
<p>与捕捉由关节点构成、较为稳定的人体动作相比，面部表情更为细微复杂，因此对数据精度要求更高。</p>
<p>CG 电影、大型游戏在预算允许的情况下，倾向于选择捕捉真人面部来完成角色的演出。与人为制作的动画角色表情相比，通过捕捉真人面部动作生成的角色会更具真实感。 </p>
<h3 id="5-毛发模型和渲染"><a href="#5-毛发模型和渲染" class="headerlink" title="5. 毛发模型和渲染"></a>5. 毛发模型和渲染</h3><p>毛发渲染一直是实时图形学的难题，因为其光照复杂，数量众多，物理效果不好抽象等。在早期，只能通过若干面片代替，后来随着硬件及渲染技术的提升，慢慢发展出了经验模型的Kajiya-Kay和基于物理的Marschner毛发渲染模型。 </p>
<h3 id="6-模拟动画-仿真"><a href="#6-模拟动画-仿真" class="headerlink" title="6.模拟动画/仿真"></a>6.模拟动画/仿真</h3><p>今天的游戏动画应用了多种物理模拟技术，例如运动学模拟(kinematics simulation),刚体动力学模拟(rigid body dynamics simulation),绳子/布料模拟(string/cloth simulation),柔体动力学模拟(soft body dynamics simulation),流体动力学模拟(fluid dynamics simulation)等等。另外碰撞侦测(collision detection)是许多模拟系统里所需的。</p>
<h3 id="7-计算机辅助设计-CAD"><a href="#7-计算机辅助设计-CAD" class="headerlink" title="7.计算机辅助设计(CAD)"></a>7.计算机辅助设计(CAD)</h3><p>CAD是利用计算机快速的数值计算和强大的图文处理功能，辅助工程技术人员进行产品设计、工程绘图和数据管理的一门计算机应用技术，是计算机科学技术发展和应用中的一门重要技术。</p>
<p>CAD的涵盖范围很广，其设计对象最初包括两大类，一类是机械、电子、汽车、航天、农业、轻工和纺织产品等；另一类是工程设计产品等，如工程建筑。如今，CAD技术的应用范围已经延伸到诸如艺术等各行各业，如电影、动画、广告、娱乐和多媒体仿真等都属于CAD范畴。</p>
<h3 id="8-可视化"><a href="#8-可视化" class="headerlink" title="8. 可视化"></a>8. 可视化</h3><p>视化是利用计算机图形学和图像处理技术，将数据转换成图形或图像在屏幕上显示出来，并进行交互处理的理论、方法和技术。它涉及到计算机图形学、图像处理、计算机视觉、计算机辅助设计等多个领域，成为研究数据表示、数据处理、决策分析等一系列问题的综合技术。目前正在飞速发展的虚拟现实技术也是以图形图像的可视化技术为依托的。</p>
<p>可视化技术最早运用于计算机科学中，并形成了可视化技术的一个重要分支——科学计算可视化(Visualization in Scientific Computing)。科学计算可视化能够把科学数据，包括测量获得的数值、图像或是计算中涉及、产生的数字信息变为直观的、以图形图像信息表示的、随时间和空间变化的物理现象或物理量呈现在研究者面前，使他们能够观察、模拟和计算。</p>
<h3 id="9-VR-AR-MR"><a href="#9-VR-AR-MR" class="headerlink" title="9. VR.AR.MR"></a>9. VR.AR.MR</h3><p>虚拟现实（Virtual Reality）</p>
<p>所谓虚拟现实，顾名思义，就是虚拟和现实相互结合。从理论上来讲，虚拟现实技术（VR）是一种可以创建和体验虚拟世界的计算机仿真系统，它利用计算机生成一种模拟环境，使用户沉浸到该环境中。虚拟现实技术就是利用现实生活中的数据，通过计算机技术产生的电子信号，将其与各种输出设备结合使其转化为能够让人们感受到的现象，这些现象可以是现实中真真切切的物体，也可以是我们肉眼所看不到的物质，通过三维模型表现出来。因为这些现象不是我们直接所能看到的，而是通过计算机技术模拟出来的现实中的世界，故称为虚拟现实。</p>
<p>增强现实（Augmented Reality）</p>
<p>增强现实技术也被称为扩增现实，AR增强现实技术是促使真实世界信息和虚拟世界信息内容之间综合在一起的较新的技术内容，其将原本在现实世界的空间范围中比较难以进行体验的实体信息在电脑等科学技术的基础上，实施模拟仿真处理，叠加将虚拟信息内容在真实世界中加以有效应用，并且在这一过程中能够被人类感官所感知，从而实现超越现实的感官体验。真实环境和虚拟物体之间重叠之后，能够在同一个画面以及空间中同时存在。</p>
<p>混合现实（Mixed Reality）</p>
<p>混合现实技术（MR）是虚拟现实技术的进一步发展，该技术通过在虚拟环境中引入现实场景信息，在虚拟世界、现实世界和用户之间搭起一个交互反馈的信息回路，以增强用户体验的真实感。</p>
<p>混合现实是一组技术组合，不仅提供新的观看方法，还提供新的输入方法，而且所有方法相互结合，从而推动创新 。输入和输出的结合对中小型企业而言是关键的差异化优势。这样，混合现实就可以直接影响工作流程，帮助员工提高工作效率和创新能力。</p>
<h3 id="10-图形用户界面"><a href="#10-图形用户界面" class="headerlink" title="10. 图形用户界面"></a>10. 图形用户界面</h3><p>图形用户界面（Graphical User Interface，简称 GUI，又称图形用户接口）是指采用图形方式显示的计算机操作用户界面。</p>
<p>图形用户界面是一种人与计算机通信的界面显示格式，允许用户使用鼠标等输入设备操纵屏幕上的图标或菜单选项，以选择命令、调用文件、启动程序或执行其它一些日常任务。与通过键盘输入文本或字符命令来完成例行任务的字符界面相比，图形用户界面有许多优点。图形用户界面由窗口、下拉菜单、对话框及其相应的控制机制构成，在各种新式应用程序中都是标准化的，即相同的操作总是以同样的方式来完成，在图形用户界面，用户看到和操作的都是图形对象，应用的是计算机图形学的技术 </p>
<h3 id="11-字体排印学"><a href="#11-字体排印学" class="headerlink" title="11. 字体排印学"></a>11. 字体排印学</h3><p>一种涉及对字体、字号、缩进、行间距、字符间距进行设计、安排等方法来进行排版的一种工艺。在数码技术普及之前，字体排印是一项专业的工作，数码时代的来临使字体排印不像从前仅由排字印刷方面的技术工人完成，而更被图形艺术家、艺术指导、文书人员甚至儿童广泛使用。 </p>
<h1 id="Direct3D-D3D"><a href="#Direct3D-D3D" class="headerlink" title="Direct3D(D3D)"></a>Direct3D(D3D)</h1><p>Direct 3D是基于微软的通用对象模式COM（Common Object Mode）的3D图形API。它是由微软（Microsoft）一手树立的3D API规范，微软公司拥有该库版权，它所有的语法定义包含在微软提供的程序开发组件的帮助文件、源代码中。Direct3D是微软公司DirectX SDK集成开发包中的重要部分，适合多媒体、娱乐、即时3D动画等广泛和实用的3D图形计算。自1996年发布以来，Direct3D以其良好的硬件兼容性和友好的编程方式很快得到了广泛的认可，现在几乎所有的具有3D图形加速的主流显示卡都对Direct3D提供良好的支持。但它也有缺陷，由于是以COM接口形式提供的，所以较为复杂，稳定性差，另外，目前只在Windows平台上可用。</p>
<h1 id="metal"><a href="#metal" class="headerlink" title="metal"></a>metal</h1><p>在 WWDC 2014 上，Apple为游戏开发者推出了新的平台技术 Metal，该技术能够为 3D 图像提高 10 倍的渲染性能，并支持大家熟悉的游戏引擎及公司。<br>Metal 是一种低层次的渲染应用程序编程接口，提供了软件所需的最低层，保证软件可以运行在不同的图形芯片上。Metal 提升了 A7 与 A8 处理器效能，让其性能完全发挥。</p>
<h1 id="cuda"><a href="#cuda" class="headerlink" title="cuda"></a>cuda</h1><p>CUDA（Compute Unified Device Architecture），是显卡厂商NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 它包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。 开发人员可以使用C语言来为CUDA™架构编写程序，所编写出的程序可以在支持CUDA™的处理器上以超高性能运行。CUDA3.0已经开始支持C++和FORTRAN。</p>
<h1 id="unity"><a href="#unity" class="headerlink" title="unity"></a>unity</h1><p>Unity [1]是实时3D互动内容创作和运营平台 [2]。包括游戏开发、美术、建筑、汽车设计、影视在内的所有创作者，借助Unity将创意变成现实。 [3]Unity平台提供一整套完善的软件解决方案 [3]，可用于创作、运营和变现任何实时互动的2D和3D内容，支持平台包括手机、平板电脑、PC、游戏主机、增强现实和虚拟现实设备。 [3]<br>基于Unity开发的游戏和体验月均下载量高达30亿次 [4]，并且其在2019年的安装量已超过370亿次 [4] 。全平台（包括PC/主机/移动设备）所有游戏中有超过一半都是使用Unity创作的；在Apple应用商店和Google Play上排名最靠前的1000款游戏中，53%都是用Unity创作的。 [5]Unity提供易用实时平台，开发者可以在平台上构建各种AR和VR互动体验。</p>
<h1 id="Unreal"><a href="#Unreal" class="headerlink" title="Unreal"></a>Unreal</h1><p>Unreal是UNREAL ENGINE（虚幻引擎）的简写，由Epic开发，是世界知名授权最广的游戏引擎之一。<br>虚幻技术研究中心在上海成立，该中心由GA国际游戏教育与虚幻引擎开发商EPIC的中国子公司EPIC GAMES CHINA联合设立。</p>
<h1 id="CAD"><a href="#CAD" class="headerlink" title="CAD"></a>CAD</h1><p>利用计算机及其图形设备帮助设计人员进行设计工作。简称CAD。 在工程和产品设计中，计算机可以帮助设计人员担负计算、信息存储和制图等项工作。在设计中通常要用计算机对不同方案进行大量的计算、分析和比较，以决定最优方案；各种设计信息，不论是数字的、文字的或图形的，都能存放在计算机的内存或外存里，并能快速地检索；设计人员通常用草图开始设计，将草图变为工作图的繁重工作可以交给计算机完成；利用计算机可以进行与图形的编辑、放大、缩小、平移和旋转等有关的图形数据加工工作。</p>
<h1 id="CAE"><a href="#CAE" class="headerlink" title="CAE"></a>CAE</h1><p>CAE(Computer Aided Engineering)指工程设计中的计算机辅助工程，指用计算机辅助求解分析复杂工程和产品的结构力学性能，以及优化结构性能等，把工程（生产）的各个环节有机地组织起来，其关键就是将有关的信息集成，使其产生并存在于工程（产品）的整个生命周期。而CAE软件可作静态结构分析，动态分析；研究线性、非线性问题；分析结构（固体）、流体、电磁等。</p>
<h1 id="CAM"><a href="#CAM" class="headerlink" title="CAM"></a>CAM</h1><p>计算机辅助制造是指在机械制造业中，利用电子数字计算机通过各种数值控制机床和设备，自动完成离散产品的加工、装配 、检测和包装等制造过程。简称cam。</p>
<h1 id="Eda"><a href="#Eda" class="headerlink" title="Eda"></a>Eda</h1><p><strong>电子设计自动化</strong>（英语：<strong>Electronic design automation</strong>，缩写：<strong>EDA</strong>）是指利用计算机辅助设计（CAD）软件，来完成超大规模集成电路（VLSI）芯片的功能设计、综合、验证、物理设计（包括布局、布线、版图、设计规则检查等）等流程的设计方式。</p>
<h1 id="微分几何"><a href="#微分几何" class="headerlink" title="微分几何"></a>微分几何</h1><p>微分几何是运用微积分的理论研究空间的几何性质的数学分支学科。<br>古典微分几何研究三维空间中的曲线和曲面，而现代微分几何开始研究更一般的空间——流形。<br>微分几何与拓扑学等其他数学分支有紧密的联系，对物理学的发展也有重要影响。爱因斯坦的广义相对论就以微分几何中的黎曼几何作为其重要的数学基础。</p>
<h1 id="计算几何"><a href="#计算几何" class="headerlink" title="计算几何"></a>计算几何</h1><h3 id="几何化"><a href="#几何化" class="headerlink" title="几何化"></a>几何化</h3><p>计算几何研究的对象是几个图形。早期人们对于图像的研究一般都是先建立坐标系，把图形转换成函数，然后用插值和逼近的数学方法，特别是用样条函数作为工具来分析图形，取得了可喜的成功。然而，这些方法过多地依赖于坐标系的选取，缺乏几何不变性，特别是用来解决某些大挠度曲线及曲线的奇异点等问题时，有一定的局限性。</p>
<p>几何图形是实际物体的抽象描述，几何化是指被研究对象本身的性质所决定的一种必然趋势。</p>
<h3 id="代数化"><a href="#代数化" class="headerlink" title="代数化"></a>代数化</h3><p>在国外，计算几何的代数化有一股很强的势头。为了在计算机和图形显示终端表示和处理各种复杂的曲面和几何形体，需进行大量的计算，往往需要将问题代数化、线性化、离散化，特别对于最新式的全色连续色调的图像，必须对显示屏上的光栅网格点逐点进行计算扫描。</p>
<h3 id="图形化"><a href="#图形化" class="headerlink" title="图形化"></a>图形化</h3><p>随着交互式图形显示系统在CAGD中的广泛应用，计算机图形学作为新兴学科得到迅速发展。其主要研究对象是图形的生成、变换、显示、剪取、隐藏线和隐藏面的消除、阴影色调及相应的光顺处理等。其中剪取问题是计算机图形学的一个基本问题，剪取的关键是速度，尤其是在交互式动态显示和最新式的光扫描中。</p>
<h1 id="GDI"><a href="#GDI" class="headerlink" title="GDI"></a>GDI</h1><p>图形设备接口（GDI ：Graphics Device Interface），它的主要任务是负责系统与绘图程序之间的信息交换，处理所有Windows程序的图形输出。</p>
<h1 id="glsl"><a href="#glsl" class="headerlink" title="glsl"></a>glsl</h1><p>OpenGL着色语言（OpenGL Shading Language）是用来在OpenGL中着色编程的语言，也即开发人员写的短小的自定义程序，他们是在图形卡的GPU （Graphic Processor Unit图形处理单元）上执行的，代替了固定的渲染管线的一部分，使渲染管线中不同层次具有可编程性。比如：视图转换、投影转换等。GLSL（GL Shading Language）的着色器代码分成2个部分：Vertex Shader（顶点着色器）和Fragment（片断着色器），有时还会有Geometry Shader（几何着色器）。负责运行顶点着色的是顶点着色器。它可以得到当前OpenGL 中的状态，GLSL内置变量进行传递。GLSL其使用C语言作为基础高阶着色语言，避免了使用汇编语言或硬件规格语言的复杂性。</p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>图形学</category>
      </categories>
  </entry>
  <entry>
    <title>OpenGL学习</title>
    <url>/2024/03/28/EDA%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<h1 id="ASIC设计"><a href="#ASIC设计" class="headerlink" title="ASIC设计"></a>ASIC设计</h1><h2 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h2><p><strong>确定项目需求</strong></p>
<ul>
<li>物理实现(制作工艺、面积、封装)</li>
<li>性能指标(速度、功耗)</li>
<li>功能指标(功能描述、接口定义)</li>
</ul>
<p><strong>芯片设计</strong></p>
<ul>
<li>项目分块</li>
<li>PTL代码设计(Verilog/SystemVerilog/VHDL)</li>
<li>IP集成</li>
</ul>
<p><strong>验证(Verification)</strong></p>
<ul>
<li>验证设计和计划</li>
<li>编写Testbench和Testcase</li>
<li>回归/还原测试</li>
<li>集成性验证</li>
</ul>
<p><strong>逻辑综合(Logic Synthesis)</strong></p>
<ul>
<li>将RTL代码设计映射到门级电路的网表</li>
</ul>
<p><strong>静态时序分析(STA)</strong></p>
<ul>
<li>套用特定的时序模型，针对特定电路分析其是否违反设计者给定的时序限制。通过数学计算方法，来计算所有的路径有没有满足时序。</li>
</ul>
<p><strong>可测性设计(DFT)</strong></p>
<ul>
<li>为了在芯片生成之后，测试芯片制作有无缺陷，一般在电路中插入扫描链</li>
</ul>
<h2 id="后端"><a href="#后端" class="headerlink" title="后端"></a>后端</h2><p><strong>布局布线</strong></p>
<p>信号布线，包括各种标准单元(基本逻辑门电路)之间的走线</p>
<p><strong>寄生参数提取和时序分析</strong></p>
<p>提取延迟信息，并加入布局布线延迟，得到更真实的时序分析</p>
<p><strong>版图物理验证</strong></p>
<p>DRC(设计规则检查)、LVS(版图一致性检查)</p>
<p><strong>生成GDSII文件，Tap_off流片</strong></p>
<h1 id="Eda工具"><a href="#Eda工具" class="headerlink" title="Eda工具"></a>Eda工具</h1><p><strong>Candence</strong></p>
<p><strong>Synopsys</strong></p>
<p><strong>Mentor</strong></p>
<h1 id="数学基础"><a href="#数学基础" class="headerlink" title="数学基础"></a>数学基础</h1><p><strong>数据结构</strong></p>
<p><strong>算法设计</strong></p>
<p><strong>图论算法</strong></p>
<p><strong>组合数学</strong></p>
<p><strong>计算几何</strong></p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p><strong>pEDA-Schematic</strong></p>
<p><strong>Layout</strong></p>
<p><strong>Simulate</strong></p>
<p><strong>CAM</strong></p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>图形学</category>
      </categories>
  </entry>
  <entry>
    <title>FF++下载脚本</title>
    <url>/2024/03/28/FF++%E4%B8%8B%E8%BD%BD%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="数据集结构"><a href="#数据集结构" class="headerlink" title="数据集结构"></a>数据集结构</h1><figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line">FaceForensics++ dataset</span><br><span class="line"><span class="string">|-- downloaded_videos</span></span><br><span class="line"><span class="meta">#包含所有原始下载的视频、视频信息文件及其提取的序列,可用于提取数据集中使用的原始序列</span></span><br><span class="line">      </span><br><span class="line"><span class="string">|-- original_sequences</span></span><br><span class="line">    <span class="string">|-- youtube</span></span><br><span class="line">    <span class="meta"># c0/raw 原始序列 图像或者视频 的 FaceForensics++ 数据集</span></span><br><span class="line">    <span class="meta"># c23/hq 原始序列 图像或者视频</span></span><br><span class="line">    <span class="meta"># c40/lq 原始序列 图像或者视频</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">|-- actors</span></span><br><span class="line">    <span class="meta"># 来自 DeepFakeDetection 的图像或者视频</span></span><br><span class="line">       </span><br><span class="line"><span class="string">|-- manipulated_sequences</span></span><br><span class="line">    <span class="string">|-- Deepfakes</span></span><br><span class="line">    <span class="meta"># 所有三个压缩度的图像/视频以及泊松图像编辑后的模型和遮罩</span></span><br><span class="line">       </span><br><span class="line">    <span class="string">|-- DeepFakeDetection</span></span><br><span class="line">    <span class="meta"># 所有三个压缩度的图像/视频以及泊松图像编辑后的模型和遮罩 </span></span><br><span class="line">        </span><br><span class="line">    <span class="string">|-- Face2Face</span></span><br><span class="line">    <span class="meta"># 所有三个压缩度的图像/视频以及泊松图像编辑后的模型和遮罩</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">|-- FaceSwap</span></span><br><span class="line">    <span class="meta"># 所有三个压缩度的图像/视频以及泊松图像编辑后的模型和遮罩</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">|-- NeuralTextures</span></span><br><span class="line">    <span class="meta"># 所有三个压缩度的图像/视频以及泊松图像编辑后的模型和遮罩   </span></span><br></pre></td></tr></table></figure>
<h1 id="文件大小"><a href="#文件大小" class="headerlink" title="文件大小"></a>文件大小</h1><ul>
<li>FaceForensics++<ul>
<li>视频<ul>
<li>YouTube <ul>
<li>原始视频：38.5GB</li>
<li>h264压缩<ul>
<li>raw/0: ~500GB</li>
<li>23: ~10GB</li>
<li>40: ~2GB</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>图像：2TB </li>
</ul>
</li>
<li>Deepfakedetection<ul>
<li>actor 视频<ul>
<li>raw/0: ~200GB</li>
<li>23: ~3GB</li>
<li>40: ~400MB</li>
</ul>
</li>
<li>manipulated 视频<ul>
<li>raw/0: ~1.6TB</li>
<li>c23: ~22GB</li>
<li>c40: ~3GB</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="下载脚本"><a href="#下载脚本" class="headerlink" title="下载脚本"></a>下载脚本</h1><p><strong>运行</strong></p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"><span class="keyword">python</span> download-FaceForensics.<span class="keyword">py</span></span><br></pre></td></tr></table></figure>
<p><strong>参数</strong></p>
<figure class="highlight bnf"><table><tr><td class="code"><pre><span class="line">python download-FaceForensics.py</span><br><span class="line">    <span class="attribute">&lt;输出路径&gt;</span></span><br><span class="line">    -d <span class="attribute">&lt;数据集类型, Face2Face, original or all&gt;</span></span><br><span class="line">    -c <span class="attribute">&lt;压缩质量, c23 or raw&gt;</span></span><br><span class="line">    -t <span class="attribute">&lt;文件类型, videos, masks or models&gt;</span></span><br><span class="line">    -server EU2</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>icpr2020论文精读</title>
    <url>/2024/03/27/icpr2020%E7%B2%BE%E8%AF%BB/</url>
    <content><![CDATA[<h1 id="1-论文精读"><a href="#1-论文精读" class="headerlink" title="1. 论文精读"></a>1. 论文精读</h1><h2 id="EfficientNet"><a href="#EfficientNet" class="headerlink" title="EfficientNet"></a>EfficientNet</h2><h1 id="2-代码运行"><a href="#2-代码运行" class="headerlink" title="2. 代码运行"></a>2. 代码运行</h1><p><strong>数据集初始化</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!python index_dfdc.py --<span class="built_in">source</span> <span class="string">&quot;/home/jovyan/work/icpr2020/dfdc&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_args</span>(<span class="params">argv</span>):</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    <span class="comment"># 路径应该写成 50个子数据集的根目录</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--source&#x27;</span>, <span class="built_in">type</span>=Path, <span class="built_in">help</span>=<span class="string">&#x27;Source dir&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--videodataset&#x27;</span>, <span class="built_in">type</span>=Path, default=<span class="string">&#x27;data/dfdc_videos.pkl&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Path to save the videos DataFrame&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Batch size&#x27;</span>, default=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parser.parse_args(argv)</span><br></pre></td></tr></table></figure>
<p><strong>提取人脸</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!python extract_faces.py \</span><br><span class="line">--<span class="built_in">source</span> <span class="string">&quot;/home/jovyan/work/icpr2020/dfdc&quot;</span> \</span><br><span class="line">--videodf <span class="string">&quot;/home/jovyan/work/icpr2020/data/dfdc_videos.pkl&quot;</span>\</span><br><span class="line">--facesfolder <span class="string">&quot;/home/jovyan/work/icpr2020/faces/output/directory&quot;</span>\</span><br><span class="line">--facesdf <span class="string">&quot;/home/jovyan/work/icpr2020/faces/df/output/directory&quot;</span>\</span><br><span class="line">--checkpoint <span class="string">&quot;/home/jovyan/work/icpr2020/tmp/outputs&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_args</span>(<span class="params">argv</span>):</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    <span class="comment"># 路径应该写成 50个子数据集的根目录</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--source&#x27;</span>, <span class="built_in">type</span>=Path, <span class="built_in">help</span>=<span class="string">&#x27;Videos root directory&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># dfdc_videos.pkl 文件</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--videodf&#x27;</span>, <span class="built_in">type</span>=Path, <span class="built_in">help</span>=<span class="string">&#x27;Path to read the videos DataFrame&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># directory 路径</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--facesfolder&#x27;</span>, <span class="built_in">type</span>=Path, <span class="built_in">help</span>=<span class="string">&#x27;Faces output root directory&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># directory 路径</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--facesdf&#x27;</span>, <span class="built_in">type</span>=Path, <span class="built_in">help</span>=<span class="string">&#x27;Path to save the output DataFrame of faces&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--checkpoint&#x27;</span>, <span class="built_in">type</span>=Path, <span class="built_in">help</span>=<span class="string">&#x27;Path to save the temporary per-video outputs&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--fpv&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">32</span>, <span class="built_in">help</span>=<span class="string">&#x27;Frames per video&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, <span class="built_in">type</span>=torch.device,</span><br><span class="line">                        default=torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>),</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Device to use for face extraction&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--collateonly&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Only perform collation of pre-existing results&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--noindex&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Do not rebuild the index&#x27;</span>, action=<span class="string">&#x27;store_false&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Batch size&#x27;</span>, default=<span class="number">16</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--threads&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Number of threads&#x27;</span>, default=<span class="number">8</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--offset&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Offset to start extraction&#x27;</span>, default=<span class="number">0</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Number of videos to process&#x27;</span>, default=<span class="number">0</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lazycheck&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Lazy check of existing video indexes&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--deepcheck&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Try to open every image&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> parser.parse_args(argv)</span><br></pre></td></tr></table></figure>
<p><strong>train_binclass</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!python train_binclass.py \</span><br><span class="line">--net EfficientNetB4  \</span><br><span class="line"><span class="comment"># dfdc-35-5-10 意思是 35 train，5 val，10 test。如果想改,看split.py文件</span></span><br><span class="line">--traindb dfdc-35-5-10 \</span><br><span class="line">--valdb dfdc-35-5-10 \</span><br><span class="line">--dfdc_faces_df_path <span class="string">&quot;/home/jovyan/work/icpr2020/faces/df/output/directory/faces_df.pkl&quot;</span> \</span><br><span class="line">--dfdc_faces_dir <span class="string">&quot;/home/jovyan/work/icpr2020/faces/output/directory&quot;</span> \</span><br><span class="line">--face scale \</span><br><span class="line">--size 224 \</span><br><span class="line">--batch 32 \</span><br><span class="line">--lr 1e-5 \</span><br><span class="line">--valint 500 \</span><br><span class="line">--patience 10 \</span><br><span class="line">--maxiter 30000 \</span><br><span class="line">--seed 41 \</span><br><span class="line">--attention \</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># Args</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--net&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;Net model class&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--traindb&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;Training datasets&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, choices=split.available_datasets,</span><br><span class="line">                        required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--valdb&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;Validation datasets&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, choices=split.available_datasets,</span><br><span class="line">                        required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dfdc_faces_df_path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, action=<span class="string">&#x27;store&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Path to the Pandas Dataframe obtained from extract_faces.py on the DFDC dataset. &#x27;</span></span><br><span class="line">                             <span class="string">&#x27;Required for training/validating on the DFDC dataset.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dfdc_faces_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, action=<span class="string">&#x27;store&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Path to the directory containing the faces extracted from the DFDC dataset. &#x27;</span></span><br><span class="line">                             <span class="string">&#x27;Required for training/validating on the DFDC dataset.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--ffpp_faces_df_path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, action=<span class="string">&#x27;store&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Path to the Pandas Dataframe obtained from extract_faces.py on the FF++ dataset. &#x27;</span></span><br><span class="line">                             <span class="string">&#x27;Required for training/validating on the FF++ dataset.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--ffpp_faces_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, action=<span class="string">&#x27;store&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Path to the directory containing the faces extracted from the FF++ dataset. &#x27;</span></span><br><span class="line">                             <span class="string">&#x27;Required for training/validating on the FF++ dataset.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--face&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;Face crop or scale&#x27;</span>, required=<span class="literal">True</span>,</span><br><span class="line">                        choices=[<span class="string">&#x27;scale&#x27;</span>, <span class="string">&#x27;tight&#x27;</span>])</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Train patch size&#x27;</span>, required=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Batch size to fit in GPU memory&#x27;</span>, default=<span class="number">32</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">1e-5</span>, <span class="built_in">help</span>=<span class="string">&#x27;Learning rate&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--valint&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Validation interval (iterations)&#x27;</span>, default=<span class="number">500</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--patience&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Patience before dropping the LR [validation intervals]&#x27;</span>,</span><br><span class="line">                        default=<span class="number">10</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--maxiter&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Maximum number of iterations&#x27;</span>, default=<span class="number">20000</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--init&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;Weight initialization file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--scratch&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Train from scratch&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--trainsamples&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Limit the number of train samples per epoch&#x27;</span>, default=-<span class="number">1</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--valsamples&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Limit the number of validation samples per epoch&#x27;</span>,</span><br><span class="line">                        default=<span class="number">6000</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--logint&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Training log interval (iterations)&#x27;</span>, default=<span class="number">100</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--workers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Num workers for data loaders&#x27;</span>, default=<span class="number">6</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;GPU device id&#x27;</span>, default=<span class="number">0</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--seed&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;Random seed&#x27;</span>, default=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--debug&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Activate debug&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--suffix&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;Suffix to default tag&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--attention&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Enable Tensorboard log of attention masks&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--log_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;Directory for saving the training logs&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;runs/binclass/&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--models_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;Directory for saving the models weights&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;weights/binclass/&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br></pre></td></tr></table></figure>
<h1 id="3-代码解读"><a href="#3-代码解读" class="headerlink" title="3. 代码解读"></a>3. 代码解读</h1><h2 id="数据集初始化-index-dfdc-py"><a href="#数据集初始化-index-dfdc-py" class="headerlink" title="数据集初始化 index_dfdc.py"></a>数据集初始化 index_dfdc.py</h2><p><strong>metadata.json合并</strong></p>
<blockquote>
<p>由于DFDC被拆分成dfdc_tarin_part_00~50，而且每个部分都有一个metadata.json。于是以下代码可以让50个metadata.json合并起来</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Index</span></span><br><span class="line">df_train_list = <span class="built_in">list</span>()</span><br><span class="line"><span class="keyword">for</span> idx, json_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(<span class="built_in">sorted</span>(source_dir.rglob(<span class="string">&#x27;metadata.json&#x27;</span>)), desc=<span class="string">&#x27;Indexing&#x27;</span>)):</span><br><span class="line">    df_tmp = pd.read_json(json_path, orient=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line">    df_tmp[<span class="string">&#x27;path&#x27;</span>] = df_tmp.index.<span class="built_in">map</span>(</span><br><span class="line">    <span class="keyword">lambda</span> x: <span class="built_in">str</span>(json_path.parent.relative_to(source_dir).joinpath(x)))</span><br><span class="line">    df_tmp[<span class="string">&#x27;folder&#x27;</span>] = <span class="built_in">int</span>(<span class="built_in">str</span>(json_path.parts[-<span class="number">2</span>]).split(<span class="string">&#x27;_&#x27;</span>)[-<span class="number">1</span>])</span><br><span class="line">    df_train_list.append(df_tmp)</span><br><span class="line">df_videos = pd.concat(df_train_list, axis=<span class="number">0</span>, verify_integrity=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="人脸提取-extract-faces-py"><a href="#人脸提取-extract-faces-py" class="headerlink" title="人脸提取 extract_faces.py"></a>人脸提取 extract_faces.py</h2><h2 id="训练-train-binclass-py"><a href="#训练-train-binclass-py" class="headerlink" title="训练 train_binclass.py"></a>训练 train_binclass.py</h2><p><strong>split.by</strong></p>
<blockquote>
<p>这部分代码可以更改训练集和测试集的数量</p>
</blockquote>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">available_datasets = [</span><br><span class="line">    <span class="string">&#x27;dfdc-35-5-10&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ff-c23-720-140-140&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ff-c23-720-140-140-5fpv&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ff-c23-720-140-140-10fpv&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ff-c23-720-140-140-15fpv&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ff-c23-720-140-140-20fpv&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ff-c23-720-140-140-25fpv&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;celebdf&#x27;</span>,  <span class="comment"># just for convenience, not used in the original paper</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_split_df</span>(<span class="params">df: pd.DataFrame, dataset: <span class="built_in">str</span>, split: <span class="built_in">str</span></span>) -&gt; pd.DataFrame:</span><br><span class="line">    <span class="keyword">if</span> dataset == <span class="string">&#x27;dfdc-35-5-10&#x27;</span>:</span><br><span class="line">        <span class="keyword">if</span> split == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">            split_df = df[df[<span class="string">&#x27;folder&#x27;</span>].isin(<span class="built_in">range</span>(<span class="number">35</span>))]</span><br><span class="line">        <span class="keyword">elif</span> split == <span class="string">&#x27;val&#x27;</span>:</span><br><span class="line">            split_df = df[df[<span class="string">&#x27;folder&#x27;</span>].isin(<span class="built_in">range</span>(<span class="number">35</span>,<span class="number">40</span>))]</span><br><span class="line">        <span class="keyword">elif</span> split == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            split_df = df[df[<span class="string">&#x27;folder&#x27;</span>].isin(<span class="built_in">range</span>(<span class="number">40</span>,<span class="number">50</span>))]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">&#x27;Unknown split: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(split))</span><br></pre></td></tr></table></figure>
<h1 id="4-指标"><a href="#4-指标" class="headerlink" title="4. 指标"></a>4. 指标</h1>]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>子豪兄2天完成论文系列之预测图像</title>
    <url>/2024/03/29/%E5%AD%90%E8%B1%AA%E5%85%842%E5%A4%A9%E5%AE%8C%E6%88%90%E8%AE%BA%E6%96%87%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<h1 id="1-预测单张图像"><a href="#1-预测单张图像" class="headerlink" title="1 预测单张图像"></a>1 预测单张图像</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<h2 id="设备"><a href="#设备" class="headerlink" title="设备"></a>设备</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 有 GPU 就用 GPU，没有就用 CPU</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;device&#x27;</span>, device)</span><br></pre></td></tr></table></figure>
<pre><code>device cuda:0
</code></pre><h2 id="载入预训练图像分类模型"><a href="#载入预训练图像分类模型" class="headerlink" title="载入预训练图像分类模型"></a>载入预训练图像分类模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> efficientnet_pytorch <span class="keyword">import</span> EfficientNet</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Detector</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Detector, self).__init__()</span><br><span class="line">        self.net=EfficientNet.from_pretrained(<span class="string">&quot;efficientnet-b4&quot;</span>,advprop=<span class="literal">True</span>,num_classes=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.net(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model=Detector()</span><br><span class="line">model=model.to(device)</span><br><span class="line">cnn_sd=torch.load(<span class="string">&#x27;weights/FFraw&#x27;</span>)</span><br><span class="line">model.load_state_dict(cnn_sd)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>
<h2 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">extract_face</span>(<span class="params">frame,model,image_size=(<span class="params"><span class="number">380</span>,<span class="number">380</span></span>)</span>):</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    faces = model.predict_jsons(frame)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(faces)==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;No face is detected&#x27;</span> )</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">    croppedfaces=[]</span><br><span class="line">    <span class="keyword">for</span> face_idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(faces)):</span><br><span class="line">        x0,y0,x1,y1=faces[face_idx][<span class="string">&#x27;bbox&#x27;</span>]</span><br><span class="line">        bbox=np.array([[x0,y0],[x1,y1]])</span><br><span class="line">        croppedfaces.append(cv2.resize(crop_face(frame,<span class="literal">None</span>,bbox,<span class="literal">False</span>,crop_by_bbox=<span class="literal">True</span>,only_img=<span class="literal">True</span>,phase=<span class="string">&#x27;test&#x27;</span>),dsize=image_size).transpose((<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> croppedfaces</span><br></pre></td></tr></table></figure>
<h2 id="载入一张测试图片"><a href="#载入一张测试图片" class="headerlink" title="载入一张测试图片"></a>载入一张测试图片</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame = cv2.imread(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用 pillow 载入</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">img_pil = Image.<span class="built_in">open</span>(frame)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.array(img_pil).shape</span><br></pre></td></tr></table></figure>
<h2 id="执行分类预测"><a href="#执行分类预测" class="headerlink" title="执行分类预测"></a>执行分类预测</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> retinaface.pre_trained_models <span class="keyword">import</span> get_model</span><br><span class="line">face_detector = get_model(<span class="string">&quot;resnet50_2020-07-20&quot;</span>, max_size=<span class="built_in">max</span>(frame.shape),device=device)</span><br><span class="line">face_detector.<span class="built_in">eval</span>()</span><br><span class="line">face_list=extract_face(frame,face_detector)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">face_list.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># img = face_list.unsqueeze(0).to(device)</span></span><br><span class="line"><span class="comment"># 执行前向预测，得到所有类别的 logit 预测分数</span></span><br><span class="line"><span class="comment">#pred_logits = model(input_img) </span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pred_logits</span></span><br><span class="line"><span class="comment">#import torch.nn.functional as F</span></span><br><span class="line"><span class="comment">#pred_softmax = F.softmax(pred_logits, dim=1) # 对 logit 分数做 softmax 运算</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#pred_softmax.shape</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    img=torch.tensor(face_list).to(device).<span class="built_in">float</span>()/<span class="number">255</span></span><br><span class="line">    <span class="comment"># torchvision.utils.save_image(img, f&#x27;test.png&#x27;, nrow=8, normalize=False, range=(0, 1))</span></span><br><span class="line">    pred=model(img).softmax(<span class="number">1</span>)[:,<span class="number">1</span>].cpu().data.numpy().tolist()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>DDGAN</title>
    <url>/2024/04/22/DDGAN/</url>
    <content><![CDATA[<p>这篇工作在原始的DDPM(去噪扩散概率模型)的基础上进行改进，针对扩散模型生成样本/采样速度慢的问题提出解决方案，同时保留了扩散模型高采样质量、模式覆盖多/多样性的优势。</p>
<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>作者提出当下的生成学习框架无法很好地同时满足以下三个要求:</p>
<ol>
<li>高采样质量</li>
<li>模式覆盖与多样性</li>
<li>快速的、低计算开销的采样</li>
</ol>
<p>作者首先讨论了为什么去噪过程需要小的步长，这也是导致去噪过程总步数多、采样速度慢的主要原因；接着作者提出了解决方案，即对于去噪过程的模型，用多模态分布代替原始Diffusion Model中的高斯分布。</p>
<p>去噪分布是高斯分布这一前提假设导致小的步长不可避免，从而导致总步数多，采样慢。</p>
<p>因此，自然地能够想到要增大步长以减小去噪过程的总步数，就需要更换假设，用别的分布来建模真实的去噪分布。作者从数据分布入手:</p>
<p><img src="https://pic2.zhimg.com/80/v2-924d66e448d6e6afa87ddf4d8b72f289_720w.webp" alt="img"></p>
<p>其中第一行是正向扩散过程中，数据分布 q(x_0) 的变化过程；第二行是给定固定的 x5 ，改变步长得到的真实去噪分布。</p>
<p>从图中我们可以看到，在正向加噪过程中随着逐步地添加高斯噪声，数据分布越来越接近单模的高斯分布；而在去噪过程中，如果我们如同原始设定一样用小的步长，一次只走一步,那么真实去噪分布是接近高斯分布的，但当步长增加时分布变得更加复杂以及多模态。</p>
<p>针对这种现象，作者提出用更有表达能力的多模态分布来建模这个去噪分布。由于条件GAN已被证明可以在图片领域建模复杂的条件分布，作者选用条件GAN来估计真实去噪分布.</p>
<h1 id="设定"><a href="#设定" class="headerlink" title="设定"></a>设定</h1><p>前向扩散过程与原来的DDPM模型一致</p>
<p>训练目标方面，训练旨在利用最小化对抗性损失，这个对抗性损失能够最小化散度</p>
<p>从而提高条件GAN的生成器 与 真实去噪分布 的匹配程度</p>
<p>具体到对抗训练方面，与时间有关的判别器。让来自真实分布的样本输出的置信度尽可能高，来着虚假样本输出置信度尽可能低。</p>
<h1 id="重参数"><a href="#重参数" class="headerlink" title="重参数"></a>重参数</h1><p>相比于原来的DDPM，现在的去噪模型更加复杂，且是一个隐式的模型(原来的建模只是简单的高斯分布)。但是由于正向扩散过程仍然是加的高斯噪声，因此无论步长多大或者数据分布多复杂，依然有$$服从高斯分布这一性质、</p>
<ol>
<li>原DDPM是以确定的映射方式由x_t预测x_0,而作者的设计中x_0是由带随机隐变量z的生成器得到的。使得去噪分布模型变得多模态且更复杂，而原DDPM的去噪模型是简单的、单模态的高斯分布。</li>
<li>对于不同的时间t，x_t相对于原始图像的扰动程度是不同的。作者的生成器只需要预测未经扰动的x_0燃火再利用$$加回扰动</li>
</ol>
<p><img src="https://pic4.zhimg.com/80/v2-ecf3b5a746af919383819f765456827f_720w.webp" alt="img"></p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>/2024/04/14/vscode%E9%85%8D%E7%BD%AElatex/</url>
    <content><![CDATA[<p><img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240414093501867.png" alt="image-20240414093501867"></p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240414093602496.png" alt="image-20240414093602496"></p>
<figure class="highlight prolog"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;latex-workshop.latex.autoBuild.run&quot;</span>: <span class="string">&quot;never&quot;</span>,</span><br><span class="line">    <span class="string">&quot;latex-workshop.showContextMenu&quot;</span>: true,</span><br><span class="line">    <span class="string">&quot;latex-workshop.intellisense.package.enabled&quot;</span>: true,</span><br><span class="line">    <span class="string">&quot;latex-workshop.message.error.show&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;latex-workshop.message.warning.show&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;latex-workshop.latex.tools&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;xelatex&quot;</span>,</span><br><span class="line">            <span class="string">&quot;command&quot;</span>: <span class="string">&quot;xelatex&quot;</span>,</span><br><span class="line">            <span class="string">&quot;args&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;-synctex=1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;-interaction=nonstopmode&quot;</span>,</span><br><span class="line">                <span class="string">&quot;-file-line-error&quot;</span>,</span><br><span class="line">                <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;pdflatex&quot;</span>,</span><br><span class="line">            <span class="string">&quot;command&quot;</span>: <span class="string">&quot;pdflatex&quot;</span>,</span><br><span class="line">            <span class="string">&quot;args&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;-synctex=1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;-interaction=nonstopmode&quot;</span>,</span><br><span class="line">                <span class="string">&quot;-file-line-error&quot;</span>,</span><br><span class="line">                <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;latexmk&quot;</span>,</span><br><span class="line">            <span class="string">&quot;command&quot;</span>: <span class="string">&quot;latexmk&quot;</span>,</span><br><span class="line">            <span class="string">&quot;args&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;-synctex=1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;-interaction=nonstopmode&quot;</span>,</span><br><span class="line">                <span class="string">&quot;-file-line-error&quot;</span>,</span><br><span class="line">                <span class="string">&quot;-pdf&quot;</span>,</span><br><span class="line">                <span class="string">&quot;-outdir=%OUTDIR%&quot;</span>,</span><br><span class="line">                <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;bibtex&quot;</span>,</span><br><span class="line">            <span class="string">&quot;command&quot;</span>: <span class="string">&quot;bibtex&quot;</span>,</span><br><span class="line">            <span class="string">&quot;args&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;%DOCFILE%&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;latex-workshop.latex.recipes&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;XeLaTeX&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tools&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;xelatex&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;PDFLaTeX&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tools&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;pdflatex&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;BibTeX&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tools&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;bibtex&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;LaTeXmk&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tools&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;latexmk&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;xelatex -&gt; bibtex -&gt; xelatex*2&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tools&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;xelatex&quot;</span>,</span><br><span class="line">                <span class="string">&quot;bibtex&quot;</span>,</span><br><span class="line">                <span class="string">&quot;xelatex&quot;</span>,</span><br><span class="line">                <span class="string">&quot;xelatex&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;pdflatex -&gt; bibtex -&gt; pdflatex*2&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tools&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;pdflatex&quot;</span>,</span><br><span class="line">                <span class="string">&quot;bibtex&quot;</span>,</span><br><span class="line">                <span class="string">&quot;pdflatex&quot;</span>,</span><br><span class="line">                <span class="string">&quot;pdflatex&quot;</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;latex-workshop.latex.clean.fileTypes&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;*.aux&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.bbl&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.blg&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.idx&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.ind&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.lof&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.lot&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.out&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.toc&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.acn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.acr&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.alg&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.glg&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.glo&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.gls&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.ist&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.fls&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.log&quot;</span>,</span><br><span class="line">        <span class="string">&quot;*.fdb_latexmk&quot;</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;latex-workshop.latex.autoClean.run&quot;</span>: <span class="string">&quot;onFailed&quot;</span>,</span><br><span class="line">    <span class="string">&quot;latex-workshop.latex.recipe.default&quot;</span>: <span class="string">&quot;lastUsed&quot;</span>,</span><br><span class="line">    <span class="string">&quot;latex-workshop.view.pdf.internal.synctex.keybinding&quot;</span>: <span class="string">&quot;double-click&quot;</span></span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>宠修</title>
    <url>/2024/03/31/%E5%AE%A0%E4%BF%AE/</url>
    <content><![CDATA[<h1 id="秘传"><a href="#秘传" class="headerlink" title="秘传"></a>秘传</h1><p><strong>每天10点准时抢点</strong></p>
<p>缴纳28w现金和28w储备</p>
<p>任务上交1-2个环装</p>
<p>能提供150-200的修炼值和大量三界功绩(能换免费精力)</p>
<p>月修炼值最低：30*150=4500</p>
<h1 id="牧场"><a href="#牧场" class="headerlink" title="牧场"></a>牧场</h1><p>4000</p>
]]></content>
      <categories>
        <category>游戏</category>
        <category>梦幻西游</category>
      </categories>
  </entry>
  <entry>
    <title>密码学论文</title>
    <url>/2024/04/12/%E5%AF%86%E7%A0%81%E5%AD%A6%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>在这个大数据处理、云计算、物联网等创新技术的现代时代，多媒体信息的利用日益增长。与其他形式的多媒体相比，视频在众多的多媒体物联网(IoMT)应用中被广泛利用并通过互联网和通信网络传输。因此，由于第三方对传输和存储的数字多媒体数据的利用和伪造，在现代通信网络上实现安全视频传输是非常必要的。目前在云和移动设备之间安全通信多媒体内容的方法在处理负载、内存支持、数据大小和电池电量方面受到限制。这些方法不是大型多媒体内容的最佳解决方案，也不适合移动设备和云的有限资源。<strong>高效视频编码(HEVC)</strong>是最新的现代视频编解码器标准，旨在有效地存储和流式传输具有合适大小和更高质量的高分辨率视频。本文提出了一种结合<strong>DNA(脱氧核糖核酸)序列</strong>、<strong>Arnold混沌映射</strong>和<strong>Mandelbrot集的新型混合密码系统</strong>，用于<strong>压缩HEVC流的安全传输</strong>。首先，采用H.265/HEVC编解码器对高分辨率视频进行编码，以达到高效的压缩性能;随后，将建议的Arnold混沌映射加密过程分别应用于压缩后的HEVC帧的三个信道(Y、U、V)上。然后，在先前混沌加密过程产生的主加密帧上建立DNA编码序列。然后，提出了一种改进的基于Mandelbrot集的条件移位过程，有效地引入了最终加密帧的Y、U和V信道上的混淆特征。大量的仿真结果和安全性分析表明，与文献密码系统相比，所提出的HEVC密码系统具有惊人的鲁棒性和安全性。</p>
<h1 id="HEVC-编码"><a href="#HEVC-编码" class="headerlink" title="HEVC 编码"></a>HEVC 编码</h1><p>HEVC（高效视频编码）是一种先进的视频压缩标准，也被称为H.265和MPEG-H part 2。它是广泛使用的AVC（H.264或MPEG-4第10部分）的潜在后继者之一。HEVC的主要优势在于，在相同视频质量水平下，它能够提供大约两倍的数据压缩比，或者在相同的比特率下显著提高视频质量。这种编码标准支持高达8192×4320的分辨率，包括8K UHD（超高清）视频。1</p>
<p>HEVC/H.265视频编解码标准由ISO与ITU共同制定，旨在提高压缩率、降低网络带宽，同时保证视频质量。它支持更大的视频尺寸和更精细的编码控制，适用于对视频质量要求更高的场合。HEVC的实现包括YUV视频信号与位流之间的相互转换。编码过程涉及将YUV视频信号经过通用编码控制得到通用控制数据，然后经过变换、缩放、量化得到量化的变换系数，接着通过帧内估计得到帧内预测数据，经过滤波控制分析得到滤波控制数据，并通过运动估计得到运动数据。这些中间结果数据加上头信息和CABAC（上下文自适应二进制算术编码）编码，最终得到编码的位流数据。解码过程则是这些编码数据的逆过程，包括位流数据的缩放、反变换、滤波控制分析、帧内估计、帧内预测、运动补偿和去块SAO滤波，最终得到视频信号。</p>
<h1 id="DNA编码序列"><a href="#DNA编码序列" class="headerlink" title="DNA编码序列"></a>DNA编码序列</h1><p>一个链DNA，由四个不同的基本核苷酸组成：腺嘌呤( A)、胸腺嘧啶(T)、胞嘧啶(C)和鸟嘌呤(G)，这4种核苷酸能够结合在一起形成一条长序列，且A与T配对，C与G配对，00与11互补，01与10互补。这样的编码方案有24种，但只有8种编码方案满足Watson-Crick规则，如表1。</p>
<p><img src="https://blog-file.jiamisoft.com/wp-content/uploads/2015/07/16.jpg?x-oss-process=image/interlace,1/quality,Q_70" alt="图像文件加密算法之DNA编码和斜帐篷映射"></p>
<h1 id="Mandelbrot集合"><a href="#Mandelbrot集合" class="headerlink" title="Mandelbrot集合"></a>Mandelbrot集合</h1><p>基本思想是它是一个可以在复平面上表示的点的集合。这个平面上的每个点都可以用复数c∈c来表示，用c = x jy来表示，其中x, y∈r。</p>
<h1 id="混沌加密"><a href="#混沌加密" class="headerlink" title="混沌加密"></a>混沌加密</h1><script type="math/tex; mode=display">
\left[ \begin{array}{c}
    x'\\
    y'\\
\end{array} \right] =A\left[ \begin{array}{c}
    x\\
    y\\
\end{array} \right] \left( \text{mod\ N} \right) ,A=\left[ \begin{matrix}
    1&        1\\
    1&        2\\
\end{matrix} \right]</script><script type="math/tex; mode=display">
\left[ \begin{array}{c}
    x_n\\
    y_n\\
\end{array} \right] =A^n\left[ \begin{array}{c}
    x_0\\
    y_0\\
\end{array} \right] \left( \text{mod\ N} \right) ,A=\left[ \begin{matrix}
    1&        1\\
    1&        2\\
\end{matrix} \right]</script><p>图像加密也称图像置乱, 是对图像的像素进行混乱和扩散, 使加密后的图像在视觉上无法获得有效信息.空域加密是常用的方法, 分为空域置乱和序列加密.空域置乱是对像素坐标进行变换使其混乱, 解密时恢复原像素坐标.图像的加密既可以作为独立的信息隐藏方法, 也可以用来作为数字水印技术中图像水印的预处理。</p>
<p>然而此时的加密并不完全可靠, 若已知采用Arnold变换作为加密方式, 则通过暴力求解法, 经过若干次的变换还是可以解密出原图.因此在一般情况下, 我们往往需要在Arnold变换中加入密钥 (ku, kv) , 以提高安全性</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{c}
    x_n\\
    y_n\\
\end{array} \right] =A^n\left[ \begin{array}{c}
    x_0\\
    y_0\\
\end{array} \right] +\left[ \begin{array}{c}
    ku\\
    kv\\
\end{array} \right] \left( \text{mod\ N} \right) \left( n=1,2,... \right) ,A=\left[ \begin{matrix}
    1&        1\\
    1&        2\\
\end{matrix} \right]</script><p><strong>基于三维Arnold变换的图像加密</strong></p>
<script type="math/tex; mode=display">
\left[ \begin{array}{c}
    r'\\
    g'\\
    b'\\
\end{array} \right] =A\left[ \begin{array}{c}
    r\\
    g\\
    b\\
\end{array} \right] \left( \text{mod\ N} \right) ,A=\left[ \begin{matrix}
    1&        1&        1\\
    1&        2&        2\\
    1&        2&        3\\
\end{matrix} \right]</script><h1 id="混合密码系统"><a href="#混合密码系统" class="headerlink" title="混合密码系统"></a>混合密码系统</h1><p>建议的HEVC密码系统包括三个主要阶段</p>
<p>(1)基于混沌映射序列的密钥流生成;</p>
<p>(2) DNA序列编码;</p>
<p>(3) 扩散混淆处理。</p>
<p>在IoMT应用中，当HEVC流传输时，该混合HEVC密码系统可以生成一种高度加密的纯压缩HEVC帧，使其不被入侵者破坏。加密过程可以用于任何hevc帧，无论大小，无论其内容特征如何。</p>
<h2 id="混沌密钥生成"><a href="#混沌密钥生成" class="headerlink" title="混沌密钥生成"></a>混沌密钥生成</h2><p>选择Arnold混沌映射用于加密过程</p>
<p>步骤(1):通过所使用的Arnold混沌映射(重复Arnold混沌映射t次，通过Eq.(2)生成Km)生成由三个混沌序列(S1、S2和S3)生成的三个密钥流(K1、K2和K3)。</p>
<p>步骤(2):对得到的K1、K2、K3进行DNA序列编码处理</p>
<h2 id="DNA序列编码"><a href="#DNA序列编码" class="headerlink" title="DNA序列编码"></a>DNA序列编码</h2><p>步骤(3):分离输入压缩HEVC帧的Y、U、V三个主要分量。</p>
<p>步骤(4):估计生成的关键流Ki与分解后的Y、U、V三个矩阵之间的汉明距离值，如式所示。(4)至(6)。</p>
<p>步骤(5):采用dna在HY、HU和hv上编码的策略，得到EHY、EHU和EHV dna序列的矩阵，如式所示。(7)至(9)。</p>
<p>步骤(6):将(3)给出的关键流生成的DNA序列与(7)到(9)给出的编码DNA序列的估计矩阵进行异或运算。</p>
<h1 id="阶段1-混沌密码生成"><a href="#阶段1-混沌密码生成" class="headerlink" title="阶段1 混沌密码生成"></a>阶段1 混沌密码生成</h1><p>CHAOTIC SECRET KEYGENERATION</p>
<h2 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1"></a>Step 1</h2><p>使用Arnold混沌映射(重复Arnold混沌映射t次)通过以下式子生成三个混沌序列(chaotic sequences)(S1,S2,S3)</p>
<p>产生三个秘密密匙流(K1,K2,K3)</p>
<script type="math/tex; mode=display">
K_m=Mod\left( \left( S_m\times 10^{10} \right) ,256 \right) \ \left( \text{for\ }m=1,2,\text{and}3 \right)</script><p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240417191821165.png" alt="image-20240417191821165"></p>
<h2 id="Step-2"><a href="#Step-2" class="headerlink" title="Step 2"></a>Step 2</h2><p>利用DNAEncode(·)函数对得到的K1、K2、K3进行DNA序列编码处理，得到与输入HEVC帧大小相同的DNA序列(E1、E2、E3)碱基，如式所示。</p>
<script type="math/tex; mode=display">
E_i=DNAEncode\left( K_i \right)</script><p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240417191853861.png" alt="image-20240417191853861"></p>
<h1 id="阶段2-DNA序列编码"><a href="#阶段2-DNA序列编码" class="headerlink" title="阶段2 DNA序列编码"></a>阶段2 DNA序列编码</h1><p>DNA SEQUENCES ENCODING</p>
<h2 id="Step-3"><a href="#Step-3" class="headerlink" title="Step 3"></a>Step 3</h2><p>分离输入压缩HEVC帧的三个主要Y, U和V分量。</p>
<h2 id="Step-4"><a href="#Step-4" class="headerlink" title="Step 4"></a>Step 4</h2><p>估计生成的密码流(Ki)与分解后的Y、U、V矩阵之间的汉明距离值。</p>
<script type="math/tex; mode=display">
H_Y\left( m,n \right) =HM\left( Y\left( m,n \right) ,K_1\left( m,n \right) \right)</script><script type="math/tex; mode=display">
H_U\left( m,n \right) =HM\left( U\left( m,n \right) ,K_2\left( m,n \right) \right)</script><script type="math/tex; mode=display">
H_V\left( m,n \right) =HM\left( V\left( m,n \right) ,K_3\left( m,n \right) \right)</script><p>利用生成的关键流与视频帧的三个分解的Y、U和V矩阵之间的汉明距离估计的目的是为了避免使用阿诺德映射可能导致的缺点。已知由Arnold映射得到的状态在多次迭代后可能是周期性的。</p>
<h2 id="Step-5"><a href="#Step-5" class="headerlink" title="Step 5"></a>Step 5</h2><p>采用在HY、HU和hv上进行dna编码的策略，生成EHY、EHU和EHV dna序列的矩阵.</p>
<script type="math/tex; mode=display">
EH_Y=DNAEncode\left( H_Y \right)</script><script type="math/tex; mode=display">
EH_U=DNAEncode\left( H_U \right)</script><script type="math/tex; mode=display">
EH_V=DNAEncode\left( H_V \right)</script><h2 id="Step-6"><a href="#Step-6" class="headerlink" title="Step 6"></a>Step 6</h2><p>将密钥流生成的DNA序列与编码DNA序列的估计矩阵进行异或运算。</p>
<script type="math/tex; mode=display">
X_Y=XOR\left( EH_Y,E_1 \right)</script><script type="math/tex; mode=display">
X_U=XOR\left( EH_U,E_2 \right)</script><script type="math/tex; mode=display">
X_V=XOR\left( EH_V,E_3 \right)</script><h1 id="阶段3-扩散-混淆过程"><a href="#阶段3-扩散-混淆过程" class="headerlink" title="阶段3 扩散-混淆过程"></a>阶段3 扩散-混淆过程</h1><p>步骤(7):采用基于以下子步骤的混淆扩散过程，生成视频帧分量CY、CU和CV，并将它们连接起来，生成最终的加密压缩HEVC帧。混淆扩散的主要步骤描述如下</p>
<h2 id="Step-1-1"><a href="#Step-1-1" class="headerlink" title="Step 1"></a>Step 1</h2><p>得到输入压缩HEVC帧的Y、U、V分量的编码DNA序列的估计值</p>
<script type="math/tex; mode=display">
E_Y=DNAEncode\left( Y \right)</script><script type="math/tex; mode=display">
E_U=DNAEncode\left( U \right)</script><script type="math/tex; mode=display">
E_V=DNAEncode\left( V \right)</script><h2 id="Step-2-1"><a href="#Step-2-1" class="headerlink" title="Step 2"></a>Step 2</h2><p>接收E1、E2、E3秘钥流的编码DNA序列。</p>
<h2 id="Step-3-1"><a href="#Step-3-1" class="headerlink" title="Step 3"></a>Step 3</h2><p>在密码流的编码DNA序列和YUV组分的编码DNA序列之间采用基于xor的DNA处理</p>
<script type="math/tex; mode=display">
XE_Y\left( m \right) =DNAXor\left( E_Y\left( m \right) ,E_1\left( m \right) \right)</script><script type="math/tex; mode=display">
XE_U\left( m \right) =DNAXor\left( E_U\left( m \right) ,E_2\left( m \right) \right)</script><script type="math/tex; mode=display">
XE_V\left( m \right) =DNAXor\left( E_V\left( m \right) ,E_3\left( m \right) \right)</script><h2 id="Step-4-1"><a href="#Step-4-1" class="headerlink" title="Step 4"></a>Step 4</h2><p>在得到的XEY、XEU和XEV上，采用算法(2)步骤中所描述的提出的条件移位机制，生成SY、SU和SV的密钥。</p>
<h2 id="Step-5-1"><a href="#Step-5-1" class="headerlink" title="Step 5"></a>Step 5</h2><p>将DNA解码过程应用于DNA序列编码阶段(2)所传递的结果，如式所示。(19)至(21)。</p>
<script type="math/tex; mode=display">
D_Y=DNADecode\left( X_Y \right)</script><script type="math/tex; mode=display">
D_U=DNADecode\left( X_U \right)</script><script type="math/tex; mode=display">
D_V=DNADecode\left( X_V \right)</script><h2 id="Step-6-1"><a href="#Step-6-1" class="headerlink" title="Step 6"></a>Step 6</h2><p>执行基于Bit异或处理的扩散处理，得到加密后的视频帧分量CY;和CV，合并得到最终的加密压缩HEVC帧，如式所示。</p>
<script type="math/tex; mode=display">
C_Y\left( m \right) =\left( BitXor\left( S_Y\left( m \right) ,D_Y\left( m \right) \right) \right) \ mod\ 256</script><script type="math/tex; mode=display">
C_U\left( m \right) =\left( BitXor\left( S_U\left( m \right) ,D_U\left( m \right) \right) \right) \,\,mod\,\,256</script><script type="math/tex; mode=display">
C_V\left( m \right) =\left( BitXor\left( S_V\left( m \right) ,D_V\left( m \right) \right) \right) \,\,mod\,\,256</script>]]></content>
      <categories>
        <category>计算机</category>
        <category>密码学</category>
      </categories>
  </entry>
  <entry>
    <title>幂率分布</title>
    <url>/2024/04/07/%E5%B9%82%E7%8E%87%E5%88%86%E5%B8%83/</url>
    <content><![CDATA[<h1 id="幂率分布"><a href="#幂率分布" class="headerlink" title="幂率分布"></a>幂率分布</h1><h2 id="概率函数"><a href="#概率函数" class="headerlink" title="概率函数"></a>概率函数</h2><p>假设变量x服从参数为 $\alpha$的幂率分布,其概率密度函数可以表示为</p>
<script type="math/tex; mode=display">
f(x)=cx^{-\alpha-1},x→∞</script><h2 id="通式"><a href="#通式" class="headerlink" title="通式"></a>通式</h2><script type="math/tex; mode=display">
lny=lnc-rlnx</script><h2 id="图像"><a href="#图像" class="headerlink" title="图像"></a>图像</h2><p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240407112450949.png" alt="image-20240407112450949"></p>
<h1 id="灰度直方图"><a href="#灰度直方图" class="headerlink" title="灰度直方图"></a>灰度直方图</h1><p>我们选用高对比度的图片high.png</p>
<p><img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240407110728665.png" alt="image-20240407110728665"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图片</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(<span class="string">&#x27;high.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将图片转换为灰度图像</span></span><br><span class="line">gray_image = image.convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算像素值的分布</span></span><br><span class="line">pixel_values = np.array(gray_image.histogram())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制直方图</span></span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="number">256</span>), pixel_values, color=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Pixel Value&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Image Histogram&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示直方图</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240407110851156.png" alt="image-20240407110851156"></p>
<p>随后我们将用幂率分布对其进行拟合</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 幂律分布的参数  </span></span><br><span class="line">alpha = <span class="number">3.0</span>  <span class="comment"># 幂律分布的指数  </span></span><br><span class="line">xmin = <span class="number">10.0</span>  <span class="comment"># 最小值  </span></span><br><span class="line">xmax = <span class="number">250.0</span>  <span class="comment"># 最大值  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建x值的数组  </span></span><br><span class="line">x = np.linspace(xmin, xmax, <span class="number">1000</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 计算幂律分布的概率密度函数值  </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">power_law_pdf</span>(<span class="params">x, alpha, xmin</span>):  </span><br><span class="line">    <span class="keyword">return</span> alpha * (xmin ** alpha) / x ** (alpha + <span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">y = <span class="number">300000</span>*power_law_pdf(x, alpha, xmin)+<span class="number">3000</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 绘制幂律分布曲线  </span></span><br><span class="line">plt.plot(x, y, label=<span class="string">f&#x27;Power Law Distribution (alpha=<span class="subst">&#123;alpha&#125;</span>)&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 设置标题和坐标轴标签  </span></span><br><span class="line">plt.title(<span class="string">&#x27;Power Law Distribution Curve&#x27;</span>)  </span><br><span class="line">plt.xlabel(<span class="string">&#x27;Value&#x27;</span>)  </span><br><span class="line">plt.ylabel(<span class="string">&#x27;Probability Density&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 显示图例  </span></span><br><span class="line">plt.legend()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 显示图形  </span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240407111013470.png" alt="image-20240407111013470"></p>
<p>或者我们把直方图均匀化</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">image = cv2.imread(<span class="string">r&#x27;high.png&#x27;</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">equ = cv2.equalizeHist(image)</span><br><span class="line">plt.hist(equ.ravel(), <span class="number">256</span>)</span><br><span class="line">plt.show()</span><br><span class="line">cv2.imshow(<span class="string">&#x27;result&#x27;</span>, equ)</span><br><span class="line">cv2.waitKey()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240407111210016.png" alt="image-20240407111210016"></p>
<p><strong>在对其</strong>进行拟合</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">image = cv2.imread(<span class="string">r&#x27;high.png&#x27;</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">equ = cv2.equalizeHist(image)</span><br><span class="line">plt.hist(equ.ravel(), <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 幂律分布的参数  </span></span><br><span class="line">alpha = <span class="number">10.0</span>  <span class="comment"># 幂律分布的指数  </span></span><br><span class="line">xmin = <span class="number">70.0</span>  <span class="comment"># 最小值  </span></span><br><span class="line">xmax = <span class="number">250.0</span>  <span class="comment"># 最大值  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建x值的数组  </span></span><br><span class="line">x = np.linspace(xmin, xmax, <span class="number">1000</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 计算幂律分布的概率密度函数值  </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">power_law_pdf</span>(<span class="params">x, alpha, xmin</span>):  </span><br><span class="line">    <span class="keyword">return</span> alpha * (xmin ** alpha) / x ** (alpha + <span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line">y = <span class="number">500000</span>*power_law_pdf(x, alpha, xmin)+<span class="number">3000</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 绘制幂律分布曲线  </span></span><br><span class="line">plt.plot(x, y, label=<span class="string">f&#x27;Power Law Distribution (alpha=<span class="subst">&#123;alpha&#125;</span>)&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 设置标题和坐标轴标签  </span></span><br><span class="line">plt.title(<span class="string">&#x27;Power Law Distribution Curve&#x27;</span>)  </span><br><span class="line">plt.xlabel(<span class="string">&#x27;Value&#x27;</span>)  </span><br><span class="line">plt.ylabel(<span class="string">&#x27;Probability Density&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 显示图例  </span></span><br><span class="line">plt.legend()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 显示图形  </span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240407112133007.png" alt="image-20240407112133007"></p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>扩散小波</title>
    <url>/2024/04/12/%E6%89%A9%E6%95%A3%E5%B0%8F%E6%B3%A2/</url>
    <content><![CDATA[<h1 id="论文阅读"><a href="#论文阅读" class="headerlink" title="论文阅读"></a>论文阅读</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>扩散模型作为一种强大的高保真图像生成解决方案正在崛起，在许多情况下，其质量超过了gan。然而，它们缓慢的训练和推理速度是一个巨大的瓶颈，阻碍了它们在实时应用中的应用。最近的一种扩散GAN方法通过将采样步骤从数千个减少到几个，显著地减少了模型的运行时间，但它们的速度仍然大大落后于GAN的同类。本文提出了一种新的基于小波的扩散方案来减小速度差距。我们通过小波分解从图像和特征层提取低频和高频成分，并自适应处理这些成分，以提高处理速度，同时保持良好的生成质量。此外，我们提出使用重构项，有效地提高了模型训练的收敛性。在CelebA-HQ, CIFAR-10, LSUN-Church和STL-10数据集上的实验结果表明，我们的解决方案是提供实时和高保真扩散模型的基石。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>这些模型将扩散过程还原为从随机噪声输入生成干净、高质量的输出。这些技术应用于各种数据领域和应用程序，但在图像生成任务中表现出最显著的成功。在各种数据集上，扩散模型在生成质量上优于最先进的生成对抗网络(GANs)[4,38]。更值得注意的是，扩散模型提供了更好的模式覆盖[14,22,41]，并提供了一种灵活的方式来处理不同类型的条件输入，例如语义地图、文本、表示和图像[36]。。最近基于扩散的文本到图像生成模型[1,34,38]允许用户仅通过文本输入生成令人难以置信的逼真图像，开启了基于人工智能的数字艺术的新时代，并有望应用于其他各种领域。</p>
<p>尽管扩散模型显示出巨大的潜力，但它的运行速度非常慢，这是一个关键的弱点，阻碍了它们像gan一样被广泛采用。基础工作去噪扩散概率模型(Denoising Diffusion Probabilistic Models, ddpm)[13]需要1000个采样步骤来产生所需的输出质量，需要几分钟才能生成一张图像。已经提出了许多减少推理时间的技术[25,40]，主要是通过减少采样步骤。然而，在DiffusionGAN之前最快的算法仍然需要几秒钟才能生成32×32图像，这比GAN慢了大约100倍。DiffusionGAN[50]通过将扩散和gan结合在一个系统中，在提高推理速度方面取得了突破性进展，最终将采样步骤减少到4步，生成32×32图像的推理时间缩短到几分之一秒。</p>
<p>尽管如此，它至少比StyleGAN慢4倍，并且随着输出分辨率的增加，速度差距不断扩大。此外，DiffusionGAN仍然需要较长的训练时间和较慢的收敛速度，这证实了扩散模型还没有为大规模或实时应用做好准备。</p>
<p>本文旨在通过引入一种新的基于小波的扩散方案来弥补速度差距。我们的解决方案依赖于离散小波变换，它将每个输入分解为低(LL)和高频(LH, HL, HH)分量的四个子带。我们在图像和特征级别上应用该变换。这使我们能够在保持输出质量相对不变的情况下显著减少训练和推理时间。在图像级别上，我们通过将空间分辨率降低四倍来获得高速提升。在特征层面上，我们强调了小波信息在发生器不同块上的重要性。通过这样的设计，我们可以在只产生边际计算开销的情况下获得相当大的性能改进。</p>
<p>我们提出的小波扩散提供了最先进的训练和推理速度，同时保持了高生成质量，通过包括CIFAR-10, STL-10, CelebA-HQ和LSUN-Church在内的标准基准实验得到了彻底的证实。我们的模型显著减少了扩散模型和gan之间的速度差距，针对大规模和实时系统。</p>
<ul>
<li>我们提出了一种新的小波扩散框架，该框架利用小波子带的降维来加速扩散模型，同时通过高频分量保持生成结果的良好视觉质量。</li>
<li>我们在图像和特征空间中使用小波分解来提高生成模型的鲁棒性和执行速度。</li>
<li>我们提出的小波扩散提供了最先进的训练和推理速度，这是实现实时和高保真扩散模型的基石。</li>
</ul>
<h2 id="相关知识"><a href="#相关知识" class="headerlink" title="相关知识"></a>相关知识</h2><h3 id="小波方法"><a href="#小波方法" class="headerlink" title="小波方法"></a>小波方法</h3><p>真实世界的数据或者信号经常表现出缓慢变化的趋势或因瞬态而出现的震荡，另一方面，图像具有被边缘中断或者<a href="https://so.csdn.net/so/search?q=对比度&amp;spm=1001.2101.3001.7020">对比度</a>突然变化的平滑区域，傅里叶变换不能有效代表突然的变化，这是因为傅里叶变换将数据表示为未在时间或空间上定位的正弦波之和，这些正弦波永远震荡。</p>
<p>为了很好准确分析突然变化的信号和图像，我们需要使用在时间和频率上都很好定位的一类新功能，就是小波变换。</p>
<p><img src="https://img-blog.csdnimg.cn/d21153ae0c584ae19888a8a4167e1b23.png" alt="img"></p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="基于小波的扩散方案"><a href="#基于小波的扩散方案" class="headerlink" title="基于小波的扩散方案"></a>基于小波的扩散方案</h3><p>首先，我们描述了如何在扩散过程中引入小波变换。我们将输入图像分解为四个小波子带，并将它们作为单个目标连接起来进行去噪处理(如图2所示)。这种模型不是在原始图像空间上执行，而是在小波谱上执行。因此，我们的模型可以利用高频信息来进一步增加生成图像的细节。同时，小波子带的空间面积比原始图像小4倍，大大降低了采样过程的计算复杂度。</p>
<p><img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240422172619071.png" alt="image-20240422172619071"></p>
<p>我们的方法建立在DDGAN模型上，其中输入是小波变换的4个小波子带。给定输入图像x∈R3×H×W，我们将其分解为一组低、高子带，并将它们进一步连接形成矩阵y∈R12×H 2 ×W 2。</p>
<p>然后，该输入通过第一个线性层投射到基本通道D，与DDGAN相比，保持网络宽度不变。因此，大多数网络都受益于空间维度减少4倍，大大减少了计算量。</p>
<p>设y0为时间步长为t的干净样本，而yt为从q(yt|y0)采样的损坏样本。在去噪过程中，生成器接收变量yt的元组，潜函数z ~ N(0, I)和时间步长t，以生成原始信号y0的近似值:y ‘ 0 = G(yt, z, t)。然后从可处理的后验分布q(yt - 1|yt, y ‘ 0)中提取预测的噪声样本y ‘ t - 1。鉴别器的作用是区分实对(yt - 1, yt)和假对(y ‘ t - 1, yt)。</p>
<p>根据[50]，我们通过对抗性损失来优化生成器和鉴别器</p>
<p>在Eq.(4)中的对抗目标基础上，我们增加了一个重构项，既防止了频率信息的丢失，又保持了小波子带的一致性。它被表示为生成的图像与其基真值之间的L1损失:</p>
<p>生成器的总体目标是对抗损失和重建损失的线性组合:</p>
<p>经过定义的几个采样步骤后，我们获得了估计的去噪子带y ‘ 0。最后的图像可以通过小波逆变换x ‘ 0 = IWT(y ‘ 0)恢复。我们在算法1中描述了采样过程。</p>
<h3 id="小波嵌入网络"><a href="#小波嵌入网络" class="headerlink" title="小波嵌入网络"></a>小波嵌入网络</h3><p>接下来，我们通过生成器将小波信息进一步纳入特征空间，增强对高频成分的感知。这有利于最终图像的清晰度和质量。</p>
<p>图3说明了我们提出的小波嵌入发生器的结构。它遵循[44]的UNet结构，M个下采样和M个上采样块，加上相同分辨率的块之间的跳过连接，M是预定义的。然而，我们没有使用正常的下采样和上采样算子，而是用频率感知块代替它们。在最低分辨率下，我们采用频率瓶颈块来更好地关注低频和高频组件。最后，为了将原始信号Y合并到编码器的不同特征金字塔中，我们使用小波下采样层引入了频率残差连接。设Y为输入图像，Fi为Y的第i个中间特征映射。我们将在下面讨论新引入的分量:.</p>
<p>频率感知下采样和上采样块。传统方法依赖于模糊核的下采样和上采样过程，以减轻混叠伪影。相反，我们利用小波变换的固有特性来进行更好的上采样和下采样(如图4所示)。实际上，这加强了对这些操作的高频信息的认识。特别是，下采样块接收输入特征Fi、潜伏z和时间嵌入t的元组，然后通过一系列层处理以返回下采样特征和高频子带。这些返回的子带作为基于上采样块中的频率线索的上采样特征的额外输入。</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240422173330672.png" alt="image-20240422173330672"></p>
<p>嵌入式小波发生器的说明。为了简化，忽略时间步嵌入t和潜嵌入z，而是将它们注入到去噪过程的各个块中。输入是时间步长为t的形状为[12 × H × W]的噪声小波子带，这些子带由我们提出的一系列组件处理，包括频率感知的上采样和下采样块、频率残差连接和一个全新的频率瓶颈块。模型的输出是无扰动输入的近似值。</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240422173429792.png" alt="image-20240422173429792"></p>
<p>频率瓶颈块位于中间阶段，中间包括两个频率瓶颈块和一个注意块。每个频率瓶颈块首先将特征映射Fi划分为低频子带Fi、ll和高频子带Fi、H的拼接。然后将Fi,ll作为输入传递给重新分配块以进行更深入的处理。处理后的低频特征映射和原高频子带Fi、H通过IWT变换回原空间。有了这样的瓶颈，该模型可以专注于学习低频子带的中间特征表示，同时保留高频细节。</p>
<p>[44]中网络的原始设计通过跨行卷积下采样层将原始信号Y合并到编码器的不同特征金字塔中。相反，我们使用小波下采样层将输入Y的剩余快捷方式映射到相应的特征维度，然后将其添加到每个特征金字塔中。具体来说，Y的残差捷径被分解成四个子带，然后将这些子带连接并馈送到卷积层进行特征投影。这个捷径的目的是丰富对特征嵌入的频率源的感知。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文介绍了一种新的基于小波的扩散方案，该方案在图像保真度和采样速度方面都有优异的性能。通过对图像和特征空间进行小波变换，我们的方法可以达到扩散模型最先进的运行速度，缩小了与StyleGAN模型[19,20,57]的差距，同时获得与StyleGAN2和其他扩散模型相当的图像生成质量。此外，我们的方法提供了比基线DDGAN更快的收敛速度[50]，证实了我们提出的框架的效率。有了这些初步结果，我们希望我们的方法可以促进未来对实时和高保真扩散模型的研究。</p>
<h1 id="代码解读"><a href="#代码解读" class="headerlink" title="代码解读"></a>代码解读</h1>]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>扩散模型DDPM</title>
    <url>/2024/04/11/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>扩散模型的基石：<strong>DDPM(Denoising Diffusion Probalistic Models)</strong>[2020]</p>
<p>DDPM的本质作用，就是学习训练数据的分布，产出尽可能符合<strong>训练数据分布</strong>的真实图片。</p>
<h1 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h1><p>总体来说，DDPM的训练过程分为2步</p>
<ul>
<li>Diffusion Process (Forward Process)</li>
<li>Denoise Process (Reverse Process)</li>
</ul>
<p>而 DDPM 的目的是要去学习训练数据的分布，然后产出和训练数据分布相似的图片。</p>
<p><strong>思路</strong></p>
<p>拿一张干净的图，每一步(timestep)都往上加一点噪音，然后在每一步里，都让模型去找到加噪前图片的样子，也就是去噪。</p>
<p>训练完毕后，我们再拿出一张纯噪声图，让它帮我们还原出原始图片的分布。</p>
<ul>
<li>Diffusion Process:一步步加噪的过程</li>
<li>Denoise Process:一步步去噪的过程</li>
</ul>
<h2 id="Diffusion-Process"><a href="#Diffusion-Process" class="headerlink" title="Diffusion Process"></a>Diffusion Process</h2><p>Diffusion Process的命名受到热力学中分子扩散的启发：分子从高浓度区域扩散至低浓度区域，直至整个系统处于平衡。加噪过程也是同理，每次往图片上增加一些噪声，直至图片变为一个纯噪声为止。</p>
<p><img src="https://pic1.zhimg.com/80/v2-b09b3294fb90384713d784776508b680_720w.webp" alt="img"></p>
<p>我们对图片进行了1000步加噪，且每一步添加的都是高斯噪声，直到图片变成一个纯高斯分布的噪声。</p>
<p><strong>数字符号标记</strong></p>
<ul>
<li>$T$:总步数</li>
<li>$x_0,x_1,…,x_T$:每步产生的图片。其中$x_0$为原始图片,$x_T$为纯高斯噪声</li>
<li>$\epsilon \sim N\left( 0,I \right)$:为每一步添加的高斯噪声</li>
<li>$q\left( x<em>t|x</em>{t-1} \right) $:$x<em>t$在条件$x=x</em>{t-1}$下的概率分布。</li>
</ul>
<p>根据以上流程，我们有：$x<em>t=x</em>{t-1}+\epsilon=x_0+\epsilon_0+\epsilon_1+…+\epsilon$</p>
<p>但是，为了得到x_t，需要sample好多次噪声</p>
<p><strong>重参数</strong></p>
<p>为了解决这种不方便的情况，我们加入权重。</p>
<p>随着步数的增加，图片的原始信息越少，噪声越多。</p>
<p>于是乎，加入一系列常数$\bar{\alpha}_1,\bar{\alpha}_2,…,\bar{\alpha}_T$，随着T的增加越来越少</p>
<p>此时可以设置为</p>
<script type="math/tex; mode=display">
x_t=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon</script><p>这时，我们只需sample一次噪声，就可以从x_0得到x_t</p>
<p>那么使得$q\left( x<em>t|x</em>{t-1} \right) $转换成$q\left( x<em>t|x</em>{0} \right) $的过程，就成为重参数</p>
<h2 id="Denoise-Process"><a href="#Denoise-Process" class="headerlink" title="Denoise Process"></a>Denoise Process</h2><p>Denoise Process的过程与Diffusion Process刚好相反：给定x<em>t，让模型能把它还原到x</em>{t-1}。</p>
<p>用$q\left( x<em>t|x</em>{t-1} \right) $来表示加噪过程，则用$p\left( x<em>{t-1}|x</em>{t} \right) $来表示去噪过程</p>
<p>由于加噪过程是按照设定好的超参数进行前向加噪，不存在训练的过程。</p>
<p>但去噪过程是真正训练并使用模型的过程。于是我们再加入一个模型参数</p>
<p>即：$p<em>\theta\left( x</em>{t-1}|x_{t} \right) $</p>
<p>如图，从第T个timestep开始，模型的输入为x_t和当前的t，模型中还包含一个噪声预测器（UNet），它会根据当前的输入预测出噪声，然后，将当前图片减去预测出来的噪声，就得到去噪后的图片。且重复这个过程，直到还原原始图片x_0。</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/v2-bfb330873e0c590511bdc369dafcd037_r.jpg" alt="img"></p>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>在重参数的表达下，第t个时刻的输入图片可以表示为：</p>
<script type="math/tex; mode=display">
x_t=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon</script><p>而第t个时刻sample出的噪声$\epsilon \sim N\left( 0,I \right)$，为我们的噪声真值。</p>
<p>预测出来的噪声为：</p>
<script type="math/tex; mode=display">
\epsilon _{\theta}\left( \sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon ,t \right)</script><p>则loss为：</p>
<script type="math/tex; mode=display">
\epsilon -\epsilon _{\theta}\left( \sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon ,t \right)</script><p>我们要做的是将Loss最小化</p>
<p><strong>由于不管对任何输入数据，不管对它的任何一步，模型在每一步做的都是去预测一个来自高斯分布的噪声</strong>。因此，整个训练过程可以设置为：</p>
<ul>
<li>从训练数据中，sample出条x_0</li>
<li>随机sample出一个timestep</li>
<li>随机sample出一个噪声</li>
<li>计算Loss</li>
<li>计算梯度，更新模型，重复上述操作，直至收敛</li>
</ul>
<h2 id="Sampling"><a href="#Sampling" class="headerlink" title="Sampling"></a>Sampling</h2><p>将DDPM训练好后，我们该去使用它，并评估它</p>
<p>我们从最后一个时刻（T）开始，传入一个纯噪声（或者是一张加了噪声的图片），逐步去噪。</p>
<p>根据$x<em>t=\sqrt{\bar{\alpha}_t}x_0+\sqrt{1-\bar{\alpha}_t}\epsilon$ 可以推出 x_t与 x</em>{t-1}的关系(具体推导后面解释)</p>
<p>通过上述方式产生的 x_0 ，我们可以计算它和真实图片分布之间的相似度</p>
<p><strong>插值方法</strong></p>
<p>先对两张任意的真实图片做Diffusion过程，然后分别给它们的diffusion结果附不同的权重，将两者diffusion结果加权相加后，再做Denoise流程，就可以得到一张很有意思的”混合人脸”。</p>
<blockquote>
<p>这个方法很关键，有启发性，可以试试替代SBI</p>
</blockquote>
<h2 id="Unet"><a href="#Unet" class="headerlink" title="Unet"></a>Unet</h2><p>我们将它分为2部分</p>
<ul>
<li>Encoder</li>
<li>Decoder</li>
</ul>
<p><strong>在Encoder部分中，UNet模型会逐步压缩图片的大小；在Decoder部分中，则会逐步还原图片的大小</strong>。</p>
<p>时在Encoder和Deocder间，还会使用“<strong>残差连接</strong>”，确保Decoder部分在推理和还原图片信息时，不会丢失掉之前步骤的信息。整体过程示意图如下，因为压缩再放大的过程形似”U”字，因此被称为UNet.</p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/9577221c43fb4f0f9945df1d99ead8be.png" alt="img"></p>
<p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/9a30c7f9446e480783a807c6f9b3010f.png" alt="img"></p>
<h2 id="DownBlock和UpBlock"><a href="#DownBlock和UpBlock" class="headerlink" title="DownBlock和UpBlock"></a>DownBlock和UpBlock</h2><p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/v2-eccb6db63e1bc0d88a57455d46b7bac2_r.jpg" alt="img"></p>
<p>TimeEmbedding层采用和Transformer一致的三角函数位置编码，将常数转变为向量。Attention层则是沿着channel维度将图片拆分为token，做完attention后再重新组装成图片</p>
<p>需要关注的是，<strong>虚线部分即为“残差连接”（Residual Connection）</strong>，而残差连接之上引入的<strong>虚线框Conv的意思是</strong>，如果in_c = out_c，则对in_c做一次卷积，使得其通道数等于out_c后，再相加；否则将直接相加</p>
<h2 id="DownSample和UpSample"><a href="#DownSample和UpSample" class="headerlink" title="DownSample和UpSample"></a>DownSample和UpSample</h2><p>这个模块很简单，就是<strong>压缩(Conv)</strong>和<strong>放大(ConvT)</strong>图片的过程。</p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>提升计划</title>
    <url>/2024/04/22/%E8%BE%85%E5%8A%A9%E6%80%A7%E4%BB%B7%E6%AF%94%E6%8F%90%E5%8D%87%E8%AE%A1%E5%88%92/</url>
    <content><![CDATA[<h1 id="日常规划"><a href="#日常规划" class="headerlink" title="日常规划"></a>日常规划</h1><h2 id="单人日常"><a href="#单人日常" class="headerlink" title="单人日常"></a>单人日常</h2><p><strong>师门</strong></p>
<p>30分钟，30w梦幻币收益</p>
<p><strong>押镖</strong></p>
<p>30分钟，14w储备收益</p>
<p><strong>跑商</strong></p>
<p>20分钟，盈利20w类型，每天一大票，一周25w补贴，48*7帮贡</p>
<p><strong>牧场庭院</strong></p>
<p>10分钟，3天50w储备</p>
<p><strong>师徒</strong></p>
<p>20分钟，人修+善恶点+良师值+10w储备金</p>
<p><strong>天下物种</strong></p>
<p>有时间就做</p>
<h2 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h2><p><strong>乌鸡</strong></p>
<p>1小时</p>
<p><strong>金兜洞</strong></p>
<p>1小时</p>
<p><strong>大闹</strong></p>
<p>卖BOSS，35分钟</p>
<h2 id="周末"><a href="#周末" class="headerlink" title="周末"></a>周末</h2><p>铃铛、18门、文墨</p>
<h1 id="提升规划"><a href="#提升规划" class="headerlink" title="提升规划"></a>提升规划</h1><h2 id="阶段1：5-6月起步期"><a href="#阶段1：5-6月起步期" class="headerlink" title="阶段1：5,6月起步期"></a>阶段1：5,6月起步期</h2><h3 id="双抗15修"><a href="#双抗15修" class="headerlink" title="双抗15修"></a>双抗15修</h3><p>1500*2=3000w储备</p>
<p>需要2个月</p>
<h3 id="更新灵饰"><a href="#更新灵饰" class="headerlink" title="更新灵饰"></a>更新灵饰</h3><p>后排灵饰更新1个4段80级(防御+法防+格挡)，需1000w梦幻币</p>
<h3 id="升级145"><a href="#升级145" class="headerlink" title="升级145"></a>升级145</h3><p>混沌境5×5×5=125w</p>
<h3 id="潜能果"><a href="#潜能果" class="headerlink" title="潜能果"></a>潜能果</h3><p>15个</p>
<h2 id="阶段2：7-8月沉淀期"><a href="#阶段2：7-8月沉淀期" class="headerlink" title="阶段2：7,8月沉淀期"></a>阶段2：7,8月沉淀期</h2><h3 id="双抗17修"><a href="#双抗17修" class="headerlink" title="双抗17修"></a>双抗17修</h3><p>2664w储备</p>
<p>需要2个月</p>
<h3 id="更新灵饰-1"><a href="#更新灵饰-1" class="headerlink" title="更新灵饰"></a>更新灵饰</h3><p>后排80级(防御+法防+格挡)4段</p>
<h3 id="潜能果-1"><a href="#潜能果-1" class="headerlink" title="潜能果"></a>潜能果</h3><p>30个</p>
<h2 id="阶段3：9-10月变强期"><a href="#阶段3：9-10月变强期" class="headerlink" title="阶段3：9,10月变强期"></a>阶段3：9,10月变强期</h2><h3 id="师门150两个"><a href="#师门150两个" class="headerlink" title="师门150两个"></a>师门150两个</h3><p>1910*2=3820w储备，需要2个月</p>
<h3 id="更新装备"><a href="#更新装备" class="headerlink" title="更新装备"></a>更新装备</h3><p>头5段更新7段</p>
<p>前排80级(治疗+速度)4段</p>
<h3 id="潜能果-2"><a href="#潜能果-2" class="headerlink" title="潜能果"></a>潜能果</h3><p>45个</p>
<h2 id="阶段4：11-12月冲刺期"><a href="#阶段4：11-12月冲刺期" class="headerlink" title="阶段4：11,12月冲刺期"></a>阶段4：11,12月冲刺期</h2><h3 id="师门150三个"><a href="#师门150三个" class="headerlink" title="师门150三个"></a>师门150三个</h3><p>4078w储备，需要2个月</p>
<h3 id="更新装备-1"><a href="#更新装备-1" class="headerlink" title="更新装备"></a>更新装备</h3><p>腰带换黑宝石</p>
<p>更新140鞋子，上5段</p>
<h3 id="潜能果-3"><a href="#潜能果-3" class="headerlink" title="潜能果"></a>潜能果</h3><p>60个</p>
<h2 id="阶段5：1-2月渡劫期"><a href="#阶段5：1-2月渡劫期" class="headerlink" title="阶段5：1,2月渡劫期"></a>阶段5：1,2月渡劫期</h2><h3 id="宠修2个10"><a href="#宠修2个10" class="headerlink" title="宠修2个10"></a>宠修2个10</h3><p>每天28w秘传，一个月840w储备</p>
<p>使用高额的储备善恶跑宠环，一轮780经验</p>
<p>牧场4000积分一个果子</p>
<blockquote>
<p>秘传：每日150-200经验</p>
<p>6个月的储备善恶：每天善恶1000,18w善恶，平均能交90次环，大概跑3轮，2340经验</p>
<p>牧场：一周一个果子，一个月4个果子</p>
</blockquote>
<h4 id="2个月"><a href="#2个月" class="headerlink" title="2个月"></a>2个月</h4><p>总修炼值：150×60+2340+8×150=12540经验</p>
<p>0-10级需要：6600经验</p>
<p>每个月能保证1个10级</p>
<h3 id="乾元丹4丹"><a href="#乾元丹4丹" class="headerlink" title="乾元丹4丹"></a>乾元丹4丹</h3><p>900w储备</p>
<h2 id="阶段6：3-4月收官期"><a href="#阶段6：3-4月收官期" class="headerlink" title="阶段6：3,4月收官期"></a>阶段6：3,4月收官期</h2><h3 id="宠修2个10-1"><a href="#宠修2个10-1" class="headerlink" title="宠修2个10"></a>宠修2个10</h3><h3 id="升级155"><a href="#升级155" class="headerlink" title="升级155"></a>升级155</h3><h3 id="准备BB"><a href="#准备BB" class="headerlink" title="准备BB"></a>准备BB</h3><p>5技能血攻，高连套，5000血+2000伤</p>
]]></content>
      <categories>
        <category>游戏</category>
        <category>梦幻西游</category>
      </categories>
  </entry>
  <entry>
    <title>扩散模型检测</title>
    <url>/2024/04/27/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<h1 id="引用核心"><a href="#引用核心" class="headerlink" title="引用核心"></a>引用核心</h1><p>【论文1】D4: Detection of Adversarial Diffusion Deepfakes Using Disjoint Ensembles[D4:利用不相交频谱子集检测对抗性扩散深度伪造,2024,WACV]</p>
<p>【论文2】On the Vulnerability of Deepfake Detectors to Attacks Generated by Denoising Diffusion Models [基于去噪扩散模型的Deepfake检测器脆弱性研究,2024,WACV]</p>
<p>【论文3】Deepfake Forensics via An Adversarial Game[通过对抗性游戏进行深度取证,2022,IEEE TRANSACTIONS ON IMAGE PROCESSIN]</p>
<p>【论文4】Wavelet Diffusion Models are fast and scalable Image Generators[小波扩散模型是快速和可扩展的图像生成器,2023,CVPR]</p>
<p>【论文5】Detecting Deepfakes with Self-Blended Images[使用自混合图像检测深度伪造，2022,CVPR]</p>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>检测扩散生成的深度假图像仍然是一个悬而未决的问题。当前的检测方法无法对付向深度伪造添加难以察觉的<strong>对抗性扰动</strong>以逃避检测的对手。</p>
<p>于是要加强检测器的对抗鲁棒性，超越对抗训练。</p>
<p>论文D4提出使用<strong>频谱不相交</strong>子集上的模型集合来提高对抗鲁棒性。</p>
<p>利用了频率中的冗余，应用显著性划分技术，在多个模型中分散分布频率分量。</p>
<p>论文2研究了，deepfake的重建过程中仅采用单个去噪扩散步骤就可以显著减低检测的可能性，而无需引入任何可感知的图像修改。作者还观察到完全基于扩散的深度伪造上训练后的鉴别器对于这种攻击时表现的泛化性是有限的。在作者的对比实验中，发现SBI方法对这种攻击有不错的抵抗性。</p>
<p>论文3使用对抗制作的样本来攻击分类模型的训练可以大大提高泛化能力。提出基于人工智能的面部操作通常会导致高频伪像，这些伪像很容易被模型发现，但很难泛化。</p>
<p>且提出：对抗训练框架可以与许多修改网络结构的现有方法一起使用，以进一步提高深度伪造检测模型的性能。</p>
<p>论文4：提出了一中新的小波扩散模型</p>
<ul>
<li>利用小波带的降维来加速扩散模型，同时通过高频分量保持生成结果的良好视觉质量</li>
<li>在图像和特征空间中使用小波分解来提高生成模型的鲁棒性和执行速度</li>
<li>该方法提供了最先进的训练和推理速度</li>
</ul>
<p>论文5则是用一张图片分为源图像和目标图像，并将2张图像分别随机图像操作，最后用Mask来融合成一张图像。即让模型训练合成数据来提升模型的鲁棒性。</p>
<h1 id="问题与构想"><a href="#问题与构想" class="headerlink" title="问题与构想"></a>问题与构想</h1><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li>扩散模型对deepfake添加难以察觉的 对抗性扰动</li>
<li>高频伪像容易被模型发现，但是不容易泛化</li>
<li>倘若使用扩散模型加入合成数据，其三个指标会互相牵制(生成质量，生成效率)</li>
<li>单纯的扩散模型对深度伪造的泛化能力是有限的</li>
<li>需要提高模型的鲁棒性，对数据的泛化能力，提高低质量数据检测能力</li>
</ul>
<h2 id="构想"><a href="#构想" class="headerlink" title="构想"></a>构想</h2><ul>
<li>根据论文3，论文4，论文5。我让扩散模型取代对抗模型，扩散模型比对抗模型有更好的生成图像能力和图像恢复能力，并与SBI方法和流行的网络结合。从而提高了合成数据的质量，进而提高模型的鲁棒性和对低质量数据的检测能力</li>
<li>根据论文1和4,将频率分散，提高对高频伪像的泛化能力</li>
<li>而论文4小波模型的高效率提高模型的检测速度。</li>
</ul>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><h2 id="扩散模型"><a href="#扩散模型" class="headerlink" title="扩散模型"></a>扩散模型</h2><h3 id="DDPM"><a href="#DDPM" class="headerlink" title="DDPM"></a>DDPM</h3><h3 id="DDGAN"><a href="#DDGAN" class="headerlink" title="DDGAN"></a>DDGAN</h3><h3 id="WDDGAN"><a href="#WDDGAN" class="headerlink" title="WDDGAN"></a>WDDGAN</h3><h2 id="小波变换"><a href="#小波变换" class="headerlink" title="小波变换"></a>小波变换</h2><p>小波变换是一种广泛应用于图像压缩的经典技术，用于从原始图像中分离低频近似和高频细节。低子带类似于原始图像的下采样版本，而高子带表示垂直、水平和对角线边缘的局部统计。值得注意的是，哈尔小波由于其简单性在实际应用中被广泛采用。它包括两种运算:离散小波变换(DWT)和离散逆小波变换(IWT)。</p>
<p>令L =√1 2 1 1和H =√1 2−1 1分别为低通滤波器和高通滤波器。它们用于构造步长为2的四个核，即LLT、LHT、HLT、HHT，将输入X∈RH×W分解为大小为H/2 ×W /2的Xll、Xlh、Xhl、Xhh四个子带。由于这些滤波器是成对正交的，它们可以形成一个4×4可逆矩阵，通过IWT精确地从频率分量重构原始信号X。</p>
<p>在本文中，我们使用这种变换来分解输入图像和特征映射，以强调高频成分，并将空间维度降至四倍，以提高采样效率。</p>
<h3 id="Haar"><a href="#Haar" class="headerlink" title="Haar"></a>Haar</h3><p>Haar小波变换是一种基于小波的信号处理方法，它将信号分解成低频和细节高频两个部分。在图像处理中，Haar小波通常用于图像压缩和特征提取，代码中使用的DWTForward模块中离散小波变换，通过选择 yH 中的不同方向上的高频分量，构建了新的特征图。将原始低频分量 yL 与新构建的高频分量拼接在一起。最后通过一个包含卷积、批归一化和ReLU激活函数的序列处理最终的特征图。</p>
<h2 id="基于小波的扩散方案"><a href="#基于小波的扩散方案" class="headerlink" title="基于小波的扩散方案"></a>基于小波的扩散方案</h2><p>首先，我们描述了如何在扩散过程中引入小波变换。我们将输入图像分解为四个小波子带，并将它们作为单个目标连接起来进行去噪处理(如图2所示)。这种模型不是在原始图像空间上执行，而是在小波谱上执行。因此，我们的模型可以利用高频信息来进一步增加生成图像的细节。同时，小波子带的空间面积比原始图像小4倍，大大降低了采样过程的计算复杂度。</p>
<p>我们的方法建立在DDGAN模型上，其中输入是小波变换的4个小波子带。给定输入图像x∈R3×H×W，我们将其分解为一组低、高子带，并将它们进一步连接形成矩阵y∈R12×H 2 ×W 2。</p>
<h1 id="提出方法"><a href="#提出方法" class="headerlink" title="提出方法"></a>提出方法</h1><h2 id="小波扩散混合图像"><a href="#小波扩散混合图像" class="headerlink" title="小波扩散混合图像"></a>小波扩散混合图像</h2><h3 id="方案1"><a href="#方案1" class="headerlink" title="方案1"></a>方案1</h3><p>首先，对于每一张图片来自视频抽取的帧，我们将图片复制，分为2个通道。一个为源图片生成通道，一个为目标图片的生成通道。源图片对其进行随机裁剪，变换等操作，目标图像则用小波扩散处理，最后我们将两个图形进行MASK混合</p>
<h3 id="方案2"><a href="#方案2" class="headerlink" title="方案2"></a>方案2</h3><p>首先，对于每一张图片来自视频抽取的帧，我们将图片复制，分为2个通道。两个图像分别进行diffusion操作，结果附不同的权重，将两者diffusion结果加权相加后，再做Denoise流程。</p>
<h2 id="去噪过程"><a href="#去噪过程" class="headerlink" title="去噪过程"></a>去噪过程</h2><p><img src="https://gitee.com/qinyueren/drawing-bed/raw/master/image-20240428145601500.png" alt="image-20240428145601500"></p>
<p>接下来，我们通过生成器将小波信息进一步纳入特征空间，增强对高频成分的感知。这有利于最终图像的清晰度和质量。</p>
<p>图3说明了我们提出的小波嵌入发生器的结构。它遵循[44]的UNet结构，M个下采样和M个上采样块，加上相同分辨率的块之间的跳过连接，M是预定义的。然而，我们没有使用正常的下采样和上采样算子，而是用频率感知块代替它们。在最低分辨率下，我们采用频率瓶颈块来更好地关注低频和高频组件。最后，为了将原始信号Y合并到编码器的不同特征金字塔中，我们使用小波下采样层引入了频率残差连接。设Y为输入图像，Fi为Y的第i个中间特征映射。我们将在下面讨论新引入的分量:</p>
<h3 id="频率感知下采样和上采样块。"><a href="#频率感知下采样和上采样块。" class="headerlink" title="频率感知下采样和上采样块。"></a>频率感知下采样和上采样块。</h3><p>传统方法依赖于模糊核的下采样和上采样过程，以减轻混叠伪影。相反，我们利用小波变换的固有特性来进行更好的上采样和下采样(如图4所示)。实际上，这加强了对这些操作的高频信息的认识。特别是，下采样块接收输入特征Fi、潜伏z和时间嵌入t的元组，然后通过一系列层处理以返回下采样特征和高频子带。这些返回的子带作为基于上采样块中的频率线索的上采样特征的额外输入。</p>
<h3 id="频率瓶颈块"><a href="#频率瓶颈块" class="headerlink" title="频率瓶颈块"></a>频率瓶颈块</h3><p>处于中间阶段，包括两个频率瓶颈块和中间的一个注意块。每个频率瓶颈块首先将特征映射Fi划分为低频子带Fi、ll和高频子带Fi、H的拼接。然后将Fi,ll作为输入传递给重新分配块以进行更深入的处理。处理后的低频特征映射和原高频子带Fi、H通过IWT变换回原空间。有了这样的瓶颈，该模型可以专注于学习低频子带的中间特征表示，同时保留高频细节。</p>
<h3 id="频率残差连接"><a href="#频率残差连接" class="headerlink" title="频率残差连接"></a>频率残差连接</h3><p>[44]中网络的原始设计通过跨行卷积下采样层将原始信号Y合并到编码器的不同特征金字塔中。相反，我们使用小波下采样层将输入Y的剩余快捷方式映射到相应的特征维度，然后将其添加到每个特征金字塔中。具体来说，Y的残差捷径被分解成四个子带，然后将这些子带连接并馈送到卷积层进行特征投影。这个捷径的目的是丰富对特征嵌入的频率源的感知。</p>
<h3 id="SBI混合"><a href="#SBI混合" class="headerlink" title="SBI混合"></a>SBI混合</h3><h1 id="实验计划"><a href="#实验计划" class="headerlink" title="实验计划"></a>实验计划</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="FF"><a href="#FF" class="headerlink" title="FF++"></a>FF++</h3><h3 id="CDF"><a href="#CDF" class="headerlink" title="CDF"></a>CDF</h3><h3 id="DFDC"><a href="#DFDC" class="headerlink" title="DFDC"></a>DFDC</h3><h3 id="SDDF"><a href="#SDDF" class="headerlink" title="SDDF"></a>SDDF</h3><h2 id="对比实验"><a href="#对比实验" class="headerlink" title="对比实验"></a>对比实验</h2><h3 id="方法对比"><a href="#方法对比" class="headerlink" title="方法对比"></a>方法对比</h3><ul>
<li>SBI</li>
<li>SBI+DDPM</li>
<li>SBI+DDGAN</li>
<li>SBI+WDDGAN</li>
</ul>
<p>4种方法在4个数据集上的测试效果</p>
<p>共16组数据</p>
<h3 id="数据集对比"><a href="#数据集对比" class="headerlink" title="数据集对比"></a>数据集对比</h3><p>4个数据集之间交叉训练和测试</p>
<p>例如，用FF++数据集训练，测试其他3个数据集</p>
<p>共16组数据</p>
<h3 id="训练网络对比"><a href="#训练网络对比" class="headerlink" title="训练网络对比"></a>训练网络对比</h3><ul>
<li>ResNet</li>
<li>Xception</li>
<li>EfficientNet</li>
</ul>
<p>3种网络架构在4种数据集上的测试效果</p>
<p>共12组数据</p>
<h2 id="质量分析"><a href="#质量分析" class="headerlink" title="质量分析"></a>质量分析</h2><h3 id="Saliency-Map"><a href="#Saliency-Map" class="headerlink" title="Saliency Map"></a>Saliency Map</h3><h3 id="Feature-Space"><a href="#Feature-Space" class="headerlink" title="Feature Space"></a>Feature Space</h3><h1 id="后期的规划"><a href="#后期的规划" class="headerlink" title="后期的规划"></a>后期的规划</h1><p>论文1：Wavalet-VIT-ECCV</p>
<p>论文2：VIT替换UNet-ICCV</p>
<p>根据这两篇论文，后期将会让用于去噪训练的模型Unet替换成VIT</p>
<p>或者将网络架构添加VIT</p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>H.264</title>
    <url>/2024/05/16/H.264/</url>
    <content><![CDATA[<h1 id="H264-简介"><a href="#H264-简介" class="headerlink" title="H264 简介"></a>H264 简介</h1><p>H.264，同时也是 MPEG-4 第十部分，是由 ITU-T 视频编码专家组（VCEG）和 ISO/IEC 动态图像专家组（MPEG）联合组成的联合视频组（JVT，Joint Video Team）提出的高度压缩数字视频编解码器标准。这个标准通常被称之为 H.264/AVC（或者 AVC/H.264 或者 H.264/MPEG-4 AVC 或 MPEG-4/H.264 AVC）。是一种面向块，基于运动补偿的视频编码标准。</p>
<p>视频编码其本质就是将<a href="https://so.csdn.net/so/search?q=数据压缩&amp;spm=1001.2101.3001.7020">数据压缩</a>，主要是去除冗余信息（包括空间上的冗余信息和时间上的冗余信息），从而实现数据量的压缩。</p>
<ul>
<li><strong>空间冗余</strong>： 在同一图像（帧）内，相近像素之间的差别很小（甚至是相同的），所以就可以用一个特定大小的像素矩阵来表示相邻的像素。</li>
<li><strong>时间冗余</strong>： 视频中连续的图像（帧）之间，其中发生变化的像素占整张图像像素的比例极其微小，所以就可以用其中一帧来表示相邻的帧来减少带宽消耗。</li>
<li><strong>编码冗余</strong>： 不同像素出现的概率不同，所以就可以为出现概率高的像素分配尽量少的字节，对出现概率低的像素分配尽量多的字节。</li>
<li><strong>视觉冗余</strong>：人眼对很多像素颜色不敏感，所以就可以丢弃这些冗余的信息而并不影响人眼观看的效果。</li>
<li><strong>知识冗余</strong>：有许多图像的理解与某些基础知识有相当大的相关性。例如，人脸的图像有固定的结构，嘴的上方有鼻子，鼻子的上方有眼睛，鼻子位于正面图像的中线上等等。这类规律性的结构可由先验知识和背景知识得到，我们称此类冗余为知识冗余。根据已有知识，对某些图像中所包含的物体，可以构造其基本模型，并创建对应各种特征的图像库，进而图像的存储只需要保存一些特征参数，从而可以大大减少数据量。</li>
</ul>
<p>用一个简单的例子来说明编码的必要性：<br>当你此刻显示器正在播放一个视频，分辨率是1280*720，帧率是25，那么一秒所产生正常的数据大小为：</p>
<blockquote>
<p>1280×720(位像素)×25(帧) / 8(1字节8位)(转换结果:B) / 1024(转换结果:KB) / 1024<br>(转换结果:MB) = 2.74MB</p>
</blockquote>
<p>那么90分钟的电影就要14.8GB，这个数据量显然在当前网络下是不现实的。</p>
<h1 id="H264-功能结构"><a href="#H264-功能结构" class="headerlink" title="H264 功能结构"></a>H264 功能结构</h1><p>在 H.264/AVC 视频编码标准中，整个系统框架划分为如下两个层面：</p>
<ul>
<li><strong>视频编码层</strong>（Video Coding Layer，VCL）：VCL 数据即被压缩编码后的视频数据序列，负责有效表示视频数据的内容，主要包括帧内预测，帧间预测、变换量化、熵编码等压缩单元。</li>
<li><strong>网络抽象层</strong>（Network Abstraction Layer，NAL）：负责将 VCL 数据封装到 NAL 单元中，并提供头信息，以保证数据适合各种信道和存储介质上的传输。</li>
</ul>
<h1 id="H264-帧类型"><a href="#H264-帧类型" class="headerlink" title="H264 帧类型"></a>H264 帧类型</h1><p>H264 结构中，一个视频图像编码后的数据叫做一帧，一帧由一个片（slice）或多个片组成，一个片由一个或多个宏块（MB）组成，一个宏块由16x16的 yuv 数据组成。宏块作为 H264 编码的基本单位。</p>
<p>经过压缩后的帧分为：I帧，P帧 和 B帧:</p>
<ul>
<li>I帧：关键帧，采用==帧内压缩技术==。你可以理解为这一帧画面的完整保留，解码时只需要本帧数据就可以完成（因为包含完整画面）。</li>
<li>P帧：向前参考帧，在压缩时，只参考前面已经处理的帧。采用==帧间压缩技术==。P 帧表示的是这一帧跟之前的一个关键帧（或 P 帧）的差别，解码时需要用之前<strong>缓存的画面</strong>叠加上<strong>本帧定义</strong>的差别，生成最终画面。（也就是差别帧，P 帧没有完整画面数据，只有与前一帧的画面差别的数据）。</li>
<li>B帧：双向参考帧，在压缩时，它即参考前而的帧，又参考它后面的帧。采用==帧间压缩技术==。B 帧记录的是本帧与前后帧的差别，换言之，要解码 B 帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B 帧压缩率高，但是解码时 CPU 工作量会比较大。</li>
</ul>
<p>两个 I 帧之间是一个图像序列，即 GOP，在一个图像序列中只有一个I帧。</p>
<p>当运动变化比较少时，一个序列可以很长，因为运动变化少就代表图像画面的内容变动很小，所以就可以编一个 I 帧，然后一直 P 帧、B 帧了。当运动变化多时，可能一个序列就比较短了。</p>
<p>还有一个概念是，IDR帧：<br>一个序列的第一个图像叫做 IDR 图像（立即刷新图像），IDR 图像都是 I 帧图像。H.264 引入 IDR 图像是为了解码的重同步，当解码器解码到 IDR 图像时，立即将参考帧队列清空，将已解码的数据全部输出或抛弃，重新查找参数集，开始一个新的序列。这样，如果前一个序列出现重大错误，在这里可以获得重新同步的机会。IDR 图像之后的图像永远不会使用 IDR 之前的图像的数据来解码。IDR 图像一定是 I 图像，但 I 图像不一定是 IDR 图像。一个序列中可以有很多的I图像，I 图像之后的图像可以引用 I 图像之间的图像做运动参考。</p>
<p>还有一点注意的，对于 IDR 帧来说，在 IDR 帧之后的所有帧都不能引用任何 IDR 帧之前的帧的内容，与此相反，对于普通的 I 帧来说，位于其之后的 B帧 和 P 帧可以引用位于普通 I 帧之前的 I 帧。从随机存取的视频流中，播放器永远可以从一个 IDR 帧播放，因为在它之后没有任何帧引用之前的帧。但是，不能在一个没有 IDR 帧的视频中从任意点开始播放，因为后面的帧总是会引用前面的帧。<br>I、B、P 各帧是根据压缩算法的需要，是人为定义的，它们都是实实在在的物理帧。一般来说，I 帧的压缩率是7（跟JPG差不多），P 帧是20，B 帧可以达到50。可见使用 B 帧能节省大量空间，节省出来的空间可以用来保存多一些 I 帧，这样在相同码率下，可以提供更好的画质。</p>
<p>正因为有 B 帧这样的双向预测帧的存在，某一帧的解码序列和实际的显示序列是不一样的。如下图所示：</p>
<p>DTS: (Decode Time Stamp) 用于视频的解码序列<br>PTS: (Presentation Time Stamp)用于视频的显示序列。</p>
<h1 id="H264-编码原理"><a href="#H264-编码原理" class="headerlink" title="H264 编码原理"></a>H264 编码原理</h1><p>H264 采用的核心压缩算法是帧内压缩和帧间压缩，帧内压缩是生成 I 帧的算法，帧间压缩是生成 B 帧和 P 帧的算法。</p>
<ul>
<li>帧内（Intraframe）压缩：也称为空间压缩（Spatialcompression）。当压缩一帧图像时，仅考虑本帧的数据而不考虑相邻帧之间的冗余信息，这实际上与静态图像压缩类似。帧内一般采用有损压缩算法，由于帧内压缩是编码一个完整的图像，所以可以独立的解码、显示。帧内压缩一般达不到很高的压缩，跟编码 JPEG 差不多。</li>
<li>帧间（Interframe）压缩：也称为时间压缩（Temporalcompression），它通过比较时间轴上不同帧之间的数据进行压缩。帧间压缩一般是无损的。帧差值（Framedifferencing）算法是一种典型的时间压缩法，相邻几帧的数据有很大的相关性，它通过比较本帧与相邻帧之间的差异，仅记录本帧与其相邻帧的差值，这样可以大大减少数据量。</li>
</ul>
<p>下面就简单描述下 H264 压缩数据的过程。通过摄像头采集到的视频帧（按每秒 30 帧算），被送到 H264 编码器的缓冲区中。编码器先要为每一幅图片划分宏块。</p>
<h3 id="划分宏块"><a href="#划分宏块" class="headerlink" title="划分宏块"></a>划分宏块</h3><p>H264 默认是使用 16X16 大小的区域作为一个宏块，也可以划分成 8X8 大小。</p>
<p>划分好宏块后，计算宏块的象素值。</p>
<p>以此类推，计算一幅图像中每个宏块的像素值。</p>
<h3 id="划分子块"><a href="#划分子块" class="headerlink" title="划分子块"></a>划分子块</h3><p>H264 对比较平坦的图像使用 16X16 大小的宏块。但为了更高的压缩率，还可以在 16X16 的宏块上更划分出更小的子块。子块的大小可以是 8X16､ 16X8､ 8X8､ 4X8､ 8X4､ 4X4非常的灵活。</p>
<h3 id="帧分组"><a href="#帧分组" class="headerlink" title="帧分组"></a>帧分组</h3><p>对于视频数据主要有两类数据冗余，一类是时间上的数据冗余，另一类是空间上的数据冗余。其中时间上的数据冗余是最大的。为什么这么说呢？假设摄像头每秒抓取30帧，这30帧的数据大部分情况下都是相关联的。也有可能不止30帧的的数据，可能几十帧，上百帧的数据都是关联特别密切的。<br>对于这些关联特别密切的帧，其实我们只需要保存一帧的数据，其它帧都可以通过这一帧再按某种规则预测出来，所以说视频数据在时间上的冗余是最多的。<br>为了达到相关帧通过预测的方法来压缩数据，就需要将视频帧进行分组。</p>
<p>H264 编码器会按顺序，每次取出两幅相邻的帧进行宏块比较，计算两帧的相似度。</p>
<p>通过宏块扫描与宏块搜索可以发现这两个帧的关联度是非常高的。进而发现这一组帧的关联度都是非常高的。因此，上面这几帧就可以划分为一组。其算法是：在相邻几幅图像画面中，一般有差别的像素只有10%以内的点,亮度差值变化不超过2%，而色度差值的变化只有1%以内，我们认为这样的图可以分到一组。<br>在这样一组帧中，经过编码后，我们只保留第一帖的完整数据，其它帧都通过参考上一帧计算出来。我们称第一帧为 IDR／I 帧，其它帧我们称为 P／B 帧，这样编码后的数据帧组我们称为 GOP。</p>
<h3 id="运动估计与补偿"><a href="#运动估计与补偿" class="headerlink" title="运动估计与补偿"></a>运动估计与补偿</h3><p>在 H264 编码器中将帧分组后，就要计算帧组内物体的运动矢量了。</p>
<p>H264 编码器首先按顺序从缓冲区头部取出两帧视频数据，然后进行宏块扫描。当发现其中一幅图片中有物体时，就在另一幅图的邻近位置（搜索窗口中）进行搜索。如果此时在另一幅图中找到该物体，那么就可以计算出物体的运动矢量了。</p>
<p>运动矢量计算出来后，将相同部分（也就是绿色部分）减去，就得到了补偿数据。我们最终只需要将补偿数据进行压缩保存，以后在解码时就可以恢复原图了。压缩补偿后的数据只需要记录很少的一点数据。</p>
<p>我们把运动矢量与补偿称为<strong>帧间压缩技术</strong>，它解决的是视频帧在时间上的数据冗余。除了帧间压缩，帧内也要进行数据压缩，帧内数据压缩解决的是空间上的数据冗余。下面我们就来介绍一下帧内压缩技术。</p>
<h3 id="帧内预测"><a href="#帧内预测" class="headerlink" title="帧内预测"></a>帧内预测</h3><p>人眼对图象都有一个识别度，对低频的亮度很敏感，对高频的亮度不太敏感。所以基于一些研究，可以将一幅图像中人眼不敏感的数据去除掉。这样就提出了帧内预测技术。</p>
<p>一幅图像被划分好宏块后，对每个宏块可以进行 9 种模式的预测。找出与原图最接近的一种预测模式。</p>
<p>将原始图像与帧内预测后的图像相减得残差值。</p>
<p>再将我们之前得到的预测模式信息一起保存起来，这样我们就可以在解码时恢复原图了。</p>
<p>经过帧内与帧间的压缩后，虽然数据有大幅减少，但还有优化的空间。</p>
<h3 id="对残差数据做-DCT-变换"><a href="#对残差数据做-DCT-变换" class="headerlink" title="对残差数据做 DCT 变换"></a>对残差数据做 DCT 变换</h3><p>可以将残差数据做整数离散余弦变换，去掉数据的相关性，进一步压缩数据。</p>
<p><strong>离散余弦变换（DCT）的作用</strong>：DCT的主要目的是将图像从空间域（即像素表示）转换到频率域。在频率域中，图像的信息被表示为不同频率的余弦波的组合。高频成分通常对应于图像中的细节部分（如边缘），而低频成分则对应于图像中的平滑区域。</p>
<p>压缩与质量的权衡：在DCT和图像压缩中，总是存在着数据量（压缩率）和图像质量之间的权衡。压缩图像通常涉及保留更多的低频信息（因为它们对人眼更重要）并丢弃或减少高频信息。块的大小直接影响这种权衡：较小的块提供更好的图像质量但较低的压缩率，而较大的块则提供更高的压缩率但可能牺牲图像的细节质量。</p>
<p>变换系数的阈值处理：在DCT后，通常会对变换系数进行阈值处理，即保留最重要的系数（通常是最大的系数，代表了图像中最显著的频率成分），而将其它系数设置为零。这种方法在大块尺寸下特别有效，因为在这些情况下，仅需要少量的系数就能代表整个块的主要信息。</p>
<p>总结：离散余弦变换（DCT）在图像处理中的应用涉及块大小选择的重要考虑。不同的块大小会影响DCT在压缩效率和图像质量之间的平衡，小块更适合高频细节的保留，而大块更有利于高压缩率的实现，但可能牺牲一些细节质量。理解这些原理有助于在图像压缩和处理中做出更合适的技术选择。</p>
<h3 id="熵编码（CABAC）"><a href="#熵编码（CABAC）" class="headerlink" title="熵编码（CABAC）"></a>熵编码（CABAC）</h3><p>上面的帧内压缩是属于有损压缩技术，也就是说图像被压缩后，无法完全复原。而熵编码压缩是一种无损压缩，其实现原理是使用新的编码来表示输入的数据，给高频的词一个短码，给低频词一个长码，从而达到压缩的效果。常用的熵编码有游程编码，哈夫曼编码和 CAVLC 编码等。</p>
<p>在 H.264/MPEG-4 AVC 中使用的熵编码算法是 CABAC（ContextAdaptive Binary Arithmatic Coding）。CABAC 在不同的上下文环境中使用不同的概率模型来编码。其编码过程大致是这样：首先，将欲编码的符号用二进制 bit 表示；然后对于每个 bit，编码器选择一个合适的概率模型，并通过相邻元素的信息来优化这个概率模型；最后，使用算术编码压缩数据。<br>我们以 A-Z 作为例子，A属于高频数据，Z属于低频数据。</p>
]]></content>
      <categories>
        <category>计算机</category>
        <category>视频编码</category>
      </categories>
  </entry>
  <entry>
    <title>人脸识别对齐</title>
    <url>/2024/06/17/insightface/</url>
    <content><![CDATA[<h1 id="1快速上手"><a href="#1快速上手" class="headerlink" title="1快速上手"></a>1快速上手</h1><p>在【python-package】目录下执行</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">pip <span class="keyword">install</span> .</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>计算机</category>
        <category>CV学习</category>
      </categories>
  </entry>
  <entry>
    <title>日常收益一览</title>
    <url>/2024/06/24/%E6%97%A5%E5%B8%B8%E6%94%B6%E7%9B%8A%E4%B8%80%E8%A7%88/</url>
    <content><![CDATA[<h1 id="日常储备金"><a href="#日常储备金" class="headerlink" title="日常储备金"></a>日常储备金</h1><p><strong>副本</strong></p>
<p>10w</p>
<p><strong>押镖5次</strong></p>
<p>5×2.8=14w</p>
<p><strong>每日师门</strong></p>
<p>5w</p>
<p><strong>师徒20环</strong></p>
<p>20×0.3=6w</p>
<p><strong>一间烹饪店</strong></p>
<p>15w</p>
<p><strong>牧场</strong></p>
<p>10w</p>
<p><strong>口袋</strong></p>
<p>40w</p>
<p><strong>合计：100w</strong></p>
<h1 id="月收入储备金"><a href="#月收入储备金" class="headerlink" title="月收入储备金"></a>月收入储备金</h1><p><strong>5日师门</strong></p>
<p>10w</p>
<p><strong>20日师门</strong></p>
<p>50w</p>
<p><strong>30次签到答题</strong></p>
<p>50w</p>
<p><strong>庭院种子(待测)</strong></p>
<p><strong>月共计：10*4+50+50+100×30=3140w</strong></p>
<h1 id="口袋580满活跃度计算"><a href="#口袋580满活跃度计算" class="headerlink" title="口袋580满活跃度计算"></a>口袋580满活跃度计算</h1><div class="table-container">
<table>
<thead>
<tr>
<th>任务</th>
<th>精力</th>
<th>活跃</th>
</tr>
</thead>
<tbody>
<tr>
<td>师门+葫芦</td>
<td>40</td>
<td>80</td>
</tr>
<tr>
<td>抓鬼+葫芦</td>
<td>75</td>
<td>110</td>
</tr>
<tr>
<td>官职+葫芦</td>
<td>100</td>
<td>80</td>
</tr>
<tr>
<td>登录互通</td>
<td>0</td>
<td>25</td>
</tr>
<tr>
<td>打坐(120分钟)</td>
<td>120</td>
<td>60</td>
</tr>
<tr>
<td>修行(180分钟)</td>
<td>180</td>
<td>180</td>
</tr>
<tr>
<td>每日福袋葫芦</td>
<td>150</td>
<td>50</td>
</tr>
<tr>
<td></td>
<td>665</td>
<td>565</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>游戏</category>
        <category>梦幻西游</category>
      </categories>
  </entry>
</search>
